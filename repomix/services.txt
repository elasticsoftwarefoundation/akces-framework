This file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.
The content has been processed where comments have been removed, content has been compressed (code blocks are separated by ⋮---- delimiter).

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: *.md, services/**/*.java, services/**/*.xml, services/**/*.properties, services/**/*.proto, services/**/*.imports, services/**/*.yaml
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Code comments have been removed from supported file types
- Content has been compressed - code blocks are separated by ⋮---- delimiter

Additional Info:
----------------

================================================================
Directory Structure
================================================================
services/
  operator/
    src/
      main/
        java/
          org/
            elasticsoftware/
              akces/
                operator/
                  aggregate/
                    Aggregate.java
                    AggregateReconciler.java
                    AggregateSpec.java
                    AggregateStatus.java
                    ConfigMapDependentResource.java
                    ServiceDependentResource.java
                    StatefulSetDependentResource.java
                  command/
                    CommandService.java
                    CommandServiceReconciler.java
                    CommandServiceSpec.java
                    CommandServiceStatus.java
                    ConfigMapDependentResource.java
                    ServiceDependentResource.java
                    StatefulSetDependentResource.java
                  query/
                    ConfigMapDependentResource.java
                    QueryService.java
                    QueryServiceReconciler.java
                    QueryServiceSpec.java
                    QueryServiceStatus.java
                    ServiceDependentResource.java
                    StatefulSetDependentResource.java
                  utils/
                    KafkaTopicUtils.java
                  AkcesOperatorApplication.java
                  AkcesOperatorConfig.java
        resources/
          META-INF/
            native-image/
              native-image.properties
          org/
            elasticsoftware/
              akces/
                operator/
                  aggregate/
                    configmap.yaml
                    service.yaml
                    statefulset.yaml
                  command/
                    configmap.yaml
                    service.yaml
                    statefulset.yaml
                  query/
                    configmap.yaml
                    service.yaml
                    statefulset.yaml
          application.properties
          logback.xml
      test/
        java/
          org/
            elasticsoftware/
              akces/
                operator/
                  AkcesOperatorApplicationTests.java
    pom.xml
  pom.xml
FRAMEWORK_OVERVIEW.md
README.md
RELEASE.md

================================================================
Files
================================================================

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/aggregate/Aggregate.java
================
public class Aggregate extends CustomResource<AggregateSpec, AggregateStatus> implements Namespaced {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/aggregate/AggregateReconciler.java
================
public class AggregateReconciler implements Reconciler<Aggregate> {
private final Logger log = LoggerFactory.getLogger(getClass());
⋮----
public void init() {
partitions = kafkaAdmin.describeTopics("Akces-Control").get("Akces-Control").partitions().size();
log.info("Found Akces-Control Topic with {} partitions", partitions);
⋮----
public UpdateControl<Aggregate> reconcile(Aggregate resource, Context<Aggregate> context) throws Exception {
reconcileTopics(resource.getSpec().getAggregateNames());
return context.getSecondaryResource(StatefulSet.class).map(statefulSet -> {
Aggregate updatedAggregate = createAggregateForStatusUpdate(resource, statefulSet);
log.info(
⋮----
resource.getMetadata().getName(),
resource.getMetadata().getNamespace(),
resource.getStatus() == null ? 0 : resource.getStatus().getReadyReplicas());
return UpdateControl.patchStatus(updatedAggregate);
}).orElseGet(UpdateControl::noUpdate);
⋮----
private Aggregate createAggregateForStatusUpdate(Aggregate tomcat, StatefulSet statefulSet) {
Aggregate res = new Aggregate();
res.setMetadata(new ObjectMetaBuilder()
.withName(tomcat.getMetadata().getName())
.withNamespace(tomcat.getMetadata().getNamespace())
.build());
⋮----
Objects.requireNonNullElse(statefulSet.getStatus(), new StatefulSetStatus());
int readyReplicas = Objects.requireNonNullElse(statefulSetStatus.getReadyReplicas(), 0);
AggregateStatus status = new AggregateStatus();
status.setReadyReplicas(readyReplicas);
res.setStatus(status);
⋮----
private void reconcileTopics(List<String> aggregateNames) {
log.info("Reconciling topics for Aggregates: {}", aggregateNames);
List<NewTopic> topics = aggregateNames.stream()
.map(name -> KafkaTopicUtils.createTopics(name, partitions))
.flatMap(List::stream).toList();
kafkaAdmin.createOrModifyTopics(topics.toArray(new NewTopic[0]));

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/aggregate/AggregateSpec.java
================
public class AggregateSpec {
⋮----
public List<String> getAggregateNames() {
⋮----
public void setAggregateNames(List<String> aggregateNames) {
⋮----
public Integer getReplicas() {
⋮----
public void setReplicas(Integer replicas) {
⋮----
public String getImage() {
⋮----
public void setImage(String image) {
⋮----
public List<String> getArgs() {
⋮----
public void setArgs(List<String> args) {
⋮----
public ResourceRequirements getResources() {
⋮----
public void setResources(ResourceRequirements resources) {
⋮----
public Boolean getEnableSchemaOverwrites() {
⋮----
public void setEnableSchemaOverwrites(Boolean enableSchemaOverwrites) {
⋮----
public String getApplicationName() {
⋮----
public void setApplicationName(String applicationName) {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/aggregate/AggregateStatus.java
================
public class AggregateStatus {
⋮----
public Integer getReadyReplicas() {
⋮----
public void setReadyReplicas(Integer readyReplicas) {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/aggregate/ConfigMapDependentResource.java
================
public class ConfigMapDependentResource extends CRUDKubernetesDependentResource<ConfigMap, Aggregate> {
⋮----
protected ConfigMap desired(Aggregate aggregate, Context<Aggregate> context) {
final ObjectMeta aggregateMetadata = aggregate.getMetadata();
final String aggregateName = aggregateMetadata.getName();
return new ConfigMapBuilder(ReconcilerUtils.loadYaml(ConfigMap.class, getClass(), "configmap.yaml"))
.editMetadata()
.withName(aggregateName + "-config")
.withNamespace(aggregateMetadata.getNamespace())
.addToLabels("app.kubernetes.io/part-of", aggregateName)
.addToLabels("app.kubernetes.io/managed-by", "akces-operator")
.endMetadata()
.build();

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/aggregate/ServiceDependentResource.java
================
public class ServiceDependentResource extends CRUDKubernetesDependentResource<Service, Aggregate> {
⋮----
protected Service desired(Aggregate aggregate, Context<Aggregate> context) {
final ObjectMeta aggregateMetadata = aggregate.getMetadata();
final String aggregateName = aggregateMetadata.getName();
return new ServiceBuilder(ReconcilerUtils.loadYaml(Service.class, getClass(), "service.yaml"))
.editMetadata()
.withName(aggregateName + "-service")
.withNamespace(aggregateMetadata.getNamespace())
.addToLabels("app.kubernetes.io/part-of", aggregateName)
.addToLabels("app.kubernetes.io/managed-by", "akces-operator")
.endMetadata()
.editSpec()
.addToSelector("app", aggregateMetadata.getName())
.endSpec()
.build();

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/aggregate/StatefulSetDependentResource.java
================
public class StatefulSetDependentResource extends CRUDKubernetesDependentResource<StatefulSet, Aggregate> {
⋮----
protected StatefulSet desired(Aggregate aggregate, Context<Aggregate> context) {
StatefulSet statefulSet = ReconcilerUtils.loadYaml(StatefulSet.class, getClass(), "statefulset.yaml");
final ObjectMeta aggregateMetadata = aggregate.getMetadata();
final String aggregateName = aggregateMetadata.getName();
⋮----
statefulSet = new StatefulSetBuilder(statefulSet)
.editMetadata()
.withName(aggregateName)
.withNamespace(aggregateMetadata.getNamespace())
.addToLabels("app", aggregateName)
.addToLabels("app.kubernetes.io/part-of", aggregateName)
.addToLabels("app.kubernetes.io/managed-by", "akces-operator")
.endMetadata()
.editSpec()
.withServiceName(aggregateName + "-service")
.editSelector().addToMatchLabels("app", aggregateName).endSelector()
.withReplicas(aggregate.getSpec().getReplicas())
.editTemplate()
.editMetadata().addToLabels("app", aggregateName).endMetadata()
⋮----
.addToImagePullSecrets(new LocalObjectReference("github-packages-cfg"))
.editFirstContainer()
.withImage(aggregate.getSpec().getImage())
.withName("akces-aggregate-service")
.withArgs(aggregate.getSpec().getArgs())
.editFirstEnv()
.withValue(aggregate.getSpec().getApplicationName())
.endEnv()
.editLastEnv()
.withValue(aggregate.getSpec().getEnableSchemaOverwrites().toString())
⋮----
.withResources(aggregate.getSpec().getResources())
.endContainer()
.editFirstVolume()
.editConfigMap()
.withName(aggregateName + "-config")
.endConfigMap()
.endVolume()
.endSpec()
.endTemplate()
.editFirstVolumeClaimTemplate()
⋮----
.withStorageClassName("akces-data-hyperdisk-balanced")
.editResources()
.withRequests(Map.of("storage", new Quantity("4Gi")))
.endResources()
⋮----
.endVolumeClaimTemplate()
⋮----
.build();

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/command/CommandService.java
================
public class CommandService extends CustomResource<CommandServiceSpec, CommandServiceStatus> implements Namespaced {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/command/CommandServiceReconciler.java
================
public class CommandServiceReconciler implements Reconciler<CommandService> {
private final Logger log = LoggerFactory.getLogger(getClass());
⋮----
public UpdateControl<CommandService> reconcile(CommandService commandService, Context<CommandService> context) throws Exception {
return context.getSecondaryResource(StatefulSet.class).map(statefulSet -> {
CommandService updatedCommandService = createCommandServiceForStatusUpdate(commandService, statefulSet);
return UpdateControl.patchStatus(updatedCommandService);
}).orElseGet(UpdateControl::noUpdate);
⋮----
private CommandService createCommandServiceForStatusUpdate(CommandService commandService, StatefulSet statefulSet) {
CommandService res = new CommandService();
res.setMetadata(new ObjectMetaBuilder()
.withName(commandService.getMetadata().getName())
.withNamespace(commandService.getMetadata().getNamespace())
.build());
⋮----
Objects.requireNonNullElse(statefulSet.getStatus(), new StatefulSetStatus());
int readyReplicas = Objects.requireNonNullElse(statefulSetStatus.getReadyReplicas(), 0);
CommandServiceStatus status = new CommandServiceStatus();
status.setReadyReplicas(readyReplicas);
res.setStatus(status);

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/command/CommandServiceSpec.java
================
public class CommandServiceSpec {
⋮----
public Integer getReplicas() {
⋮----
public void setReplicas(Integer replicas) {
⋮----
public String getImage() {
⋮----
public void setImage(String image) {
⋮----
public List<String> getArgs() {
⋮----
public void setArgs(List<String> args) {
⋮----
public ResourceRequirements getResources() {
⋮----
public void setResources(ResourceRequirements resources) {
⋮----
public String getApplicationName() {
⋮----
public void setApplicationName(String applicationName) {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/command/CommandServiceStatus.java
================
public class CommandServiceStatus {
⋮----
public Integer getReadyReplicas() {
⋮----
public void setReadyReplicas(Integer readyReplicas) {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/command/ConfigMapDependentResource.java
================
public class ConfigMapDependentResource extends CRUDKubernetesDependentResource<ConfigMap, CommandService> {
⋮----
protected ConfigMap desired(CommandService commandService, Context<CommandService> context) {
final ObjectMeta metadata = commandService.getMetadata();
final String commandServiceName = metadata.getName();
return new ConfigMapBuilder(ReconcilerUtils.loadYaml(ConfigMap.class, getClass(), "configmap.yaml"))
.editMetadata()
.withName(commandServiceName + "-config")
.withNamespace(metadata.getNamespace())
.addToLabels("app.kubernetes.io/part-of", commandServiceName)
.addToLabels("app.kubernetes.io/managed-by", "akces-operator")
.endMetadata()
.build();

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/command/ServiceDependentResource.java
================
public class ServiceDependentResource extends CRUDKubernetesDependentResource<Service, CommandService> {
⋮----
protected Service desired(CommandService commandService, Context<CommandService> context) {
final ObjectMeta metadata = commandService.getMetadata();
final String commandServiceName = metadata.getName();
return new ServiceBuilder(ReconcilerUtils.loadYaml(Service.class, getClass(), "service.yaml"))
.editMetadata()
.withName(commandServiceName + "-service")
.withNamespace(metadata.getNamespace())
.addToLabels("app.kubernetes.io/part-of", commandServiceName)
.addToLabels("app.kubernetes.io/managed-by", "akces-operator")
.endMetadata()
.editSpec()
.addToSelector("app", metadata.getName())
.endSpec()
.build();

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/command/StatefulSetDependentResource.java
================
public class StatefulSetDependentResource extends CRUDKubernetesDependentResource<StatefulSet, CommandService> {
⋮----
protected StatefulSet desired(CommandService aggregate, Context<CommandService> context) {
StatefulSet statefulSet = ReconcilerUtils.loadYaml(StatefulSet.class, getClass(), "statefulset.yaml");
final ObjectMeta metadata = aggregate.getMetadata();
final String commandServiceName = metadata.getName();
⋮----
statefulSet = new StatefulSetBuilder(statefulSet)
.editMetadata()
.withName(commandServiceName)
.withNamespace(metadata.getNamespace())
.addToLabels("app", commandServiceName)
.addToLabels("app.kubernetes.io/part-of", commandServiceName)
.addToLabels("app.kubernetes.io/managed-by", "akces-operator")
.endMetadata()
.editSpec()
.withServiceName(commandServiceName + "-service")
.editSelector().addToMatchLabels("app", commandServiceName).endSelector()
.withReplicas(aggregate.getSpec().getReplicas())
.editTemplate()
.editMetadata().addToLabels("app", commandServiceName).endMetadata()
⋮----
.addToImagePullSecrets(new LocalObjectReference("github-packages-cfg"))
.editFirstContainer()
.withImage(aggregate.getSpec().getImage())
.withName("akces-command-service")
.withArgs(aggregate.getSpec().getArgs())
.editFirstEnv()
.withValue(aggregate.getSpec().getApplicationName())
.endEnv()
.withResources(aggregate.getSpec().getResources())
.endContainer()
.editFirstVolume()
.editConfigMap()
.withName(commandServiceName + "-config")
.endConfigMap()
.endVolume()
.endSpec()
.endTemplate()
⋮----
.build();

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/query/ConfigMapDependentResource.java
================
public class ConfigMapDependentResource extends CRUDKubernetesDependentResource<ConfigMap, QueryService> {
⋮----
protected ConfigMap desired(QueryService queryService, Context<QueryService> context) {
final ObjectMeta queryServiceMetadata = queryService.getMetadata();
final String queryServiceName = queryServiceMetadata.getName();
return new ConfigMapBuilder(ReconcilerUtils.loadYaml(ConfigMap.class, getClass(), "configmap.yaml"))
.editMetadata()
.withName(queryServiceName + "-config")
.withNamespace(queryServiceMetadata.getNamespace())
.addToLabels("app.kubernetes.io/part-of", queryServiceName)
.addToLabels("app.kubernetes.io/managed-by", "akces-operator")
.endMetadata()
.build();

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/query/QueryService.java
================
public class QueryService extends CustomResource<QueryServiceSpec, QueryServiceStatus> implements Namespaced {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/query/QueryServiceReconciler.java
================
public class QueryServiceReconciler implements Reconciler<QueryService> {
private final Logger log = LoggerFactory.getLogger(getClass());
⋮----
public UpdateControl<QueryService> reconcile(QueryService queryService, Context<QueryService> context) throws Exception {
return context.getSecondaryResource(StatefulSet.class).map(statefulSet -> {
QueryService updatedQueryService = createQueryServiceForStatusUpdate(queryService, statefulSet);
return UpdateControl.patchStatus(updatedQueryService);
}).orElseGet(UpdateControl::noUpdate);
⋮----
private QueryService createQueryServiceForStatusUpdate(QueryService queryService, StatefulSet statefulSet) {
QueryService res = new QueryService();
res.setMetadata(new ObjectMetaBuilder()
.withName(queryService.getMetadata().getName())
.withNamespace(queryService.getMetadata().getNamespace())
.build());
⋮----
Objects.requireNonNullElse(statefulSet.getStatus(), new StatefulSetStatus());
int readyReplicas = Objects.requireNonNullElse(statefulSetStatus.getReadyReplicas(), 0);
QueryServiceStatus status = new QueryServiceStatus();
status.setReadyReplicas(readyReplicas);
res.setStatus(status);

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/query/QueryServiceSpec.java
================
public class QueryServiceSpec {
⋮----
public Integer getReplicas() {
⋮----
public void setReplicas(Integer replicas) {
⋮----
public String getImage() {
⋮----
public void setImage(String image) {
⋮----
public List<String> getArgs() {
⋮----
public void setArgs(List<String> args) {
⋮----
public ResourceRequirements getResources() {
⋮----
public void setResources(ResourceRequirements resources) {
⋮----
public String getApplicationName() {
⋮----
public void setApplicationName(String applicationName) {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/query/QueryServiceStatus.java
================
public class QueryServiceStatus {
⋮----
public Integer getReadyReplicas() {
⋮----
public void setReadyReplicas(Integer readyReplicas) {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/query/ServiceDependentResource.java
================
public class ServiceDependentResource extends CRUDKubernetesDependentResource<Service, QueryService> {
⋮----
protected Service desired(QueryService queryService, Context<QueryService> context) {
final ObjectMeta queryServiceMetadata = queryService.getMetadata();
final String queryServiceName = queryServiceMetadata.getName();
return new ServiceBuilder(ReconcilerUtils.loadYaml(Service.class, getClass(), "service.yaml"))
.editMetadata()
.withName(queryServiceName + "-service")
.withNamespace(queryServiceMetadata.getNamespace())
.addToLabels("app.kubernetes.io/part-of", queryServiceName)
.addToLabels("app.kubernetes.io/managed-by", "akces-operator")
.endMetadata()
.editSpec()
.addToSelector("app", queryServiceMetadata.getName())
.endSpec()
.build();

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/query/StatefulSetDependentResource.java
================
public class StatefulSetDependentResource extends CRUDKubernetesDependentResource<StatefulSet, QueryService> {
⋮----
protected StatefulSet desired(QueryService queryService, Context<QueryService> context) {
StatefulSet statefulSet = ReconcilerUtils.loadYaml(StatefulSet.class, getClass(), "statefulset.yaml");
final ObjectMeta queryServiceMetadata = queryService.getMetadata();
final String queryServiceName = queryServiceMetadata.getName();
⋮----
statefulSet = new StatefulSetBuilder(statefulSet)
.editMetadata()
.withName(queryServiceName)
.withNamespace(queryServiceMetadata.getNamespace())
.addToLabels("app", queryServiceName)
.addToLabels("app.kubernetes.io/part-of", queryServiceName)
.addToLabels("app.kubernetes.io/managed-by", "akces-operator")
.endMetadata()
.editSpec()
.withServiceName(queryServiceName + "-service")
.editSelector().addToMatchLabels("app", queryServiceName).endSelector()
.withReplicas(queryService.getSpec().getReplicas())
.editTemplate()
.editMetadata().addToLabels("app", queryServiceName).endMetadata()
⋮----
.addToImagePullSecrets(new LocalObjectReference("github-packages-cfg"))
.editFirstContainer()
.withImage(queryService.getSpec().getImage())
.withName("akces-query-service")
.withArgs(queryService.getSpec().getArgs())
.editFirstEnv()
.withValue(queryService.getSpec().getApplicationName())
.endEnv()
.withResources(queryService.getSpec().getResources())
.endContainer()
.editFirstVolume()
.editConfigMap()
.withName(queryServiceName + "-config")
.endConfigMap()
.endVolume()
.endSpec()
.endTemplate()
.editFirstVolumeClaimTemplate()
⋮----
.withStorageClassName("akces-data-hyperdisk-balanced")
.editResources()
.withRequests(Map.of("storage", new Quantity("4Gi")))
.endResources()
⋮----
.endVolumeClaimTemplate()
⋮----
.build();

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/utils/KafkaTopicUtils.java
================
public class KafkaTopicUtils {
⋮----
public static List<NewTopic> createTopics(String topicName, int numPartitions) {
return List.of(
createTopic(topicName + COMMANDS_SUFFIX, numPartitions),
createTopic(topicName + DOMAINEVENTS_SUFFIX, numPartitions),
createCompactedTopic(topicName + AGGREGRATESTATE_SUFFIX, numPartitions)
⋮----
public static NewTopic createTopic(String name, int numPartitions) {
return createTopic(name, numPartitions, -1L);
⋮----
public static NewTopic createTopic(String name, int numPartitions, long retentionMs) {
NewTopic topic = new NewTopic(name, numPartitions, Short.parseShort("1"));
return topic.configs(Map.of(
⋮----
"retention.ms", Long.toString(retentionMs),
⋮----
public static NewTopic createCompactedTopic(String name, int numPartitions) {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/AkcesOperatorApplication.java
================
public class AkcesOperatorApplication {
⋮----
public static void main(String[] args) {
Security.setProperty("crypto.policy", "unlimited");
Security.insertProviderAt(new BouncyCastleProvider(), 1);
SpringApplication.run(AkcesOperatorApplication.class, args);

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/AkcesOperatorConfig.java
================
public class AkcesOperatorConfig {
⋮----
public KafkaAdmin kafkaAdmin(@Value(value = "${spring.kafka.bootstrap-servers}") String bootstrapServers) {
return new KafkaAdmin(Map.of(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers));
⋮----
public AggregateReconciler aggregateReconciler(KafkaAdmin kafkaAdmin) {
return new AggregateReconciler(kafkaAdmin);
⋮----
public CommandServiceReconciler commandServiceReconciler() {
return new CommandServiceReconciler();
⋮----
public QueryServiceReconciler queryServiceReconciler() {
return new QueryServiceReconciler();

================
File: services/operator/src/main/resources/META-INF/native-image/native-image.properties
================
#
# Copyright 2022 - 2025 The Original Authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
#     you may not use this file except in compliance with the License.
#     You may obtain a copy of the License at
#
#           http://www.apache.org/licenses/LICENSE-2.0
#
#     Unless required by applicable law or agreed to in writing, software
#     distributed under the License is distributed on an "AS IS" BASIS,
#     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#     See the License for the specific language governing permissions and
#     limitations under the License.
#
#
Args=--strict-image-heap

================
File: services/operator/src/main/resources/org/elasticsoftware/akces/operator/aggregate/configmap.yaml
================
apiVersion: v1
kind: ConfigMap
metadata:
  name: ""
data:
  application.properties: |
    # Spring application properties
    spring.application.name=${SPRING_APPLICATION_NAME}
    spring.kafka.enabled=true
    spring.kafka.bootstrap-servers=akces-kafka-bootstrap.kafka:9092
    spring.kafka.consumer.properties.session.timeout.ms=45000
    management.endpoint.health.probes.enabled=true
    management.health.livenessState.enabled=true
    management.health.readinessState.enabled=true
    server.shutdown=graceful
    spring.mvc.problemdetails.enabled=true
    akces.schemaregistry.url=http://akces-schema-registry.kafka:8081
    akces.rocksdb.baseDir=/var/lib/akces-data
    akces.aggregate.schemas.forceRegister=${ENABLE_SCHEMA_OVERWRITES}
  logback.xml: |
    <configuration>
        <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
            <layout class="ch.qos.logback.classic.PatternLayout">
                <Pattern>
                    %d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n
                </Pattern>
            </layout>
        </appender>

        <logger name="org.apache.kafka" level="warn" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <logger name="org.apache.kafka.clients.producer" level="warn" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <logger name="org.apache.kafka.clients.consumer" level="warn" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <logger name="org.apache.kafka.clients.NetworkClient" level="error" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <logger name="org.apache.kafka.clients.producer.internals.Sender" level="error" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <root level="info">
            <appender-ref ref="CONSOLE"/>
        </root>
    </configuration>

================
File: services/operator/src/main/resources/org/elasticsoftware/akces/operator/aggregate/service.yaml
================
apiVersion: v1
kind: Service
metadata:
  name: ""
spec:
  selector:
    app: ""
  ports:
    - protocol: TCP
      name: http
      port: 80
      targetPort: 8080
  type: ClusterIP

================
File: services/operator/src/main/resources/org/elasticsoftware/akces/operator/aggregate/statefulset.yaml
================
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: ""
  labels:
    app.kubernetes.io/part-of: ""
    app.kubernetes.io/managed-by: ""
spec:
  serviceName: ""
  replicas: 3
  podManagementPolicy: Parallel
  selector:
    matchLabels:
      app: ""
  template:
    metadata:
      labels:
        app: ""
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      containers:
        - name: akces-aggregate-service
          image: ""
          env:
            - name: SPRING_APPLICATION_NAME
              value: "Akces Aggregate Service"
            - name: SPRING_CONFIG_LOCATION
              value: "file:/config/application.properties"
            - name: LOGGING_CONFIG
              value: "file:/config/logback.xml"
            - name: BPL_JVM_THREAD_COUNT
              value: "100"
            - name: JAVA_TOOL_OPTIONS
              value: "-XX:+UseZGC -XX:+ZGenerational"
            - name: ENABLE_SCHEMA_OVERWRITES
              value: "false"
          lifecycle:
            preStop:
              exec:
                command: [ "/bin/sh", "-c", "sleep 15" ]
          ports:
            - containerPort: 8080
              name: http
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /actuator/health/readiness
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 1
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: actuator/health/liveness
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          volumeMounts:
            - name: config-volume
              mountPath: /config
            - name: akces-data
              mountPath: /var/lib/akces-data
              readOnly: false
      volumes:
        - name: config-volume
          configMap:
            name: ""
  volumeClaimTemplates:
    - metadata:
        name: akces-data
      spec:
        accessModes: [ "ReadWriteOnce" ]
        storageClassName: "akces-data-hyperdisk-balanced"
        resources:
          requests:
            storage: 4Gi

================
File: services/operator/src/main/resources/org/elasticsoftware/akces/operator/command/configmap.yaml
================
apiVersion: v1
kind: ConfigMap
metadata:
  name: ""
data:
  application.properties: |
    # Spring application properties
    spring.application.name=${SPRING_APPLICATION_NAME}
    spring.kafka.enabled=true
    spring.kafka.bootstrap-servers=akces-kafka-bootstrap.kafka:9092
    spring.kafka.consumer.properties.session.timeout.ms=45000
    management.endpoint.health.probes.enabled=true
    management.health.livenessState.enabled=true
    management.health.readinessState.enabled=true
    server.shutdown=graceful
    spring.mvc.problemdetails.enabled=true
    akces.schemaregistry.url=http://akces-schema-registry.kafka:8081
    akces.rocksdb.baseDir=/var/lib/akces-data
  logback.xml: |
    <configuration>
        <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
            <layout class="ch.qos.logback.classic.PatternLayout">
                <Pattern>
                    %d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n
                </Pattern>
            </layout>
        </appender>

        <logger name="org.apache.kafka" level="warn" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <logger name="org.apache.kafka.clients.producer" level="warn" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <logger name="org.apache.kafka.clients.consumer" level="warn" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <root level="info">
            <appender-ref ref="CONSOLE"/>
        </root>
    </configuration>

================
File: services/operator/src/main/resources/org/elasticsoftware/akces/operator/command/service.yaml
================
apiVersion: v1
kind: Service
metadata:
  name: ""
spec:
  selector:
    app: ""
  ports:
    - protocol: TCP
      name: http
      port: 80
      targetPort: 8080
  type: ClusterIP

================
File: services/operator/src/main/resources/org/elasticsoftware/akces/operator/command/statefulset.yaml
================
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: ""
  labels:
    app.kubernetes.io/part-of: ""
    app.kubernetes.io/managed-by: ""
spec:
  serviceName: ""
  replicas: 3
  podManagementPolicy: Parallel
  selector:
    matchLabels:
      app: ""
  template:
    metadata:
      labels:
        app: ""
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      containers:
        - name: akces-command-service
          image: ""
          env:
            - name: SPRING_APPLICATION_NAME
              value: "Akces Command Service"
            - name: SPRING_CONFIG_LOCATION
              value: "file:/config/application.properties"
            - name: LOGGING_CONFIG
              value: "file:/config/logback.xml"
            - name: BPL_JVM_THREAD_COUNT
              value: "100"
            - name: JAVA_TOOL_OPTIONS
              value: "-XX:+UseZGC -XX:+ZGenerational"
          lifecycle:
            preStop:
              exec:
                command: [ "/bin/sh", "-c", "sleep 10" ]
          ports:
            - containerPort: 8080
              name: http
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /actuator/health/readiness
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 1
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: actuator/health/liveness
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          volumeMounts:
            - name: config-volume
              mountPath: /config
      volumes:
        - name: config-volume
          configMap:
            name: ""

================
File: services/operator/src/main/resources/org/elasticsoftware/akces/operator/query/configmap.yaml
================
apiVersion: v1
kind: ConfigMap
metadata:
  name: ""
data:
  application.properties: |
    # Spring application properties
    spring.application.name=${SPRING_APPLICATION_NAME}
    spring.kafka.enabled=true
    spring.kafka.bootstrap-servers=akces-kafka-bootstrap.kafka:9092
    spring.kafka.consumer.properties.session.timeout.ms=45000
    management.endpoint.health.probes.enabled=true
    management.health.livenessState.enabled=true
    management.health.readinessState.enabled=true
    server.shutdown=graceful
    spring.mvc.problemdetails.enabled=true
    akces.schemaregistry.url=http://akces-schema-registry.kafka:8081
    akces.rocksdb.baseDir=/var/lib/akces-data
  logback.xml: |
    <configuration>
        <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
            <layout class="ch.qos.logback.classic.PatternLayout">
                <Pattern>
                    %d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n
                </Pattern>
            </layout>
        </appender>

        <logger name="org.apache.kafka" level="warn" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <logger name="org.apache.kafka.clients.producer" level="warn" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <logger name="org.apache.kafka.clients.consumer" level="warn" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <root level="info">
            <appender-ref ref="CONSOLE"/>
        </root>
    </configuration>

================
File: services/operator/src/main/resources/org/elasticsoftware/akces/operator/query/service.yaml
================
apiVersion: v1
kind: Service
metadata:
  name: ""
spec:
  selector:
    app: ""
  ports:
    - protocol: TCP
      name: http
      port: 80
      targetPort: 8080
  type: ClusterIP

================
File: services/operator/src/main/resources/org/elasticsoftware/akces/operator/query/statefulset.yaml
================
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: ""
  labels:
    app.kubernetes.io/part-of: ""
    app.kubernetes.io/managed-by: ""
spec:
  serviceName: ""
  replicas: 3
  podManagementPolicy: Parallel
  selector:
    matchLabels:
      app: ""
  template:
    metadata:
      labels:
        app: ""
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      containers:
        - name: akces-query-service
          image: ""
          env:
            - name: SPRING_APPLICATION_NAME
              value: "Akces Query Service"
            - name: SPRING_CONFIG_LOCATION
              value: "file:/config/application.properties"
            - name: LOGGING_CONFIG
              value: "file:/config/logback.xml"
            - name: BPL_JVM_THREAD_COUNT
              value: "100"
            - name: JAVA_TOOL_OPTIONS
              value: "-XX:+UseZGC -XX:+ZGenerational"
          lifecycle:
            preStop:
              exec:
                command: [ "/bin/sh", "-c", "sleep 10" ]
          ports:
            - containerPort: 8080
              name: http
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /actuator/health/readiness
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 1
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: actuator/health/liveness
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          volumeMounts:
            - name: config-volume
              mountPath: /config
            - name: akces-data
              mountPath: /var/lib/akces-data
              readOnly: false
      volumes:
        - name: config-volume
          configMap:
            name: ""
  volumeClaimTemplates:
    - metadata:
        name: akces-data
      spec:
        accessModes: [ "ReadWriteOnce" ]
        storageClassName: "akces-data-hyperdisk-balanced"
        resources:
          requests:
            storage: 4Gi

================
File: services/operator/src/main/resources/application.properties
================
#
# Copyright 2022 - 2025 The Original Authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
#     you may not use this file except in compliance with the License.
#     You may obtain a copy of the License at
#
#           http://www.apache.org/licenses/LICENSE-2.0
#
#     Unless required by applicable law or agreed to in writing, software
#     distributed under the License is distributed on an "AS IS" BASIS,
#     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#     See the License for the specific language governing permissions and
#     limitations under the License.
#
#
spring.application.name=Akces Operator
spring.kafka.bootstrap-servers=akces-kafka-bootstrap.kafka:9092
management.endpoint.health.probes.enabled=true
management.health.livenessState.enabled=true
management.health.readinessState.enabled=true
server.shutdown=graceful
javaoperatorsdk.crd.apply-on-startup=true

================
File: services/operator/src/main/resources/logback.xml
================
<?xml version="1.0" encoding="UTF-8"?>

















<configuration>

    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <layout class="ch.qos.logback.classic.PatternLayout">
            <Pattern>
                %d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n
            </Pattern>
        </layout>
    </appender>

    <logger name="org.apache.kafka" level="warn" additivity="false">
        <appender-ref ref="CONSOLE"/>
    </logger>

    <logger name="org.apache.kafka.clients.producer" level="warn" additivity="false">
        <appender-ref ref="CONSOLE"/>
    </logger>

    <logger name="org.apache.kafka.clients.consumer" level="warn" additivity="false">
        <appender-ref ref="CONSOLE"/>
    </logger>

    <root level="info">
        <appender-ref ref="CONSOLE"/>
    </root>

</configuration>

================
File: services/operator/src/test/java/org/elasticsoftware/akces/operator/AkcesOperatorApplicationTests.java
================
class AkcesOperatorApplicationTests {
⋮----
private static final Network network = Network.newNetwork();
⋮----
new KafkaContainer(DockerImageName.parse("confluentinc/cp-kafka:" + CONFLUENT_PLATFORM_VERSION))
.withKraft()
.withEnv("KAFKA_AUTO_CREATE_TOPICS_ENABLE", "false")
.withNetwork(network)
.withNetworkAliases("kafka");
⋮----
void contextLoads() {
assertThat(restTemplate).isNotNull();
assertThat(aggregateReconciler).isNotNull();
⋮----
void healthReadinessEndpointShouldBeEnabled() throws Exception {
assertThat(this.restTemplate.getForObject("http://localhost:" + port + "/actuator/health/readiness",
String.class)).contains("{\"status\":\"UP\"}");
⋮----
void healthLivenessEndpointShouldBeEnabled() throws Exception {
assertThat(this.restTemplate.getForObject("http://localhost:" + port + "/actuator/health/liveness",
⋮----
void testAggregateReconciliation() throws Exception {
Aggregate aggregate = new Aggregate();
aggregate.setMetadata(new ObjectMetaBuilder()
.withName("test-aggregate")
.withNamespace("akces")
.build());
aggregate.setSpec(new AggregateSpec());
aggregate.getSpec().setReplicas(3);
aggregate.getSpec().setImage("test-image");
aggregate.getSpec().setAggregateNames(List.of("Account", "OrderProcessManager", "Wallet"));
⋮----
Context<Aggregate> mockContext = mock(Context.class);
when(mockContext.getSecondaryResource(StatefulSet.class)).thenReturn(Optional.empty());
UpdateControl<Aggregate> updateControl = aggregateReconciler.reconcile(aggregate, mockContext);
⋮----
Map<String, TopicDescription> reconciledTopics = kafkaAdmin.describeTopics("Account-DomainEvents", "Account-Commands", "Account-AggregateState",
⋮----
assertThat(reconciledTopics).hasSize(9);
assertThat(reconciledTopics.get("Account-DomainEvents").partitions().size()).isEqualTo(3);
assertThat(reconciledTopics.get("Account-Commands").partitions().size()).isEqualTo(3);
assertThat(reconciledTopics.get("Account-AggregateState").partitions().size()).isEqualTo(3);
assertThat(reconciledTopics.get("OrderProcessManager-DomainEvents").partitions().size()).isEqualTo(3);
assertThat(reconciledTopics.get("OrderProcessManager-Commands").partitions().size()).isEqualTo(3);
assertThat(reconciledTopics.get("OrderProcessManager-AggregateState").partitions().size()).isEqualTo(3);
assertThat(reconciledTopics.get("Wallet-DomainEvents").partitions().size()).isEqualTo(3);
assertThat(reconciledTopics.get("Wallet-Commands").partitions().size()).isEqualTo(3);
assertThat(reconciledTopics.get("Wallet-AggregateState").partitions().size()).isEqualTo(3);
⋮----
void testCommandServiceReconciliation() throws Exception {
CommandService commandService = new CommandService();
commandService.setMetadata(new ObjectMetaBuilder()
.withName("test-command-service")
⋮----
commandService.setSpec(new CommandServiceSpec());
commandService.getSpec().setReplicas(3);
commandService.getSpec().setImage("test-image");
⋮----
Context<CommandService> mockContext = mock(Context.class);
⋮----
UpdateControl<CommandService> updateControl = commandServiceReconciler.reconcile(commandService, mockContext);
⋮----
assertThat(updateControl.isNoUpdate()).isTrue();
assertThat(updateControl.getResource().isPresent()).isFalse();
⋮----
void testQueryServiceReconciliation() throws Exception {
QueryService queryService = new QueryService();
queryService.setMetadata(new ObjectMetaBuilder()
.withName("test-query-service")
⋮----
queryService.setSpec(new QueryServiceSpec());
queryService.getSpec().setReplicas(3);
queryService.getSpec().setImage("test-image");
⋮----
Context<QueryService> mockContext = mock(Context.class);
⋮----
UpdateControl<QueryService> updateControl = queryServiceReconciler.reconcile(queryService, mockContext);
⋮----
public static class KafkaInitializer
⋮----
public void initialize(ConfigurableApplicationContext applicationContext) {
⋮----
KafkaAdmin kafkaAdmin = new KafkaAdmin(Map.of(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, kafka.getBootstrapServers()));
kafkaAdmin.createOrModifyTopics(
createCompactedTopic("Akces-Control", 3),
createTopic("Akces-CommandResponses", 3, 604800000L),
createCompactedTopic("Akces-GDPRKeys", 3)
⋮----
TestPropertySourceUtils.addInlinedPropertiesToEnvironment(
⋮----
"spring.kafka.bootstrap-servers=" + kafka.getBootstrapServers()

================
File: services/operator/pom.xml
================
<?xml version="1.0" encoding="UTF-8"?>

















<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>
    <parent>
        <groupId>org.elasticsoftwarefoundation.akces</groupId>
        <artifactId>akces-framework-services</artifactId>
        <version>0.8.1-SNAPSHOT</version>
    </parent>
    <artifactId>akces-operator</artifactId>
    <name>Elastic Software Foundation :: Akces :: Services :: Akces Operator</name>
    <description>Kubernetes Operator for the Akces Framework</description>
    <properties>
    </properties>
    <dependencies>
        <dependency>
            <groupId>io.javaoperatorsdk</groupId>
            <artifactId>operator-framework-spring-boot-starter</artifactId>
        </dependency>

        <dependency>
            <groupId>io.javaoperatorsdk</groupId>
            <artifactId>operator-framework-spring-boot-starter-test</artifactId>
            <scope>test</scope>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-actuator</artifactId>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-logging</artifactId>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-autoconfigure</artifactId>
        </dependency>

        <dependency>
            <groupId>org.springframework.kafka</groupId>
            <artifactId>spring-kafka</artifactId>
        </dependency>
        <dependency>
            <groupId>org.bouncycastle</groupId>
            <artifactId>bcprov-jdk18on</artifactId>
        </dependency>
        <dependency>
            <groupId>org.bouncycastle</groupId>
            <artifactId>bcpkix-jdk18on</artifactId>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-test</artifactId>
            <scope>test</scope>
        </dependency>

        <dependency>
            <groupId>org.testcontainers</groupId>
            <artifactId>junit-jupiter</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.mockito</groupId>
            <artifactId>mockito-core</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.testcontainers</groupId>
            <artifactId>kafka</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>io.javaoperatorsdk</groupId>
            <artifactId>operator-framework-junit-5</artifactId>
            <scope>test</scope>
        </dependency>
    </dependencies>

    <build>
        <plugins>
            <plugin>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-maven-plugin</artifactId>
            </plugin>
            <plugin>
                <groupId>io.fabric8</groupId>
                <artifactId>crd-generator-maven-plugin</artifactId>
                <executions>
                    <execution>
                        <id>generate-resources</id>
                        <configuration>
                            <outputDirectory>${project.basedir}/src/main/resources/META-INF/fabric8/</outputDirectory>
                        </configuration>
                        <goals>
                            <goal>generate</goal>
                        </goals>
                    </execution>
                    <execution>
                        <goals>
                            <goal>generate</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>
        </plugins>
    </build>

</project>

================
File: services/pom.xml
================
<?xml version="1.0" encoding="UTF-8"?>

















<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <parent>
        <groupId>org.elasticsoftwarefoundation.akces</groupId>
        <artifactId>akces-framework-parent</artifactId>
        <version>0.8.1-SNAPSHOT</version>
    </parent>
    <modelVersion>4.0.0</modelVersion>

    <artifactId>akces-framework-services</artifactId>
    <packaging>pom</packaging>

    <name>Elastic Software Foundation :: Akces :: Services</name>
    <url>https://github.com/elasticsoftwarefoundation/akces-framework</url>

    <properties>
        <operator-sdk.version>5.0.3</operator-sdk.version>
        <bouncycastle.version>1.80</bouncycastle.version>
        <fabric8.version>7.1.0</fabric8.version>
    </properties>

    <dependencyManagement>
        <dependencies>
            <dependency>
                <groupId>io.javaoperatorsdk</groupId>
                <artifactId>operator-framework-spring-boot-starter</artifactId>
                <version>6.0.0</version>
                <exclusions>
                    <exclusion>
                        <groupId>io.fabric8</groupId>
                        <artifactId>kubernetes-httpclient-vertx</artifactId>
                    </exclusion>
                </exclusions>
            </dependency>
            <dependency>
                <groupId>io.javaoperatorsdk</groupId>
                <artifactId>operator-framework-spring-boot-starter-test</artifactId>
                <version>6.0.0</version>
            </dependency>
            <dependency>
                <groupId>io.javaoperatorsdk</groupId>
                <artifactId>operator-framework-junit-5</artifactId>
                <version>${operator-sdk.version}</version>
            </dependency>
            <dependency>
                <groupId>io.javaoperatorsdk</groupId>
                <artifactId>operator-framework</artifactId>
                <version>${operator-sdk.version}</version>
            </dependency>
            <dependency>
                <groupId>io.fabric8</groupId>
                <artifactId>crd-generator-apt-v2</artifactId>
                <version>${fabric8.version}</version>
            </dependency>
            <dependency>
                <groupId>org.bouncycastle</groupId>
                <artifactId>bcprov-jdk18on</artifactId>
                <version>${bouncycastle.version}</version>
            </dependency>
            <dependency>
                <groupId>org.bouncycastle</groupId>
                <artifactId>bcpkix-jdk18on</artifactId>
                <version>${bouncycastle.version}</version>
            </dependency>
            <dependency>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-dependencies</artifactId>
                <version>${spring-boot.version}</version>
                <type>pom</type>
                <scope>import</scope>
            </dependency>
        </dependencies>
    </dependencyManagement>
    <modules>
        <module>operator</module>
    </modules>
    <build>
        <plugins>
            <plugin>

                <artifactId>maven-deploy-plugin</artifactId>
                <configuration>
                    <skip>true</skip>
                </configuration>
            </plugin>
        </plugins>
    </build>
    <profiles>
        <profile>
            <id>maven-release</id>
            <build>
                <plugins>
                    <plugin>
                        <groupId>org.springframework.boot</groupId>
                        <artifactId>spring-boot-maven-plugin</artifactId>
                        <configuration>
                            <docker>
                                <publishRegistry>
                                    <username>${env.GITHUB_ACTOR}</username>
                                    <password>${env.GITHUB_TOKEN}</password>
                                    <url>docker://ghcr.io</url>
                                </publishRegistry>
                            </docker>
                            <image>
                                <builder>docker.io/paketobuildpacks/builder-noble-java-tiny:latest</builder>
                                <runImage>docker.io/paketobuildpacks/run-noble-tiny:latest</runImage>
                                <name>ghcr.io/elasticsoftwarefoundation/${project.artifactId}:${project.version}</name>
                                <publish>true</publish>
                                <env>
                                    <BP_JVM_VERSION>${java.version}</BP_JVM_VERSION>
                                    <BP_JVM_JLINK_ENABLED>false</BP_JVM_JLINK_ENABLED>
                                </env>
                                <buildpacks>
                                    <buildpack>paketo-buildpacks/ca-certificates</buildpack>
                                    <buildpack>gcr.io/paketo-buildpacks/adoptium:latest</buildpack>
                                    <buildpack>paketo-buildpacks/syft</buildpack>
                                    <buildpack>paketo-buildpacks/executable-jar</buildpack>
                                    <buildpack>paketo-buildpacks/spring-boot</buildpack>
                                </buildpacks>
                            </image>
                        </configuration>
                    </plugin>
                </plugins>
            </build>
        </profile>
        <profile>
            <id>native</id>
            <build>
                <pluginManagement>
                    <plugins>
                        <plugin>
                            <groupId>org.apache.maven.plugins</groupId>
                            <artifactId>maven-jar-plugin</artifactId>
                            <configuration>
                                <archive>
                                    <manifestEntries>
                                        <Spring-Boot-Native-Processed>true</Spring-Boot-Native-Processed>
                                    </manifestEntries>
                                </archive>
                            </configuration>
                        </plugin>
                        <plugin>
                            <groupId>org.springframework.boot</groupId>
                            <artifactId>spring-boot-maven-plugin</artifactId>
                            <executions>
                                <execution>
                                    <id>process-aot</id>
                                    <goals>
                                        <goal>process-aot</goal>
                                    </goals>
                                </execution>
                            </executions>
                            <configuration>
                                <docker>
                                    <publishRegistry>
                                        <username>${env.GITHUB_ACTOR}</username>
                                        <password>${env.GITHUB_TOKEN}</password>
                                        <url>docker://ghcr.io</url>
                                    </publishRegistry>
                                </docker>
                                <image>
                                    <builder>docker.io/paketobuildpacks/builder-noble-java-tiny:latest</builder>
                                    <runImage>docker.io/paketobuildpacks/run-noble-tiny:latest</runImage>
                                    <name>ghcr.io/elasticsoftwarefoundation/${project.artifactId}:${project.version}
                                    </name>
                                    <publish>true</publish>
                                    <env>
                                        <BP_JVM_VERSION>${java.version}</BP_JVM_VERSION>
                                        <BP_JVM_JLINK_ENABLED>false</BP_JVM_JLINK_ENABLED>
                                    </env>
                                </image>
                            </configuration>
                        </plugin>
                        <plugin>
                            <groupId>org.graalvm.buildtools</groupId>
                            <artifactId>native-maven-plugin</artifactId>
                            <configuration>
                                <classesDirectory>${project.build.outputDirectory}</classesDirectory>
                                <requiredVersion>22.3</requiredVersion>
                            </configuration>
                            <executions>
                                <execution>
                                    <id>add-reachability-metadata</id>
                                    <goals>
                                        <goal>add-reachability-metadata</goal>
                                    </goals>
                                </execution>
                                <execution>
                                    <id>build-native</id>
                                    <goals>
                                        <goal>compile-no-fork</goal>
                                    </goals>
                                    <phase>package</phase>
                                </execution>
                            </executions>
                        </plugin>
                    </plugins>
                </pluginManagement>
            </build>
        </profile>
        <profile>
            <id>nativeTest</id>
            <dependencies>
                <dependency>
                    <groupId>org.junit.platform</groupId>
                    <artifactId>junit-platform-launcher</artifactId>
                    <scope>test</scope>
                </dependency>
            </dependencies>
            <build>
                <plugins>
                    <plugin>
                        <groupId>org.springframework.boot</groupId>
                        <artifactId>spring-boot-maven-plugin</artifactId>
                        <executions>
                            <execution>
                                <id>process-test-aot</id>
                                <goals>
                                    <goal>process-test-aot</goal>
                                </goals>
                            </execution>
                        </executions>
                    </plugin>
                    <plugin>
                        <groupId>org.graalvm.buildtools</groupId>
                        <artifactId>native-maven-plugin</artifactId>
                        <configuration>
                            <classesDirectory>${project.build.outputDirectory}</classesDirectory>
                            <requiredVersion>22.3</requiredVersion>
                        </configuration>
                        <executions>
                            <execution>
                                <id>native-test</id>
                                <goals>
                                    <goal>test</goal>
                                </goals>
                            </execution>
                        </executions>
                    </plugin>
                </plugins>
            </build>
        </profile>
    </profiles>
</project>

================
File: FRAMEWORK_OVERVIEW.md
================
# Akces Framework Comprehensive Overview

Akces is an event-sourcing and CQRS (Command Query Responsibility Segregation) framework built on top of Kafka. It provides a structured approach to building distributed, event-driven applications with a focus on domain events, aggregates, and command handling.

## Main Purpose

Akces provides a comprehensive solution for implementing event-sourcing-based applications. Its primary goal is to simplify building scalable, event-driven systems by providing:

1. A structured approach to defining domain models and handling commands
2. A robust event-sourcing mechanism for maintaining aggregate state
3. Support for distributed processing of commands and events
4. A query model system to support the "read side" of CQRS patterns
5. Privacy-focused data handling through GDPR-compliant encryption

## Key Features

### 1. Event Sourcing

Akces implements event sourcing patterns where the state of an aggregate is derived from a sequence of domain events. Key aspects include:

- Event storage in Kafka topics
- Automatic event application to update aggregate state
- Support for maintaining aggregate state in RocksDB
- Precise event versioning and schema validation

### 2. Command Processing

The framework provides a structured approach to command handling:

- Command validation and routing
- Transaction-based command processing
- Command response handling
- Error event generation for failed commands

### 3. Query Models

Separate from the command side, Akces provides:

- Query model state derived from events
- Database models for persistent storage 
- Support for JPA and JDBC implementations
- Event handlers for query models

### 4. GDPR Compliance

The framework includes built-in support for personal data protection:

- Annotation-based PII data marking
- Transparent encryption/decryption of sensitive data
- Context-aware encryption keys

### 5. Schema Registry Integration

For maintaining compatibility and validation:

- Integration with Confluent Schema Registry
- JSON schema generation and compatibility checking
- Schema versioning support

## Architecture

Akces has a modular architecture organized into the following components:

### Core Modules

1. **API Module**: Contains interfaces and annotations defining the core concepts
   - Aggregates, Commands, Events
   - Event handlers, Command handlers
   - Query models

2. **Runtime Module**: Provides the core event-sourcing implementation
   - Aggregate runtime for handling commands
   - State repositories and management
   - GDPR context management
   - Kafka integration

3. **Client Module**: Handles interaction with the command side
   - Command sending and validation
   - Schema registry integration
   - Command response processing

4. **Query-Support Module**: Handles query models and read-side concerns
   - Database model interaction
   - Query model state handling
   - Event processing for query models

5. **Shared Module**: Common utilities and shared classes
   - Protocol records for communication
   - Serialization/deserialization
   - GDPR utilities
   - Kafka utilities

### Key Components

1. **Aggregates**: The core domain objects that encapsulate business logic
   - Maintain their state through event sourcing
   - Process commands and emit events
   - Handle incoming domain events

2. **Commands**: Represent requests to modify state
   - Validated through schemas
   - Routed to appropriate aggregates
   - Generate domain events

3. **Domain Events**: Represent facts that have occurred
   - The source of truth for aggregate state
   - Used to rebuild state
   - Consumed by query models

4. **Query Models**: Read-optimized representations of data
   - Updated via event handlers
   - Provide fast access to application state

5. **Controllers**: Manage runtime and communication
   - `AkcesAggregateController`: Manages aggregate partitions and command handling
   - `AkcesDatabaseModelController`: Manages database models
   - `AkcesQueryModelController`: Manages query models
   - `AkcesClientController`: Client-side controller for sending commands

6. **Partitioning**: Ensures scalability
   - Kafka-based partitioning of aggregates
   - Command routing based on aggregate ID
   - Parallel processing across partitions

## Workflow

A typical workflow in Akces follows this pattern:

1. A client sends a command to modify an aggregate's state via the Akces client
2. The command is routed to the appropriate aggregate partition
3. The aggregate processes the command, generating one or more domain events
4. The events are stored in Kafka and applied to the aggregate state
5. Query models and database models consume the events to update their state
6. Command responses are sent back to clients

## Deployment Architecture

Akces is designed for distributed deployment with:

- Kafka as the communication and storage backbone
- RocksDB for local state storage
- Schema Registry for schema validation
- Different services for command and query sides

## Key Design Patterns

1. **Event Sourcing**: State is derived from events rather than stored directly
2. **CQRS**: Separate models for reading and writing
3. **Domain-Driven Design**: Focus on aggregates, commands, and events
4. **Partitioning**: Distribution of processing across multiple instances
5. **Annotation-based Configuration**: Using annotations to define behavior

## Technical Implementation

Akces relies on several key technologies:

- **Spring Framework**: For dependency injection and configuration
- **Kafka**: As the event store and messaging backbone
- **RocksDB**: For local state storage
- **Jackson**: For JSON serialization/deserialization
- **Protobuf**: For efficient binary serialization
- **Confluent Schema Registry**: For schema validation and evolution

The framework provides both a programming model (through annotations and interfaces) and a runtime environment for executing event-sourced applications.

## Conclusion

Akces is a comprehensive framework for building event-sourced, CQRS-based applications with a focus on scalability, resilience, and privacy. It provides a structured approach to domain modeling while handling the complex infrastructure concerns of distributed systems.

================
File: README.md
================
# Akces Framework

## Overview

Akces Framework is a robust CQRS (Command Query Responsibility Segregation) and Event Sourcing framework built on Apache Kafka. The framework provides a comprehensive infrastructure for building distributed, event-driven applications with a clean separation between command and query operations.

At its core, Akces implements the full event sourcing pattern, capturing all changes to application state as a sequence of events. These events can be replayed to reconstruct the state at any point in time, providing a complete audit trail and enabling powerful temporal queries.

The framework leverages Kafka's distributed architecture for reliable event storage and processing, making it highly scalable and resilient. It also provides built-in support for personal data protection (GDPR compliance), schema evolution, and efficient state management.

## Core Concepts

- **Aggregates**: Domain entities that encapsulate business logic and maintain state through events
- **Commands**: Requests to change the state of an aggregate
- **Domain Events**: Facts that have occurred, representing state changes
- **Command Handlers**: Process commands and produce events
- **Event Sourcing Handlers**: Apply events to update aggregate state
- **Query Models**: Read-optimized projections of aggregate state
- **Database Models**: Persistent storage of aggregate data

## Main Features

### Command Handling
- **Command Bus**: A distributed command bus for routing commands to appropriate aggregates
- **Command Validation**: Automatic schema validation using JSON Schema
- **Command Handlers**: Annotation-based command handling with automatic event publishing
- **Transaction Support**: Transactional processing of commands

### Event Sourcing
- **Event Store**: Kafka-based event store for persisting all domain events
- **Event Handlers**: Annotation-based event handling for processing domain events
- **Event Sourcing Handlers**: Automatic state reconstruction from domain events
- **Event Bridging**: Bridge events between different aggregates

### Aggregate Management
- **Aggregate Runtimes**: Lifecycle management for aggregates
- **State Management**: Efficient state storage using RocksDB
- **Partitioning**: Automatic partitioning of aggregates across nodes for scalability
- **Event Indexing**: Automatic indexing of events for efficient querying

### Query Support
- **Query Models**: Build specialized read models from domain events
- **Database Models**: Automatically sync data to databases for efficient querying
- **Materialized Views**: Build and maintain materialized views of aggregate state
- **State Hydration**: Efficiently load and cache query model state

### Privacy & GDPR Support
- **PII Data Handling**: Built-in support for Personal Identifiable Information (PII)
- **Data Encryption**: Transparent encryption/decryption of sensitive data
- **Annotation-based PII Marking**: Easy identification of sensitive fields
- **Key Management**: Secure management of encryption keys

### Schema Management
- **Schema Evolution**: Support for evolving schemas with backward compatibility
- **Schema Registry Integration**: Works with Confluent Schema Registry for schema management
- **Schema Validation**: Automatic validation of commands and events against their schemas
- **Schema Compatibility Checks**: Ensure backward compatibility of schema changes

## Architecture

The framework consists of several modules:

- **api**: Core interfaces and annotations defining the framework's programming model
- **shared**: Common utilities, serialization, and GDPR support
- **runtime**: The runtime environment for aggregates, including command handling and event sourcing
- **client**: Client library for interacting with aggregate services
- **query-support**: Support for query models and database models

## Setup Instructions

### Prerequisites

- Java 17 or higher
- Apache Kafka 3.x
- Confluent Schema Registry
- Maven 3.6+

### Maven Dependencies

Add the following to your `pom.xml`:

```xml
<dependency>
    <groupId>org.elasticsoftwarefoundation.akces</groupId>
    <artifactId>akces-api</artifactId>
    <version>0.8.1</version>
</dependency>

<dependency>
    <groupId>org.elasticsoftwarefoundation.akces</groupId>
    <artifactId>akces-client</artifactId>
    <version>0.8.1</version>
</dependency>

<!-- For running aggregates -->
<dependency>
    <groupId>org.elasticsoftwarefoundation.akces</groupId>
    <artifactId>akces-runtime</artifactId>
    <version>0.8.1</version>
</dependency>

<!-- For query models -->
<dependency>
    <groupId>org.elasticsoftwarefoundation.akces</groupId>
    <artifactId>akces-query-support</artifactId>
    <version>0.8.1</version>
</dependency>
```

### Configuration

Create an `application.yaml` file with the following configuration:

```yaml
spring:
  kafka:
    bootstrap-servers: localhost:9092
    consumer:
      enable-auto-commit: false
      isolation-level: read_committed
      max-poll-records: 500
      heartbeat-interval: 2000
      auto-offset-reset: latest
      properties:
        max.poll.interval.ms: 10000
        session.timeout.ms: 30000
        partition.assignment.strategy: org.apache.kafka.clients.consumer.CooperativeStickyAssignor
    producer:
      acks: all
      retries: 2147483647
      properties:
        enable.idempotence: true
        max.in.flight.requests.per.connection: 1

akces:
  schemaregistry:
    url: http://localhost:8081
  rocksdb:
    baseDir: /tmp/akces
```

## Usage Examples

### Define an Aggregate

```java
@AggregateInfo(value = "Wallet", version = 1, generateGDPRKeyOnCreate = true, indexed = true, indexName = "Wallets")
public final class Wallet implements Aggregate<WalletState> {
    @Override
    public Class<WalletState> getStateClass() {
        return WalletState.class;
    }

    @CommandHandler(create = true, produces = {WalletCreatedEvent.class, BalanceCreatedEvent.class})
    public Stream<DomainEvent> create(CreateWalletCommand cmd, WalletState isNull) {
        return Stream.of(new WalletCreatedEvent(cmd.id()), new BalanceCreatedEvent(cmd.id(), cmd.currency()));
    }

    @EventSourcingHandler(create = true)
    public WalletState create(WalletCreatedEvent event, WalletState isNull) {
        return new WalletState(event.id(), new ArrayList<>());
    }
    
    @EventSourcingHandler
    public WalletState createBalance(BalanceCreatedEvent event, WalletState state) {
        List<WalletState.Balance> balances = new ArrayList<>(state.balances());
        balances.add(new WalletState.Balance(event.currency(), BigDecimal.ZERO));
        return new WalletState(state.id(), balances);
    }
    
    @CommandHandler(produces = {WalletCreditedEvent.class, InvalidAmountErrorEvent.class, InvalidCurrencyErrorEvent.class})
    public Stream<DomainEvent> credit(CreditWalletCommand cmd, WalletState currentState) {
        WalletState.Balance balance = currentState.balances().stream()
                .filter(b -> b.currency().equals(cmd.currency()))
                .findFirst().orElse(null);
                
        if (balance == null) {
            return Stream.of(new InvalidCurrencyErrorEvent(cmd.id(), cmd.currency()));
        }
        
        if (cmd.amount().compareTo(BigDecimal.ZERO) < 0) {
            return Stream.of(new InvalidAmountErrorEvent(cmd.id(), cmd.currency()));
        }
        
        return Stream.of(new WalletCreditedEvent(currentState.id(), cmd.currency(), cmd.amount(), 
                balance.amount().add(cmd.amount())));
    }
}
```

### Define an Aggregate State

```java
public record WalletState(String id, List<Balance> balances) implements AggregateState {
    @Override
    public String getAggregateId() {
        return id();
    }

    public record Balance(String currency, BigDecimal amount, BigDecimal reservedAmount) {
        public Balance(String currency, BigDecimal amount) {
            this(currency, amount, BigDecimal.ZERO);
        }

        public BigDecimal getAvailableAmount() {
            return amount.subtract(reservedAmount);
        }
    }
}
```

### Create Commands

```java
@CommandInfo(type = "CreateWallet", version = 1)
public record CreateWalletCommand(@AggregateIdentifier @NotNull String id, 
                                  @NotNull String currency) implements Command {
    @Override
    public String getAggregateId() {
        return id();
    }
}

@CommandInfo(type = "CreditWallet", version = 1)
public record CreditWalletCommand(@AggregateIdentifier @NotNull String id,
                                 @NotNull String currency,
                                 @NotNull BigDecimal amount) implements Command {
    @Override
    public String getAggregateId() {
        return id();
    }
}
```

### Create Events

```java
@DomainEventInfo(type = "WalletCreated", version = 1)
public record WalletCreatedEvent(@AggregateIdentifier @NotNull String id) implements DomainEvent {
    @Override
    public String getAggregateId() {
        return id();
    }
}

@DomainEventInfo(type = "BalanceCreated", version = 1)
public record BalanceCreatedEvent(@AggregateIdentifier @NotNull String id, 
                                 @NotNull String currency) implements DomainEvent {
    @Override
    public String getAggregateId() {
        return id();
    }
}

@DomainEventInfo(type = "WalletCredited", version = 1)
public record WalletCreditedEvent(@AggregateIdentifier @NotNull String id,
                                 @NotNull String currency,
                                 @NotNull BigDecimal amount,
                                 @NotNull BigDecimal newBalance) implements DomainEvent {
    @Override
    public String getAggregateId() {
        return id();
    }
}
```

### Error Events

```java
@DomainEventInfo(type = "InvalidCurrencyError", version = 1)
public record InvalidCurrencyErrorEvent(@AggregateIdentifier @NotNull String walletId,
                                       @NotNull String currency) implements ErrorEvent {
    @Override
    public String getAggregateId() {
        return walletId();
    }
}

@DomainEventInfo(type = "InvalidAmountError", version = 1)
public record InvalidAmountErrorEvent(@AggregateIdentifier @NotNull String walletId,
                                     @NotNull String currency) implements ErrorEvent {
    @Override
    public String getAggregateId() {
        return walletId();
    }
}
```

### Sending Commands

```java
@Autowired
private AkcesClient akcesClient;

public void createWallet() {
    String walletId = UUID.randomUUID().toString();
    CreateWalletCommand command = new CreateWalletCommand(walletId, "USD");
    
    // Send command and get events synchronously
    List<DomainEvent> events = akcesClient.send("DEFAULT_TENANT", command)
        .toCompletableFuture()
        .join();
    
    // Or send command asynchronously
    akcesClient.sendAndForget("DEFAULT_TENANT", command);
}

public void creditWallet(String walletId, String currency, BigDecimal amount) {
    CreditWalletCommand command = new CreditWalletCommand(walletId, currency, amount);
    
    try {
        List<DomainEvent> events = akcesClient.send("DEFAULT_TENANT", command)
            .toCompletableFuture()
            .join();
            
        // Check if we received an error event
        if (events.stream().anyMatch(event -> event instanceof ErrorEvent)) {
            ErrorEvent error = (ErrorEvent) events.stream()
                .filter(event -> event instanceof ErrorEvent)
                .findFirst()
                .orElse(null);
            // Handle error
        }
    } catch (Exception e) {
        // Handle exceptions (validation errors, connectivity issues, etc.)
    }
}
```

### Create a Query Model

```java
@QueryModelInfo(value = "WalletQuery", version = 1, indexName = "Wallets")
public class WalletQueryModel implements QueryModel<WalletQueryModelState> {
    @Override
    public Class<WalletQueryModelState> getStateClass() {
        return WalletQueryModelState.class;
    }
    
    @Override
    public String getIndexName() {
        return "Wallets";
    }

    @QueryModelEventHandler(create = true)
    public WalletQueryModelState create(WalletCreatedEvent event, WalletQueryModelState isNull) {
        return new WalletQueryModelState(event.id(), List.of());
    }
    
    @QueryModelEventHandler
    public WalletQueryModelState createBalance(BalanceCreatedEvent event, WalletQueryModelState currentState) {
        WalletQueryModelState.Balance balance = new WalletQueryModelState.Balance(event.currency(), BigDecimal.ZERO);
        List<WalletQueryModelState.Balance> balances = new ArrayList<>(currentState.balances());
        balances.add(balance);
        return new WalletQueryModelState(currentState.walletId(), balances);
    }
    
    @QueryModelEventHandler
    public WalletQueryModelState creditWallet(WalletCreditedEvent event, WalletQueryModelState currentState) {
        return new WalletQueryModelState(
                currentState.walletId(),
                currentState.balances().stream().map(balance -> {
                    if (balance.currency().equals(event.currency())) {
                        return new WalletQueryModelState.Balance(
                                balance.currency(),
                                balance.amount().add(event.amount()),
                                balance.reservedAmount()
                        );
                    }
                    return balance;
                }).toList());
    }
}

public record WalletQueryModelState(String walletId, List<Balance> balances) implements QueryModelState {
    @Override
    public String getIndexKey() {
        return walletId();
    }
    
    public record Balance(String currency, BigDecimal amount, BigDecimal reservedAmount) {
        public Balance(String currency, BigDecimal amount) {
            this(currency, amount, BigDecimal.ZERO);
        }
        
        public BigDecimal getAvailableAmount() {
            return amount.subtract(reservedAmount);
        }
    }
}
```

### Query a Model

```java
@Autowired
private QueryModels queryModels;

public WalletQueryModelState getWallet(String walletId) {
    return queryModels.getHydratedState(WalletQueryModel.class, walletId)
        .toCompletableFuture()
        .join();
}

public void displayWalletBalances(String walletId) {
    try {
        WalletQueryModelState wallet = queryModels.getHydratedState(WalletQueryModel.class, walletId)
            .toCompletableFuture()
            .get(5, TimeUnit.SECONDS);
            
        wallet.balances().forEach(balance -> {
            System.out.printf("Currency: %s, Amount: %s, Available: %s%n", 
                balance.currency(), 
                balance.amount().toPlainString(), 
                balance.getAvailableAmount().toPlainString());
        });
    } catch (QueryModelIdNotFoundException e) {
        System.out.println("Wallet not found: " + e.getModelId());
    } catch (Exception e) {
        System.out.println("Error retrieving wallet: " + e.getMessage());
    }
}
```

### Create a Database Model

```java
@DatabaseModelInfo(value = "WalletDatabase", version = 1)
public class WalletDatabaseModel extends JdbcDatabaseModel {
    @DatabaseModelEventHandler
    public void handle(WalletCreatedEvent event) {
        jdbcTemplate.update("""
            INSERT INTO wallets (wallet_id, created_date) 
            VALUES (?, NOW())
            """, 
            event.id());
    }
    
    @DatabaseModelEventHandler
    public void handle(BalanceCreatedEvent event) {
        jdbcTemplate.update("""
            INSERT INTO wallet_balances (wallet_id, currency, amount) 
            VALUES (?, ?, ?)
            """, 
            event.id(), event.currency(), 0.00);
    }
    
    @DatabaseModelEventHandler
    public void handle(WalletCreditedEvent event) {
        jdbcTemplate.update("""
            UPDATE wallet_balances
            SET amount = ?
            WHERE wallet_id = ? AND currency = ?
            """,
            event.newBalance(), event.id(), event.currency());
    }
}
```

## GDPR and PII Data

The framework provides built-in support for Personal Identifiable Information (PII):

```java
@AggregateStateInfo(value = "AccountState", version = 1)
public record AccountState(@AggregateIdentifier String userId, 
                          String country, 
                          @PIIData String firstName, 
                          @PIIData String lastName, 
                          @PIIData String email) implements AggregateState {
    @Override
    public String getAggregateId() {
        return userId();
    }
}
```

PII data is automatically encrypted when stored and decrypted when retrieved. The encryption is transparent to the application code.

## Process Managers

Akces also supports process managers for coordinating complex workflows across multiple aggregates:

```java
@AggregateInfo(value = "OrderProcessManager", version = 1)
public class OrderProcessManager implements ProcessManager<OrderProcessManagerState, OrderProcess> {
    @Override
    public Class<OrderProcessManagerState> getStateClass() {
        return OrderProcessManagerState.class;
    }
    
    @EventHandler(create = true)
    public Stream<UserOrderProcessesCreatedEvent> create(AccountCreatedEvent event, OrderProcessManagerState isNull) {
        return Stream.of(new UserOrderProcessesCreatedEvent(event.userId()));
    }
    
    @CommandHandler
    public Stream<BuyOrderCreatedEvent> placeBuyOrder(PlaceBuyOrderCommand command, OrderProcessManagerState state) {
        String orderId = UUID.randomUUID().toString();
        // Start a multi-step process
        getCommandBus().send(new ReserveAmountCommand(
                state.userId(),
                command.market().quoteCurrency(),
                command.quantity().multiply(command.limitPrice()),
                orderId));
        
        return Stream.of(new BuyOrderCreatedEvent(
                state.userId(),
                orderId,
                command.market(),
                command.quantity(),
                command.limitPrice(),
                command.clientReference()));
    }
    
    @EventHandler
    public Stream<DomainEvent> handle(AmountReservedEvent event, OrderProcessManagerState state) {
        OrderProcess orderProcess = state.getAkcesProcess(event.referenceId());
        
        if (orderProcess instanceof BuyOrderProcess) {
            return Stream.of(new BuyOrderPlacedEvent(
                    state.userId(), 
                    orderProcess.orderId(), 
                    orderProcess.market(), 
                    orderProcess.quantity(), 
                    orderProcess.limitPrice()));
        }
        
        return Stream.empty();
    }
    
    @EventHandler
    public Stream<DomainEvent> handle(InsufficientFundsErrorEvent errorEvent, OrderProcessManagerState state) {
        return Stream.of(state.getAkcesProcess(errorEvent.referenceId()).handle(errorEvent));
    }
}
```

## Running the Framework

### Aggregate Service

```java
@SpringBootApplication
public class AggregateServiceApplication {
    public static void main(String[] args) {
        SpringApplication.run(AggregateServiceApplication.class, args);
    }
}
```

### Query Service

```java
@SpringBootApplication
public class QueryServiceApplication {
    public static void main(String[] args) {
        SpringApplication.run(QueryServiceApplication.class, args);
    }
}
```

### Client Application

```java
@SpringBootApplication
public class ClientApplication {
    public static void main(String[] args) {
        SpringApplication.run(ClientApplication.class, args);
    }
    
    @Bean
    public CommandLineRunner commandLineRunner(AkcesClient akcesClient) {
        return args -> {
            // Create a new wallet
            String walletId = UUID.randomUUID().toString();
            CreateWalletCommand createCommand = new CreateWalletCommand(walletId, "USD");
            
            List<DomainEvent> createEvents = akcesClient.send(createCommand)
                .toCompletableFuture()
                .join();
                
            System.out.println("Wallet created: " + walletId);
            
            // Credit the wallet
            CreditWalletCommand creditCommand = new CreditWalletCommand(walletId, "USD", new BigDecimal("1000.00"));
            
            List<DomainEvent> creditEvents = akcesClient.send(creditCommand)
                .toCompletableFuture()
                .join();
                
            System.out.println("Wallet credited: " + walletId);
        };
    }
}
```

## Benefits of Using Akces Framework

- **Scalability**: Built on Kafka for horizontal scalability across distributed nodes
- **Reliability**: Event sourcing ensures data integrity and provides complete audit trails
- **Flexibility**: Clean separation of commands and queries following CQRS principles
- **Performance**: Efficient state management with RocksDB and optimized query models
- **Security**: Built-in support for data privacy and GDPR compliance
- **Evolution**: Schema evolution with backward compatibility checks
- **Developer Experience**: Intuitive annotation-based programming model
- **Observability**: Transparent view of all commands and events flowing through the system
- **Temporal Queries**: Ability to reconstruct state at any point in time

## License

Apache License 2.0

================
File: RELEASE.md
================
## Release process

This project uses the Maven Release Plugin and GitHub Actions to create releases.\
Just run `mvn release:prepare release:perform && git push` in the root to select the version to be released and create a
VCS tag.

GitHub Actions will
start [the build process](https://github.com/elasticsoftwarefoundation/akces-framework/actions/workflows/maven-publish.yml).

If successful, the build will be automatically published
to [Github Packages](https://maven.pkg.github.com/elasticsoftwarefoundation/akces-framework/).



================================================================
End of Codebase
================================================================

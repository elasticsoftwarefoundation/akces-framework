This file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.
The content has been processed where comments have been removed, content has been compressed (code blocks are separated by ⋮---- delimiter).

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: *.md, services/**/*.java, services/**/*.xml, services/**/*.properties, services/**/*.proto, services/**/*.imports, services/**/*.yaml
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Code comments have been removed from supported file types
- Content has been compressed - code blocks are separated by ⋮---- delimiter
- Files are sorted by Git change count (files with more changes are at the bottom)

Additional Info:
----------------

================================================================
Directory Structure
================================================================
services/
  operator/
    src/
      main/
        java/
          org/
            elasticsoftware/
              akces/
                operator/
                  aggregate/
                    Aggregate.java
                    AggregateReconciler.java
                    AggregateSpec.java
                    AggregateStatus.java
                    ConfigMapDependentResource.java
                    ServiceDependentResource.java
                    StatefulSetDependentResource.java
                  command/
                    CommandService.java
                    CommandServiceReconciler.java
                    CommandServiceSpec.java
                    CommandServiceStatus.java
                    ConfigMapDependentResource.java
                    ServiceDependentResource.java
                    StatefulSetDependentResource.java
                  query/
                    ConfigMapDependentResource.java
                    QueryService.java
                    QueryServiceReconciler.java
                    QueryServiceSpec.java
                    QueryServiceStatus.java
                    ServiceDependentResource.java
                    StatefulSetDependentResource.java
                  utils/
                    KafkaTopicUtils.java
                  AkcesOperatorApplication.java
                  AkcesOperatorConfig.java
        resources/
          META-INF/
            native-image/
              native-image.properties
          org/
            elasticsoftware/
              akces/
                operator/
                  aggregate/
                    configmap.yaml
                    service.yaml
                    statefulset.yaml
                  command/
                    configmap.yaml
                    service.yaml
                    statefulset.yaml
                  query/
                    configmap.yaml
                    service.yaml
                    statefulset.yaml
          application.properties
          logback.xml
      test/
        java/
          org/
            elasticsoftware/
              akces/
                operator/
                  AkcesOperatorApplicationTests.java
    pom.xml
  pom.xml
FRAMEWORK_OVERVIEW.md
README.md
RELEASE.md
SERVICES.md
TEST-APPS.md

================================================================
Files
================================================================

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/aggregate/Aggregate.java
================
public class Aggregate extends CustomResource<AggregateSpec, AggregateStatus> implements Namespaced {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/aggregate/AggregateReconciler.java
================
public class AggregateReconciler implements Reconciler<Aggregate> {
private final Logger log = LoggerFactory.getLogger(getClass());
⋮----
public void init() {
partitions = kafkaAdmin.describeTopics("Akces-Control").get("Akces-Control").partitions().size();
log.info("Found Akces-Control Topic with {} partitions", partitions);
⋮----
public UpdateControl<Aggregate> reconcile(Aggregate resource, Context<Aggregate> context) throws Exception {
reconcileTopics(resource.getSpec().getAggregateNames());
return context.getSecondaryResource(StatefulSet.class).map(statefulSet -> {
Aggregate updatedAggregate = createAggregateForStatusUpdate(resource, statefulSet);
log.info(
⋮----
resource.getMetadata().getName(),
resource.getMetadata().getNamespace(),
resource.getStatus() == null ? 0 : resource.getStatus().getReadyReplicas());
return UpdateControl.patchStatus(updatedAggregate);
}).orElseGet(UpdateControl::noUpdate);
⋮----
private Aggregate createAggregateForStatusUpdate(Aggregate tomcat, StatefulSet statefulSet) {
Aggregate res = new Aggregate();
res.setMetadata(new ObjectMetaBuilder()
.withName(tomcat.getMetadata().getName())
.withNamespace(tomcat.getMetadata().getNamespace())
.build());
⋮----
Objects.requireNonNullElse(statefulSet.getStatus(), new StatefulSetStatus());
int readyReplicas = Objects.requireNonNullElse(statefulSetStatus.getReadyReplicas(), 0);
AggregateStatus status = new AggregateStatus();
status.setReadyReplicas(readyReplicas);
res.setStatus(status);
⋮----
private void reconcileTopics(List<String> aggregateNames) {
log.info("Reconciling topics for Aggregates: {}", aggregateNames);
List<NewTopic> topics = aggregateNames.stream()
.map(name -> KafkaTopicUtils.createTopics(name, partitions))
.flatMap(List::stream).toList();
kafkaAdmin.createOrModifyTopics(topics.toArray(new NewTopic[0]));

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/aggregate/AggregateSpec.java
================
public class AggregateSpec {
⋮----
public List<String> getAggregateNames() {
⋮----
public void setAggregateNames(List<String> aggregateNames) {
⋮----
public Integer getReplicas() {
⋮----
public void setReplicas(Integer replicas) {
⋮----
public String getImage() {
⋮----
public void setImage(String image) {
⋮----
public List<String> getArgs() {
⋮----
public void setArgs(List<String> args) {
⋮----
public ResourceRequirements getResources() {
⋮----
public void setResources(ResourceRequirements resources) {
⋮----
public Boolean getEnableSchemaOverwrites() {
⋮----
public void setEnableSchemaOverwrites(Boolean enableSchemaOverwrites) {
⋮----
public String getApplicationName() {
⋮----
public void setApplicationName(String applicationName) {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/aggregate/AggregateStatus.java
================
public class AggregateStatus {
⋮----
public Integer getReadyReplicas() {
⋮----
public void setReadyReplicas(Integer readyReplicas) {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/aggregate/ConfigMapDependentResource.java
================
public class ConfigMapDependentResource extends CRUDKubernetesDependentResource<ConfigMap, Aggregate> {
⋮----
protected ConfigMap desired(Aggregate aggregate, Context<Aggregate> context) {
final ObjectMeta aggregateMetadata = aggregate.getMetadata();
final String aggregateName = aggregateMetadata.getName();
return new ConfigMapBuilder(ReconcilerUtils.loadYaml(ConfigMap.class, getClass(), "configmap.yaml"))
.editMetadata()
.withName(aggregateName + "-config")
.withNamespace(aggregateMetadata.getNamespace())
.addToLabels("app.kubernetes.io/part-of", aggregateName)
.addToLabels("app.kubernetes.io/managed-by", "akces-operator")
.endMetadata()
.build();

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/aggregate/ServiceDependentResource.java
================
public class ServiceDependentResource extends CRUDKubernetesDependentResource<Service, Aggregate> {
⋮----
protected Service desired(Aggregate aggregate, Context<Aggregate> context) {
final ObjectMeta aggregateMetadata = aggregate.getMetadata();
final String aggregateName = aggregateMetadata.getName();
return new ServiceBuilder(ReconcilerUtils.loadYaml(Service.class, getClass(), "service.yaml"))
.editMetadata()
.withName(aggregateName + "-service")
.withNamespace(aggregateMetadata.getNamespace())
.addToLabels("app.kubernetes.io/part-of", aggregateName)
.addToLabels("app.kubernetes.io/managed-by", "akces-operator")
.endMetadata()
.editSpec()
.addToSelector("app", aggregateMetadata.getName())
.endSpec()
.build();

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/aggregate/StatefulSetDependentResource.java
================
public class StatefulSetDependentResource extends CRUDKubernetesDependentResource<StatefulSet, Aggregate> {
⋮----
protected StatefulSet desired(Aggregate aggregate, Context<Aggregate> context) {
StatefulSet statefulSet = ReconcilerUtils.loadYaml(StatefulSet.class, getClass(), "statefulset.yaml");
final ObjectMeta aggregateMetadata = aggregate.getMetadata();
final String aggregateName = aggregateMetadata.getName();
⋮----
statefulSet = new StatefulSetBuilder(statefulSet)
.editMetadata()
.withName(aggregateName)
.withNamespace(aggregateMetadata.getNamespace())
.addToLabels("app", aggregateName)
.addToLabels("app.kubernetes.io/part-of", aggregateName)
.addToLabels("app.kubernetes.io/managed-by", "akces-operator")
.endMetadata()
.editSpec()
.withServiceName(aggregateName + "-service")
.editSelector().addToMatchLabels("app", aggregateName).endSelector()
.withReplicas(aggregate.getSpec().getReplicas())
.editTemplate()
.editMetadata().addToLabels("app", aggregateName).endMetadata()
⋮----
.addToImagePullSecrets(new LocalObjectReference("github-packages-cfg"))
.editFirstContainer()
.withImage(aggregate.getSpec().getImage())
.withName("akces-aggregate-service")
.withArgs(aggregate.getSpec().getArgs())
.editFirstEnv()
.withValue(aggregate.getSpec().getApplicationName())
.endEnv()
.editLastEnv()
.withValue(aggregate.getSpec().getEnableSchemaOverwrites().toString())
⋮----
.withResources(aggregate.getSpec().getResources())
.endContainer()
.editFirstVolume()
.editConfigMap()
.withName(aggregateName + "-config")
.endConfigMap()
.endVolume()
.endSpec()
.endTemplate()
.editFirstVolumeClaimTemplate()
⋮----
.withStorageClassName("akces-data-hyperdisk-balanced")
.editResources()
.withRequests(Map.of("storage", new Quantity("4Gi")))
.endResources()
⋮----
.endVolumeClaimTemplate()
⋮----
.build();

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/command/CommandService.java
================
public class CommandService extends CustomResource<CommandServiceSpec, CommandServiceStatus> implements Namespaced {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/command/CommandServiceReconciler.java
================
public class CommandServiceReconciler implements Reconciler<CommandService> {
private final Logger log = LoggerFactory.getLogger(getClass());
⋮----
public UpdateControl<CommandService> reconcile(CommandService commandService, Context<CommandService> context) throws Exception {
return context.getSecondaryResource(StatefulSet.class).map(statefulSet -> {
CommandService updatedCommandService = createCommandServiceForStatusUpdate(commandService, statefulSet);
return UpdateControl.patchStatus(updatedCommandService);
}).orElseGet(UpdateControl::noUpdate);
⋮----
private CommandService createCommandServiceForStatusUpdate(CommandService commandService, StatefulSet statefulSet) {
CommandService res = new CommandService();
res.setMetadata(new ObjectMetaBuilder()
.withName(commandService.getMetadata().getName())
.withNamespace(commandService.getMetadata().getNamespace())
.build());
⋮----
Objects.requireNonNullElse(statefulSet.getStatus(), new StatefulSetStatus());
int readyReplicas = Objects.requireNonNullElse(statefulSetStatus.getReadyReplicas(), 0);
CommandServiceStatus status = new CommandServiceStatus();
status.setReadyReplicas(readyReplicas);
res.setStatus(status);

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/command/CommandServiceSpec.java
================
public class CommandServiceSpec {
⋮----
public Integer getReplicas() {
⋮----
public void setReplicas(Integer replicas) {
⋮----
public String getImage() {
⋮----
public void setImage(String image) {
⋮----
public List<String> getArgs() {
⋮----
public void setArgs(List<String> args) {
⋮----
public ResourceRequirements getResources() {
⋮----
public void setResources(ResourceRequirements resources) {
⋮----
public String getApplicationName() {
⋮----
public void setApplicationName(String applicationName) {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/command/CommandServiceStatus.java
================
public class CommandServiceStatus {
⋮----
public Integer getReadyReplicas() {
⋮----
public void setReadyReplicas(Integer readyReplicas) {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/command/ConfigMapDependentResource.java
================
public class ConfigMapDependentResource extends CRUDKubernetesDependentResource<ConfigMap, CommandService> {
⋮----
protected ConfigMap desired(CommandService commandService, Context<CommandService> context) {
final ObjectMeta metadata = commandService.getMetadata();
final String commandServiceName = metadata.getName();
return new ConfigMapBuilder(ReconcilerUtils.loadYaml(ConfigMap.class, getClass(), "configmap.yaml"))
.editMetadata()
.withName(commandServiceName + "-config")
.withNamespace(metadata.getNamespace())
.addToLabels("app.kubernetes.io/part-of", commandServiceName)
.addToLabels("app.kubernetes.io/managed-by", "akces-operator")
.endMetadata()
.build();

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/command/ServiceDependentResource.java
================
public class ServiceDependentResource extends CRUDKubernetesDependentResource<Service, CommandService> {
⋮----
protected Service desired(CommandService commandService, Context<CommandService> context) {
final ObjectMeta metadata = commandService.getMetadata();
final String commandServiceName = metadata.getName();
return new ServiceBuilder(ReconcilerUtils.loadYaml(Service.class, getClass(), "service.yaml"))
.editMetadata()
.withName(commandServiceName + "-service")
.withNamespace(metadata.getNamespace())
.addToLabels("app.kubernetes.io/part-of", commandServiceName)
.addToLabels("app.kubernetes.io/managed-by", "akces-operator")
.endMetadata()
.editSpec()
.addToSelector("app", metadata.getName())
.endSpec()
.build();

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/command/StatefulSetDependentResource.java
================
public class StatefulSetDependentResource extends CRUDKubernetesDependentResource<StatefulSet, CommandService> {
⋮----
protected StatefulSet desired(CommandService aggregate, Context<CommandService> context) {
StatefulSet statefulSet = ReconcilerUtils.loadYaml(StatefulSet.class, getClass(), "statefulset.yaml");
final ObjectMeta metadata = aggregate.getMetadata();
final String commandServiceName = metadata.getName();
⋮----
statefulSet = new StatefulSetBuilder(statefulSet)
.editMetadata()
.withName(commandServiceName)
.withNamespace(metadata.getNamespace())
.addToLabels("app", commandServiceName)
.addToLabels("app.kubernetes.io/part-of", commandServiceName)
.addToLabels("app.kubernetes.io/managed-by", "akces-operator")
.endMetadata()
.editSpec()
.withServiceName(commandServiceName + "-service")
.editSelector().addToMatchLabels("app", commandServiceName).endSelector()
.withReplicas(aggregate.getSpec().getReplicas())
.editTemplate()
.editMetadata().addToLabels("app", commandServiceName).endMetadata()
⋮----
.addToImagePullSecrets(new LocalObjectReference("github-packages-cfg"))
.editFirstContainer()
.withImage(aggregate.getSpec().getImage())
.withName("akces-command-service")
.withArgs(aggregate.getSpec().getArgs())
.editFirstEnv()
.withValue(aggregate.getSpec().getApplicationName())
.endEnv()
.withResources(aggregate.getSpec().getResources())
.endContainer()
.editFirstVolume()
.editConfigMap()
.withName(commandServiceName + "-config")
.endConfigMap()
.endVolume()
.endSpec()
.endTemplate()
⋮----
.build();

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/query/QueryService.java
================
public class QueryService extends CustomResource<QueryServiceSpec, QueryServiceStatus> implements Namespaced {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/query/QueryServiceReconciler.java
================
public class QueryServiceReconciler implements Reconciler<QueryService> {
private final Logger log = LoggerFactory.getLogger(getClass());
⋮----
public UpdateControl<QueryService> reconcile(QueryService queryService, Context<QueryService> context) throws Exception {
return context.getSecondaryResource(StatefulSet.class).map(statefulSet -> {
QueryService updatedQueryService = createQueryServiceForStatusUpdate(queryService, statefulSet);
return UpdateControl.patchStatus(updatedQueryService);
}).orElseGet(UpdateControl::noUpdate);
⋮----
private QueryService createQueryServiceForStatusUpdate(QueryService queryService, StatefulSet statefulSet) {
QueryService res = new QueryService();
res.setMetadata(new ObjectMetaBuilder()
.withName(queryService.getMetadata().getName())
.withNamespace(queryService.getMetadata().getNamespace())
.build());
⋮----
Objects.requireNonNullElse(statefulSet.getStatus(), new StatefulSetStatus());
int readyReplicas = Objects.requireNonNullElse(statefulSetStatus.getReadyReplicas(), 0);
QueryServiceStatus status = new QueryServiceStatus();
status.setReadyReplicas(readyReplicas);
res.setStatus(status);

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/query/QueryServiceStatus.java
================
public class QueryServiceStatus {
⋮----
public Integer getReadyReplicas() {
⋮----
public void setReadyReplicas(Integer readyReplicas) {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/query/ServiceDependentResource.java
================
public class ServiceDependentResource extends CRUDKubernetesDependentResource<Service, QueryService> {
⋮----
protected Service desired(QueryService queryService, Context<QueryService> context) {
final ObjectMeta queryServiceMetadata = queryService.getMetadata();
final String queryServiceName = queryServiceMetadata.getName();
return new ServiceBuilder(ReconcilerUtils.loadYaml(Service.class, getClass(), "service.yaml"))
.editMetadata()
.withName(queryServiceName + "-service")
.withNamespace(queryServiceMetadata.getNamespace())
.addToLabels("app.kubernetes.io/part-of", queryServiceName)
.addToLabels("app.kubernetes.io/managed-by", "akces-operator")
.endMetadata()
.editSpec()
.addToSelector("app", queryServiceMetadata.getName())
.endSpec()
.build();

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/utils/KafkaTopicUtils.java
================
public class KafkaTopicUtils {
⋮----
public static List<NewTopic> createTopics(String topicName, int numPartitions) {
return List.of(
createTopic(topicName + COMMANDS_SUFFIX, numPartitions),
createTopic(topicName + DOMAINEVENTS_SUFFIX, numPartitions),
createCompactedTopic(topicName + AGGREGRATESTATE_SUFFIX, numPartitions)
⋮----
public static NewTopic createTopic(String name, int numPartitions) {
return createTopic(name, numPartitions, -1L);
⋮----
public static NewTopic createTopic(String name, int numPartitions, long retentionMs) {
NewTopic topic = new NewTopic(name, numPartitions, Short.parseShort("1"));
return topic.configs(Map.of(
⋮----
"retention.ms", Long.toString(retentionMs),
⋮----
public static NewTopic createCompactedTopic(String name, int numPartitions) {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/AkcesOperatorApplication.java
================
public class AkcesOperatorApplication {
⋮----
public static void main(String[] args) {
Security.setProperty("crypto.policy", "unlimited");
Security.insertProviderAt(new BouncyCastleProvider(), 1);
SpringApplication.run(AkcesOperatorApplication.class, args);

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/AkcesOperatorConfig.java
================
public class AkcesOperatorConfig {
⋮----
public KafkaAdmin kafkaAdmin(@Value(value = "${spring.kafka.bootstrap-servers}") String bootstrapServers) {
return new KafkaAdmin(Map.of(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers));
⋮----
public AggregateReconciler aggregateReconciler(KafkaAdmin kafkaAdmin) {
return new AggregateReconciler(kafkaAdmin);
⋮----
public CommandServiceReconciler commandServiceReconciler() {
return new CommandServiceReconciler();
⋮----
public QueryServiceReconciler queryServiceReconciler() {
return new QueryServiceReconciler();

================
File: services/operator/src/main/resources/META-INF/native-image/native-image.properties
================
#
# Copyright 2022 - 2025 The Original Authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
#     you may not use this file except in compliance with the License.
#     You may obtain a copy of the License at
#
#           http://www.apache.org/licenses/LICENSE-2.0
#
#     Unless required by applicable law or agreed to in writing, software
#     distributed under the License is distributed on an "AS IS" BASIS,
#     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#     See the License for the specific language governing permissions and
#     limitations under the License.
#
#
Args=--strict-image-heap

================
File: services/operator/src/main/resources/org/elasticsoftware/akces/operator/aggregate/service.yaml
================
apiVersion: v1
kind: Service
metadata:
  name: ""
spec:
  selector:
    app: ""
  ports:
    - protocol: TCP
      name: http
      port: 80
      targetPort: 8080
  type: ClusterIP

================
File: services/operator/src/main/resources/org/elasticsoftware/akces/operator/aggregate/statefulset.yaml
================
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: ""
  labels:
    app.kubernetes.io/part-of: ""
    app.kubernetes.io/managed-by: ""
spec:
  serviceName: ""
  replicas: 3
  podManagementPolicy: Parallel
  selector:
    matchLabels:
      app: ""
  template:
    metadata:
      labels:
        app: ""
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      containers:
        - name: akces-aggregate-service
          image: ""
          env:
            - name: SPRING_APPLICATION_NAME
              value: "Akces Aggregate Service"
            - name: SPRING_CONFIG_LOCATION
              value: "file:/config/application.properties"
            - name: LOGGING_CONFIG
              value: "file:/config/logback.xml"
            - name: BPL_JVM_THREAD_COUNT
              value: "100"
            - name: JAVA_TOOL_OPTIONS
              value: "-XX:+UseZGC -XX:+ZGenerational"
            - name: ENABLE_SCHEMA_OVERWRITES
              value: "false"
          lifecycle:
            preStop:
              exec:
                command: [ "/bin/sh", "-c", "sleep 15" ]
          ports:
            - containerPort: 8080
              name: http
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /actuator/health/readiness
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 1
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: actuator/health/liveness
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          volumeMounts:
            - name: config-volume
              mountPath: /config
            - name: akces-data
              mountPath: /var/lib/akces-data
              readOnly: false
      volumes:
        - name: config-volume
          configMap:
            name: ""
  volumeClaimTemplates:
    - metadata:
        name: akces-data
      spec:
        accessModes: [ "ReadWriteOnce" ]
        storageClassName: "akces-data-hyperdisk-balanced"
        resources:
          requests:
            storage: 4Gi

================
File: services/operator/src/main/resources/org/elasticsoftware/akces/operator/command/configmap.yaml
================
apiVersion: v1
kind: ConfigMap
metadata:
  name: ""
data:
  application.properties: |
    # Spring application properties
    spring.application.name=${SPRING_APPLICATION_NAME}
    spring.kafka.enabled=true
    spring.kafka.bootstrap-servers=akces-kafka-bootstrap.kafka:9092
    spring.kafka.consumer.properties.session.timeout.ms=45000
    management.endpoint.health.probes.enabled=true
    management.health.livenessState.enabled=true
    management.health.readinessState.enabled=true
    server.shutdown=graceful
    spring.mvc.problemdetails.enabled=true
    akces.schemaregistry.url=http://akces-schema-registry.kafka:8081
    akces.rocksdb.baseDir=/var/lib/akces-data
  logback.xml: |
    <configuration>
        <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
            <layout class="ch.qos.logback.classic.PatternLayout">
                <Pattern>
                    %d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n
                </Pattern>
            </layout>
        </appender>

        <logger name="org.apache.kafka" level="warn" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <logger name="org.apache.kafka.clients.producer" level="warn" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <logger name="org.apache.kafka.clients.consumer" level="warn" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <root level="info">
            <appender-ref ref="CONSOLE"/>
        </root>
    </configuration>

================
File: services/operator/src/main/resources/org/elasticsoftware/akces/operator/command/service.yaml
================
apiVersion: v1
kind: Service
metadata:
  name: ""
spec:
  selector:
    app: ""
  ports:
    - protocol: TCP
      name: http
      port: 80
      targetPort: 8080
  type: ClusterIP

================
File: services/operator/src/main/resources/org/elasticsoftware/akces/operator/command/statefulset.yaml
================
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: ""
  labels:
    app.kubernetes.io/part-of: ""
    app.kubernetes.io/managed-by: ""
spec:
  serviceName: ""
  replicas: 3
  podManagementPolicy: Parallel
  selector:
    matchLabels:
      app: ""
  template:
    metadata:
      labels:
        app: ""
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      containers:
        - name: akces-command-service
          image: ""
          env:
            - name: SPRING_APPLICATION_NAME
              value: "Akces Command Service"
            - name: SPRING_CONFIG_LOCATION
              value: "file:/config/application.properties"
            - name: LOGGING_CONFIG
              value: "file:/config/logback.xml"
            - name: BPL_JVM_THREAD_COUNT
              value: "100"
            - name: JAVA_TOOL_OPTIONS
              value: "-XX:+UseZGC -XX:+ZGenerational"
          lifecycle:
            preStop:
              exec:
                command: [ "/bin/sh", "-c", "sleep 10" ]
          ports:
            - containerPort: 8080
              name: http
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /actuator/health/readiness
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 1
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: actuator/health/liveness
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          volumeMounts:
            - name: config-volume
              mountPath: /config
      volumes:
        - name: config-volume
          configMap:
            name: ""

================
File: services/operator/src/main/resources/org/elasticsoftware/akces/operator/query/service.yaml
================
apiVersion: v1
kind: Service
metadata:
  name: ""
spec:
  selector:
    app: ""
  ports:
    - protocol: TCP
      name: http
      port: 80
      targetPort: 8080
  type: ClusterIP

================
File: services/operator/src/main/resources/application.properties
================
#
# Copyright 2022 - 2025 The Original Authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
#     you may not use this file except in compliance with the License.
#     You may obtain a copy of the License at
#
#           http://www.apache.org/licenses/LICENSE-2.0
#
#     Unless required by applicable law or agreed to in writing, software
#     distributed under the License is distributed on an "AS IS" BASIS,
#     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#     See the License for the specific language governing permissions and
#     limitations under the License.
#
#
spring.application.name=Akces Operator
spring.kafka.bootstrap-servers=akces-kafka-bootstrap.kafka:9092
management.endpoint.health.probes.enabled=true
management.health.livenessState.enabled=true
management.health.readinessState.enabled=true
server.shutdown=graceful
javaoperatorsdk.crd.apply-on-startup=true

================
File: services/operator/src/main/resources/logback.xml
================
<?xml version="1.0" encoding="UTF-8"?>

















<configuration>

    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <layout class="ch.qos.logback.classic.PatternLayout">
            <Pattern>
                %d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n
            </Pattern>
        </layout>
    </appender>

    <logger name="org.apache.kafka" level="warn" additivity="false">
        <appender-ref ref="CONSOLE"/>
    </logger>

    <logger name="org.apache.kafka.clients.producer" level="warn" additivity="false">
        <appender-ref ref="CONSOLE"/>
    </logger>

    <logger name="org.apache.kafka.clients.consumer" level="warn" additivity="false">
        <appender-ref ref="CONSOLE"/>
    </logger>

    <root level="info">
        <appender-ref ref="CONSOLE"/>
    </root>

</configuration>

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/query/ConfigMapDependentResource.java
================
public class ConfigMapDependentResource extends CRUDKubernetesDependentResource<ConfigMap, QueryService> {
⋮----
protected ConfigMap desired(QueryService queryService, Context<QueryService> context) {
final ObjectMeta queryServiceMetadata = queryService.getMetadata();
final String queryServiceName = queryServiceMetadata.getName();
final QueryServiceSpec spec = queryService.getSpec();
return new ConfigMapBuilder(ReconcilerUtils.loadYaml(ConfigMap.class, getClass(), "configmap.yaml"))
.editMetadata()
.withName(queryServiceName + "-config")
.withNamespace(queryServiceMetadata.getNamespace())
.addToLabels("app.kubernetes.io/part-of", queryServiceName)
.addToLabels("app.kubernetes.io/managed-by", "akces-operator")
.endMetadata()
.addToData(spec.getApplicationProperties() != null ?
Map.of("application.properties", spec.getApplicationProperties()) :
Collections.emptyMap())
.build();

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/query/QueryServiceSpec.java
================
public class QueryServiceSpec {
⋮----
public Integer getReplicas() {
⋮----
public void setReplicas(Integer replicas) {
⋮----
public String getImage() {
⋮----
public void setImage(String image) {
⋮----
public List<String> getArgs() {
return args != null ? args : Collections.emptyList();
⋮----
public void setArgs(List<String> args) {
⋮----
public ResourceRequirements getResources() {
⋮----
public void setResources(ResourceRequirements resources) {
⋮----
public String getApplicationName() {
⋮----
public void setApplicationName(String applicationName) {
⋮----
public List<EnvVar> getEnv() {
return env != null ? env : Collections.emptyList();
⋮----
public void setEnv(List<EnvVar> env) {
⋮----
public String getApplicationProperties() {
⋮----
public void setApplicationProperties(String applicationProperties) {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/query/StatefulSetDependentResource.java
================
public class StatefulSetDependentResource extends CRUDKubernetesDependentResource<StatefulSet, QueryService> {
⋮----
protected StatefulSet desired(QueryService queryService, Context<QueryService> context) {
StatefulSet statefulSet = ReconcilerUtils.loadYaml(StatefulSet.class, getClass(), "statefulset.yaml");
final ObjectMeta queryServiceMetadata = queryService.getMetadata();
final String queryServiceName = queryServiceMetadata.getName();
⋮----
statefulSet = new StatefulSetBuilder(statefulSet)
.editMetadata()
.withName(queryServiceName)
.withNamespace(queryServiceMetadata.getNamespace())
.addToLabels("app", queryServiceName)
.addToLabels("app.kubernetes.io/part-of", queryServiceName)
.addToLabels("app.kubernetes.io/managed-by", "akces-operator")
.endMetadata()
.editSpec()
.withServiceName(queryServiceName + "-service")
.editSelector().addToMatchLabels("app", queryServiceName).endSelector()
.withReplicas(queryService.getSpec().getReplicas())
.editTemplate()
.editMetadata().addToLabels("app", queryServiceName).endMetadata()
⋮----
.addToImagePullSecrets(new LocalObjectReference("github-packages-cfg"))
.editFirstContainer()
.withImage(queryService.getSpec().getImage())
.withName("akces-query-service")
.withArgs(queryService.getSpec().getArgs())
.editFirstEnv()
.withValue(queryService.getSpec().getApplicationName())
.endEnv()
.addToEnv(queryService.getSpec().getEnv().toArray(new EnvVar[0]))
.withResources(queryService.getSpec().getResources())
.endContainer()
.editFirstVolume()
.editConfigMap()
.withName(queryServiceName + "-config")
.endConfigMap()
.endVolume()
.endSpec()
.endTemplate()
.editFirstVolumeClaimTemplate()
⋮----
.withStorageClassName("akces-data-hyperdisk-balanced")
.editResources()
.withRequests(Map.of("storage", new Quantity("4Gi")))
.endResources()
⋮----
.endVolumeClaimTemplate()
⋮----
.build();

================
File: services/operator/src/main/resources/org/elasticsoftware/akces/operator/aggregate/configmap.yaml
================
apiVersion: v1
kind: ConfigMap
metadata:
  name: ""
data:
  application.properties: |
    # Spring application properties
    spring.application.name=${SPRING_APPLICATION_NAME}
    spring.kafka.enabled=true
    spring.kafka.bootstrap-servers=akces-kafka-bootstrap.kafka:9092
    spring.kafka.consumer.properties.session.timeout.ms=45000
    management.endpoint.health.probes.enabled=true
    management.health.livenessState.enabled=true
    management.health.readinessState.enabled=true
    server.shutdown=graceful
    spring.mvc.problemdetails.enabled=true
    akces.schemaregistry.url=http://akces-schema-registry.kafka:8081
    akces.rocksdb.baseDir=/var/lib/akces-data
    akces.aggregate.schemas.forceRegister=${ENABLE_SCHEMA_OVERWRITES}
  logback.xml: |
    <configuration>
        <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
            <layout class="ch.qos.logback.classic.PatternLayout">
                <Pattern>
                    %d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n
                </Pattern>
            </layout>
        </appender>

        <logger name="org.apache.kafka" level="warn" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <logger name="org.apache.kafka.clients.producer" level="warn" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <logger name="org.apache.kafka.clients.consumer" level="warn" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <logger name="org.apache.kafka.clients.NetworkClient" level="error" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <logger name="org.apache.kafka.clients.producer.internals.Sender" level="error" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <root level="info">
            <appender-ref ref="CONSOLE"/>
        </root>
    </configuration>

================
File: services/operator/src/main/resources/org/elasticsoftware/akces/operator/query/configmap.yaml
================
apiVersion: v1
kind: ConfigMap
metadata:
  name: ""
data:
  application-default.properties: |
    # Spring application properties
    spring.application.name=${SPRING_APPLICATION_NAME}
    spring.kafka.enabled=true
    spring.kafka.bootstrap-servers=akces-kafka-bootstrap.kafka:9092
    spring.kafka.consumer.properties.session.timeout.ms=45000
    management.endpoint.health.probes.enabled=true
    management.health.livenessState.enabled=true
    management.health.readinessState.enabled=true
    server.shutdown=graceful
    spring.mvc.problemdetails.enabled=true
    akces.schemaregistry.url=http://akces-schema-registry.kafka:8081
    akces.rocksdb.baseDir=/var/lib/akces-data
  logback.xml: |
    <configuration>
        <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
            <layout class="ch.qos.logback.classic.PatternLayout">
                <Pattern>
                    %d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n
                </Pattern>
            </layout>
        </appender>

        <logger name="org.apache.kafka" level="warn" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <logger name="org.apache.kafka.clients.producer" level="warn" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <logger name="org.apache.kafka.clients.consumer" level="warn" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <root level="info">
            <appender-ref ref="CONSOLE"/>
        </root>
    </configuration>

================
File: services/operator/src/test/java/org/elasticsoftware/akces/operator/AkcesOperatorApplicationTests.java
================
class AkcesOperatorApplicationTests {
⋮----
private static final Network network = Network.newNetwork();
⋮----
new KafkaContainer(DockerImageName.parse("confluentinc/cp-kafka:" + CONFLUENT_PLATFORM_VERSION))
.withKraft()
.withEnv("KAFKA_AUTO_CREATE_TOPICS_ENABLE", "false")
.withNetwork(network)
.withNetworkAliases("kafka");
⋮----
void contextLoads() {
assertThat(restTemplate).isNotNull();
assertThat(aggregateReconciler).isNotNull();
⋮----
void healthReadinessEndpointShouldBeEnabled() throws Exception {
assertThat(this.restTemplate.getForObject("http://localhost:" + port + "/actuator/health/readiness",
String.class)).contains("{\"status\":\"UP\"}");
⋮----
void healthLivenessEndpointShouldBeEnabled() throws Exception {
assertThat(this.restTemplate.getForObject("http://localhost:" + port + "/actuator/health/liveness",
⋮----
void testAggregateReconciliation() throws Exception {
Aggregate aggregate = new Aggregate();
aggregate.setMetadata(new ObjectMetaBuilder()
.withName("test-aggregate")
.withNamespace("akces")
.build());
aggregate.setSpec(new AggregateSpec());
aggregate.getSpec().setReplicas(3);
aggregate.getSpec().setImage("test-image");
aggregate.getSpec().setAggregateNames(List.of("Account", "OrderProcessManager", "Wallet"));
⋮----
Context<Aggregate> mockContext = mock(Context.class);
when(mockContext.getSecondaryResource(StatefulSet.class)).thenReturn(Optional.empty());
UpdateControl<Aggregate> updateControl = aggregateReconciler.reconcile(aggregate, mockContext);
⋮----
Map<String, TopicDescription> reconciledTopics = kafkaAdmin.describeTopics("Account-DomainEvents", "Account-Commands", "Account-AggregateState",
⋮----
assertThat(reconciledTopics).hasSize(9);
assertThat(reconciledTopics.get("Account-DomainEvents").partitions().size()).isEqualTo(3);
assertThat(reconciledTopics.get("Account-Commands").partitions().size()).isEqualTo(3);
assertThat(reconciledTopics.get("Account-AggregateState").partitions().size()).isEqualTo(3);
assertThat(reconciledTopics.get("OrderProcessManager-DomainEvents").partitions().size()).isEqualTo(3);
assertThat(reconciledTopics.get("OrderProcessManager-Commands").partitions().size()).isEqualTo(3);
assertThat(reconciledTopics.get("OrderProcessManager-AggregateState").partitions().size()).isEqualTo(3);
assertThat(reconciledTopics.get("Wallet-DomainEvents").partitions().size()).isEqualTo(3);
assertThat(reconciledTopics.get("Wallet-Commands").partitions().size()).isEqualTo(3);
assertThat(reconciledTopics.get("Wallet-AggregateState").partitions().size()).isEqualTo(3);
⋮----
void testCommandServiceReconciliation() throws Exception {
CommandService commandService = new CommandService();
commandService.setMetadata(new ObjectMetaBuilder()
.withName("test-command-service")
⋮----
commandService.setSpec(new CommandServiceSpec());
commandService.getSpec().setReplicas(3);
commandService.getSpec().setImage("test-image");
⋮----
Context<CommandService> mockContext = mock(Context.class);
⋮----
UpdateControl<CommandService> updateControl = commandServiceReconciler.reconcile(commandService, mockContext);
⋮----
assertThat(updateControl.isNoUpdate()).isTrue();
assertThat(updateControl.getResource().isPresent()).isFalse();
⋮----
void testQueryServiceReconciliation() throws Exception {
QueryService queryService = new QueryService();
queryService.setMetadata(new ObjectMetaBuilder()
.withName("test-query-service")
⋮----
queryService.setSpec(new QueryServiceSpec());
queryService.getSpec().setReplicas(3);
queryService.getSpec().setImage("test-image");
⋮----
Context<QueryService> mockContext = mock(Context.class);
⋮----
UpdateControl<QueryService> updateControl = queryServiceReconciler.reconcile(queryService, mockContext);
⋮----
public static class KafkaInitializer
⋮----
public void initialize(ConfigurableApplicationContext applicationContext) {
⋮----
KafkaAdmin kafkaAdmin = new KafkaAdmin(Map.of(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, kafka.getBootstrapServers()));
kafkaAdmin.createOrModifyTopics(
createCompactedTopic("Akces-Control", 3),
createTopic("Akces-CommandResponses", 3, 604800000L),
createCompactedTopic("Akces-GDPRKeys", 3)
⋮----
TestPropertySourceUtils.addInlinedPropertiesToEnvironment(
⋮----
"spring.kafka.bootstrap-servers=" + kafka.getBootstrapServers()

================
File: RELEASE.md
================
## Release process

This project uses the Maven Release Plugin and GitHub Actions to create releases.\
Just run `mvn release:prepare release:perform && git push` in the root to select the version to be released and create a
VCS tag.

GitHub Actions will
start [the build process](https://github.com/elasticsoftwarefoundation/akces-framework/actions/workflows/maven-publish.yml).

If successful, the build will be automatically published
to [Github Packages](https://maven.pkg.github.com/elasticsoftwarefoundation/akces-framework/).

================
File: SERVICES.md
================
# Akces Framework Services

## Overview

The Akces Framework provides a set of specialized services that implement the CQRS (Command Query Responsibility Segregation) and Event Sourcing patterns using Apache Kafka as the underlying infrastructure. This document describes the main services in the framework and how they interact to form a complete event-driven architecture.

## Core Services Architecture

The Akces Framework consists of three main service types that work together:

1. **Command Services** - Handle commands and validate business logic
2. **Aggregate Services** - Maintain event-sourced state for domain entities
3. **Query Services** - Provide optimized read models for client applications

These services are managed by the Akces Operator, a Kubernetes operator that automates the deployment, scaling, and management of the Akces services in a Kubernetes environment.

## Akces Operator

The Akces Operator is a Kubernetes operator built using the Java Operator SDK that manages the lifecycle of Akces Framework services in a Kubernetes cluster.

### Features

- Automated deployment of Command, Aggregate, and Query services
- Kafka topic management (creation and configuration)
- State management for deployed services
- Resource scaling based on workload
- Configuration management

### Custom Resources

The operator defines three Custom Resource Definitions (CRDs):

#### 1. Aggregate

The Aggregate custom resource defines an Aggregate service that maintains the state of domain entities using event sourcing.

```yaml
apiVersion: akces.elasticsoftware.org/v1
kind: Aggregate
metadata:
  name: account-aggregate
spec:
  replicas: 3
  image: ghcr.io/elasticsoftwarefoundation/akces-aggregate-service:0.9.0
  aggregateNames:
    - Account
    - OrderProcessManager
    - Wallet
  applicationName: "Akces Account Aggregate Service"
  enableSchemaOverwrites: false
  args:
    - "--spring.profiles.active=prod"
  resources:
    requests:
      memory: "512Mi"
      cpu: "500m"
    limits:
      memory: "1Gi"
      cpu: "1000m"
```

#### 2. CommandService

The CommandService custom resource defines a Command service that validates and processes commands before sending them to the appropriate aggregate.

```yaml
apiVersion: akces.elasticsoftware.org/v1
kind: CommandService
metadata:
  name: account-command
spec:
  replicas: 3
  image: ghcr.io/elasticsoftwarefoundation/akces-command-service:0.9.0
  applicationName: "Akces Account Command Service"
  args:
    - "--spring.profiles.active=prod"
  resources:
    requests:
      memory: "512Mi"
      cpu: "500m"
    limits:
      memory: "1Gi"
      cpu: "1000m"
```

#### 3. QueryService

The QueryService custom resource defines a Query service that provides optimized read models for client applications.

```yaml
apiVersion: akces.elasticsoftware.org/v1
kind: QueryService
metadata:
  name: account-query
spec:
  replicas: 3
  image: ghcr.io/elasticsoftwarefoundation/akces-query-service:0.9.0
  applicationName: "Akces Account Query Service"
  args:
    - "--spring.profiles.active=prod"
  env:
    - name: DB_HOST
      value: "postgres.default"
    - name: DB_PORT
      value: "5432"
  applicationProperties: |
    # Custom application properties
    spring.datasource.url=jdbc:postgresql://${DB_HOST}:${DB_PORT}/accounts
    spring.datasource.username=${DB_USER}
    spring.datasource.password=${DB_PASSWORD}
    spring.jpa.hibernate.ddl-auto=validate
  resources:
    requests:
      memory: "512Mi"
      cpu: "500m"
    limits:
      memory: "1Gi"
      cpu: "1000m"
```

### Reconciliation Process

For each custom resource, the operator:

1. Creates a ConfigMap with the service configuration
2. Deploys a StatefulSet to run the service instances
3. Creates a Service for network access
4. Manages Kafka topics required by the service
5. Updates the status of the resource based on the StatefulSet's status

## Service Details

### Aggregate Service

The Aggregate Service is responsible for:

- Processing commands received from the Command Service
- Maintaining the event-sourced state of domain aggregates
- Applying business logic through command handlers
- Emitting domain events to Kafka topics
- Storing state snapshots for efficient recovery

Key characteristics:
- Stateful service (requires persistent storage)
- Uses RocksDB for state storage
- Consumes and produces to Kafka topics
- Processes events in a strictly ordered fashion per aggregate

Configuration:
- Deployed with a PersistentVolumeClaim for state storage
- Configured with Kafka connection details
- Uses ZGC for efficient memory management
- Exposes health endpoints for monitoring

### Command Service

The Command Service is responsible for:

- Receiving commands from client applications
- Validating command structure and content
- Routing commands to the appropriate aggregate
- Managing command response handling
- Implementing schema validation using JSON Schema

Key characteristics:
- Stateless service
- Acts as the entry point for write operations
- Handles command validation and routing
- Provides synchronous and asynchronous APIs for clients

Configuration:
- Deployed without persistent storage
- Configured with Kafka connection details
- Exposes HTTP endpoints for client requests

### Query Service

The Query Service is responsible for:

- Building and maintaining read models from domain events
- Providing optimized views of domain data
- Serving queries from client applications
- Updating read models based on domain events

Key characteristics:
- Stateful service (requires persistent storage)
- Consumes domain events from Kafka topics
- Maintains query-optimized state
- Can integrate with traditional databases (SQL, NoSQL)

Configuration:
- Deployed with a PersistentVolumeClaim for state storage
- Can be configured with custom application properties
- Supports custom environment variables for database connections
- Exposes HTTP endpoints for client queries

## Kafka Topic Structure

The operator manages the following Kafka topics for each aggregate:

- `<AggregateName>-Commands` - Commands sent to the aggregate
- `<AggregateName>-DomainEvents` - Domain events emitted by the aggregate
- `<AggregateName>-AggregateState` - Compacted topic storing the latest state of each aggregate instance

Additionally, the framework uses the following system topics:

- `Akces-Control` - Control messages and metadata
- `Akces-CommandResponses` - Responses to commands (for client notification)
- `Akces-GDPRKeys` - Encryption keys for GDPR-protected data

## Deployment Patterns

The Akces services can be deployed in various patterns:

1. **Monolithic Deployment** - All three service types deployed together for simple applications
2. **Microservice Deployment** - Each aggregate type gets its own set of services
3. **Hybrid Deployment** - Command services handle multiple aggregates, while query services are specialized

## Configuration and Integration

### Spring Boot Integration

All Akces services are built on Spring Boot and provide:

- Health endpoints for monitoring
- Graceful shutdown
- Structured logging with Logback
- Support for configuration via properties files or environment variables

### Customization Options

Each service type can be customized:

- Custom application properties
- Environment variables
- Resource limits and requests
- Replica count for scaling
- Custom Docker images for domain-specific logic

### High Availability

The operator deploys services with:

- Multiple replicas for redundancy
- Affinity rules for distributing across nodes
- Probes for health checking
- Graceful shutdown handling

## Usage Examples

### Deploying a Complete CQRS System

To deploy a complete CQRS system for a domain, create instances of all three CRDs:

```yaml
# 1. Create the Aggregate Service
apiVersion: akces.elasticsoftware.org/v1
kind: Aggregate
metadata:
  name: wallet-aggregate
spec:
  replicas: 3
  image: ghcr.io/elasticsoftwarefoundation/akces-aggregate-service:0.9.0
  aggregateNames:
    - Wallet
  applicationName: "Wallet Aggregate Service"
  enableSchemaOverwrites: false

---
# 2. Create the Command Service
apiVersion: akces.elasticsoftware.org/v1
kind: CommandService
metadata:
  name: wallet-command
spec:
  replicas: 3
  image: ghcr.io/elasticsoftwarefoundation/akces-command-service:0.9.0
  applicationName: "Wallet Command Service"

---
# 3. Create the Query Service
apiVersion: akces.elasticsoftware.org/v1
kind: QueryService
metadata:
  name: wallet-query
spec:
  replicas: 3
  image: ghcr.io/elasticsoftwarefoundation/akces-query-service:0.9.0
  applicationName: "Wallet Query Service"
  applicationProperties: |
    spring.application.name=Wallet Query Service
    akces.querymodels.enabled=true
    akces.querymodels.packages=com.example.wallet.query
```

### Scaling Services

To scale a service, update the `replicas` field:

```yaml
apiVersion: akces.elasticsoftware.org/v1
kind: Aggregate
metadata:
  name: wallet-aggregate
spec:
  replicas: 5  # Increased from 3 to 5
  # other fields remain the same
```

### Accessing Service Information

The operator updates the status of each resource with information about the running service:

```bash
kubectl get aggregate wallet-aggregate -o yaml
```

Example output:
```yaml
apiVersion: akces.elasticsoftware.org/v1
kind: Aggregate
metadata:
  name: wallet-aggregate
spec:
  # [...]
status:
  readyReplicas: 3
```

## Best Practices

1. **Resource Planning**
   - Size CPU and memory resources based on the expected load
   - Monitor resource usage to adjust as needed

2. **Persistence**
   - Use SSDs or high-performance disks for state storage
   - In GCP, consider using Hyperdisk Balanced for optimal performance

3. **Scaling**
   - Horizontally scale services to match workload
   - Ensure Kafka partitions match or exceed service replica count

4. **Monitoring**
   - Set up monitoring for the health endpoints
   - Monitor Kafka lag to detect processing delays

5. **Backup**
   - Regular backups of Kafka topics are recommended
   - Implement disaster recovery plans for data safety

## Troubleshooting

Common issues and solutions:

1. **Service Not Starting**
   - Check ConfigMap exists and has correct format
   - Verify image pull secrets are configured
   - Check resource constraints

2. **Command Processing Issues**
   - Verify Kafka topics exist and are accessible
   - Check schema compatibility in Schema Registry
   - Review service logs for validation errors

3. **Query Service Not Updating**
   - Check Kafka consumer lag
   - Verify event handlers are correctly implemented
   - Check database connectivity if using external databases

4. **Performance Issues**
   - Tune Kafka parameters for performance
   - Adjust JVM settings via environment variables
   - Scale up resources or increase replicas

5. **Operator Issues**
   - Check operator logs for reconciliation errors
   - Verify RBAC permissions for the operator

## Conclusion

The Akces Framework services provide a complete implementation of CQRS and Event Sourcing patterns using Kafka as the backbone infrastructure. The Kubernetes operator simplifies the deployment and management of these services, allowing teams to focus on domain-specific implementations rather than infrastructure concerns.

By separating commands, aggregates, and queries into distinct services, the framework provides flexibility, scalability, and resilience while maintaining the integrity of the event-sourced data model.

================
File: TEST-APPS.md
================
# Akces Framework Test Applications

This document provides an overview of the test applications included in the Akces Framework repository. These applications demonstrate real-world usage patterns and implementation examples of the Akces Framework's CQRS (Command Query Responsibility Segregation) and Event Sourcing capabilities.

## Crypto Trading Application

The primary test application is a Crypto Trading platform that showcases how to build a distributed, event-driven system using the Akces Framework.

### Overview

The Crypto Trading application simulates a cryptocurrency trading platform where users can:

- Create accounts
- Manage crypto wallets with various currency balances
- Place market orders to buy cryptocurrencies
- View market information from exchanges (via Coinbase API integration)

The application demonstrates the full CQRS pattern with clear separation between commands (write operations) and queries (read operations), as well as event sourcing for maintaining complete audit trails and state reconstruction.

### Architecture

The application follows a modular architecture split into three main components:

1. **Aggregates Module** (`crypto-trading/aggregates`): Contains domain models, commands, events, and business logic
2. **Commands Module** (`crypto-trading/commands`): Provides API endpoints for write operations
3. **Queries Module** (`crypto-trading/queries`): Provides API endpoints for read operations and maintains query-optimized data models

### Key Aggregates

The application defines several key aggregates that demonstrate different aspects of domain modeling with Akces:

#### Account Aggregate

Represents a user account in the trading system:

- Creates new user accounts
- Stores basic user information including PII (Personally Identifiable Information) that is automatically protected through Akces's GDPR compliance features

```java
public final class Account implements Aggregate<AccountState> {
    public Stream<AccountCreatedEvent> create(CreateAccountCommand cmd, AccountState isNull) {
        return Stream.of(new AccountCreatedEvent(cmd.userId(), cmd.country(), 
                                               cmd.firstName(), cmd.lastName(), cmd.email()));
    }
}
```

#### Wallet Aggregate

Manages a user's cryptocurrency holdings:

- Creates wallets automatically when accounts are created
- Supports multiple currency balances within a wallet
- Handles crediting and debiting operations
- Implements reservation system for pending transactions
- Demonstrates state versioning/migration with `WalletState` and `WalletStateV2`

```java
public final class Wallet implements Aggregate<WalletStateV2> {
    public Stream<DomainEvent> credit(CreditWalletCommand cmd, WalletStateV2 currentState) {
        // Validation and business logic
        return Stream.of(new WalletCreditedEvent(currentState.id(), cmd.currency(), 
                                               cmd.amount(), balance.amount().add(cmd.amount())));
    }
}
```

#### CryptoMarket Aggregate

Represents a trading market for a specific cryptocurrency pair:

- Creates market definitions with base and quote currencies
- Processes market orders
- Integrates with external Coinbase API for pricing
- Demonstrates external service integration

```java
public class CryptoMarket implements Aggregate<CryptoMarketState> {
    public Stream<DomainEvent> handle(PlaceMarketOrderCommand command, CryptoMarketState currentState) {
        // Market order processing logic with external API integration
        Ticker currentTicker = coinbaseService.getTicker(currentState.id());
        // Further processing...
    }
}
```

#### OrderProcessManager Aggregate

Demonstrates the Process Manager pattern for coordinating complex workflows:

- Orchestrates the full lifecycle of buy orders across multiple aggregates
- Reacts to events from different aggregates to advance the process
- Handles compensating transactions for failures
- Shows how to implement saga patterns with Akces

```java
public class OrderProcessManager implements Aggregate<OrderProcessManagerState> {
    public Stream<BuyOrderCreatedEvent> placeBuyOrder(PlaceBuyOrderCommand command, OrderProcessManagerState state) {
        // Reserve funds first
        getCommandBus().send(new ReserveAmountCommand(/*...*/));
        // Create the order
        return Stream.of(new BuyOrderCreatedEvent(/*...*/));
    }
    
    // Event handlers to advance the process based on events from other aggregates
    public Stream<DomainEvent> handle(AmountReservedEvent event, OrderProcessManagerState state) {
        // Place the market order now that funds are reserved
        getCommandBus().send(new PlaceMarketOrderCommand(/*...*/));
        return Stream.of(new BuyOrderPlacedEvent(/*...*/));
    }
}
```

### Commands and Events

The application defines a rich set of commands and events that demonstrate best practices:

#### Commands

- `CreateAccountCommand`: Creates a new user account
- `CreateWalletCommand`: Creates a new wallet
- `CreateBalanceCommand`: Adds a new currency balance to a wallet
- `CreditWalletCommand`: Adds funds to a wallet balance
- `DebitWalletCommand`: Removes funds from a wallet balance
- `ReserveAmountCommand`: Reserves funds for a pending transaction
- `PlaceBuyOrderCommand`: Initiates a buy order process
- `PlaceMarketOrderCommand`: Places an order on a market

#### Events

- `AccountCreatedEvent`: Signals account creation
- `WalletCreatedEvent`: Signals wallet creation
- `BalanceCreatedEvent`: Signals addition of a new balance
- `WalletCreditedEvent`: Signals successful crediting of funds
- `WalletDebitedEvent`: Signals successful debiting of funds
- `AmountReservedEvent`: Signals successful fund reservation
- `BuyOrderCreatedEvent`: Signals creation of a buy order
- `MarketOrderFilledEvent`: Signals successful execution of a market order

#### Error Events

The application handles errors through specialized error events:

- `InvalidAmountErrorEvent`: Signals an invalid amount in a command
- `InsufficientFundsErrorEvent`: Signals insufficient funds for an operation
- `InvalidCryptoCurrencyErrorEvent`: Signals an unknown cryptocurrency
- `MarketOrderRejectedErrorEvent`: Signals rejection of a market order

### Query Models

The application defines query models that are optimized for read operations:

- `AccountQueryModel`: Provides efficient access to account information
- `WalletQueryModel`: Provides efficient access to wallet balances
- `CryptoMarketModel`: Provides access to market information

These models are kept up-to-date by subscribing to domain events and are stored in formats optimized for queries.

### Database Integration

The application demonstrates database integration for query models:

- Uses JDBC for database access
- Implements Liquibase for database migrations
- Shows how to map domain events to database operations

```java
public class CryptoMarketModel extends JdbcDatabaseModel {
    public void handle(CryptoMarketCreatedEvent event) {
        cryptoMarketRepository.save(CryptoMarket.createNew(
            event.id(),
            event.baseCrypto(),
            event.quoteCrypto(),
            // Other properties...
        ));
    }
}
```

### REST API

The application exposes REST endpoints for both commands and queries:

#### Command Endpoints

- `POST /v1/accounts`: Create a new account
- `POST /v1/wallets/{walletId}/balances`: Add a new balance to a wallet
- `POST /v1/wallets/{walletId}/balances/{currency}/credit`: Credit funds to a wallet
- `POST /v1/accounts/{accountId}/orders/buy`: Place a buy order

#### Query Endpoints

- `GET /v1/accounts/{accountId}`: Get account information
- `GET /v1/wallets/{walletId}`: Get wallet information
- `GET /v1/markets`: Get all markets
- `GET /v1/markets/{marketId}`: Get specific market information

### Testing

The application includes comprehensive tests that demonstrate testing strategies for CQRS and Event Sourcing:

- Unit tests for individual aggregates
- Integration tests for command processing
- End-to-end tests for full workflows
- Tests that verify temporal queries and event replay

The tests use TestContainers to set up Kafka, Schema Registry, and PostgreSQL for realistic testing environments.

## Technical Highlights

### Event Sourcing Implementation

- All state changes are captured as immutable events
- State is reconstructed by replaying events
- Events are stored in Kafka topics, partitioned by aggregate ID
- Snapshots are maintained in RocksDB for efficient access

### CQRS Pattern

- Clear separation between command and query responsibilities
- Command endpoints focusing on write operations
- Query endpoints optimized for read operations
- Different data models for writes and reads

### GDPR Compliance

- PII data (like names and emails) is automatically protected
- Uses `@PIIData` annotation to mark sensitive fields
- Transparent encryption during serialization

### Schema Management

- Integration with Confluent Schema Registry
- Command and event validation using JSON Schema
- Schema evolution with version tracking

### Process Management

- Complex workflows coordinated across multiple aggregates
- Stateful process tracking
- Event-driven process advancement

## Conclusion

The Crypto Trading application serves as a comprehensive demonstration of building distributed, event-driven systems with the Akces Framework. It showcases best practices for implementing CQRS and Event Sourcing patterns and demonstrates how to solve common challenges in distributed systems.

This application can be used as a reference implementation when building your own applications with the Akces Framework, offering patterns and solutions for common requirements in enterprise applications.

================
File: services/operator/src/main/resources/org/elasticsoftware/akces/operator/query/statefulset.yaml
================
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: ""
  labels:
    app.kubernetes.io/part-of: ""
    app.kubernetes.io/managed-by: ""
spec:
  serviceName: ""
  replicas: 3
  podManagementPolicy: Parallel
  selector:
    matchLabels:
      app: ""
  template:
    metadata:
      labels:
        app: ""
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      containers:
        - name: akces-query-service
          image: ""
          env:
            - name: SPRING_APPLICATION_NAME
              value: "Akces Query Service"
            - name: SPRING_CONFIG_LOCATION
              value: "file:/config/application-default.properties,optional:file:/config/application.properties"
            - name: LOGGING_CONFIG
              value: "file:/config/logback.xml"
            - name: BPL_JVM_THREAD_COUNT
              value: "100"
            - name: JAVA_TOOL_OPTIONS
              value: "-XX:+UseZGC -XX:+ZGenerational"
          lifecycle:
            preStop:
              exec:
                command: [ "/bin/sh", "-c", "sleep 10" ]
          ports:
            - containerPort: 8080
              name: http
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /actuator/health/readiness
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 1
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: actuator/health/liveness
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          volumeMounts:
            - name: config-volume
              mountPath: /config
            - name: akces-data
              mountPath: /var/lib/akces-data
              readOnly: false
      volumes:
        - name: config-volume
          configMap:
            name: ""
  volumeClaimTemplates:
    - metadata:
        name: akces-data
      spec:
        accessModes: [ "ReadWriteOnce" ]
        storageClassName: "akces-data-hyperdisk-balanced"
        resources:
          requests:
            storage: 4Gi

================
File: FRAMEWORK_OVERVIEW.md
================
# Comprehensive Analysis of the Akces Framework - Updated Overview

## Introduction

The Akces Framework is a sophisticated event sourcing and CQRS (Command Query Responsibility Segregation) implementation built on Apache Kafka. It provides a comprehensive infrastructure for building distributed, event-driven applications with a clear separation between write and read concerns.

## Core Purpose and Values

Akces addresses several key challenges in distributed systems:

1. **Event Sourcing Implementation**: Provides a complete event sourcing framework where all changes to application state are captured as an immutable sequence of events.

2. **CQRS Architecture**: Enforces clean separation between command (write) and query (read) responsibilities for better scalability and performance.

3. **Partition-Based Scalability**: Leverages Kafka's partitioning for horizontal scaling of aggregates, allowing applications to scale with increasing load.

4. **Privacy By Design**: Built-in GDPR compliance through transparent encryption of personally identifiable information (PII).

5. **Schema Evolution**: Sophisticated schema management with backward compatibility checks to support evolving domain models.

6. **Process Management**: First-class support for process managers to orchestrate multi-step business processes across aggregates.

## Architecture Overview

Akces is organized into five main modules, each with distinct responsibilities:

### 1. API Module (`akces-api`)
Defines the core interfaces and annotations that make up the programming model:
- `Aggregate` and `AggregateState` interfaces
- Command and event interfaces with marker annotations
- Handler annotations (`@CommandHandler`, `@EventHandler`, etc.)
- Query model interfaces and annotations

### 2. Shared Module (`akces-shared`)
Contains common utilities and shared functionality:
- Protocol record definitions for Kafka communication
- GDPR compliance utilities with encryption/decryption
- Schema registry integration for JSON schema validation
- Serialization/deserialization support with Protocol Buffers
- RocksDB utilities for efficient state management

### 3. Runtime Module (`akces-runtime`)
Implements the core event sourcing infrastructure:
- Aggregate runtime for processing commands and events
- State repositories (RocksDB-based and in-memory)
- Command handling pipeline with validation
- Event sourcing mechanics for state reconstruction
- Kafka partition management for distributed processing

### 4. Client Module (`akces-client`)
Provides client-side functionality for command submission:
- Command sending with synchronous and asynchronous APIs
- Service discovery for routing commands to the correct aggregate
- Schema validation and compatibility checking
- Command response handling

### 5. Query Support Module (`akces-query-support`)
Implements the query side of CQRS:
- Query model runtime for maintaining read models
- Database model support (JDBC, JPA) for persistence
- Event handling for updating query models
- State hydration for efficient retrieval
- Caching for improved read performance

## Key Components and Patterns

### Aggregate Pattern

At the core of Akces is the concept of aggregates, which are domain entities that:
- Encapsulate business logic within consistency boundaries
- Respond to commands by validating and processing them
- Emit domain events representing facts that have occurred
- Maintain state through event sourcing mechanisms

```java
@AggregateInfo(value = "Wallet", version = 1)
public final class Wallet implements Aggregate<WalletState> {
    @CommandHandler(create = true)
    public Stream<DomainEvent> create(CreateWalletCommand cmd, WalletState isNull) {
        return Stream.of(new WalletCreatedEvent(cmd.id()));
    }
    
    @EventSourcingHandler(create = true)
    public WalletState create(WalletCreatedEvent event, WalletState isNull) {
        return new WalletState(event.id(), new ArrayList<>());
    }
}
```

### Command Handling

Commands are processed through a pipeline that:
1. Validates the command structure using JSON Schema
2. Routes the command to the appropriate aggregate partition
3. Processes the command to produce domain events
4. Applies those events to update the aggregate state
5. Persists both events and updated state to Kafka topics

```java
@CommandInfo(type = "CreateWallet", version = 1)
public record CreateWalletCommand(@AggregateIdentifier String id, String currency) implements Command {
    @Override
    public String getAggregateId() {
        return id();
    }
}
```

### Event Sourcing

The event sourcing mechanism:
1. Captures all state changes as immutable events in Kafka
2. Stores events in partitioned topics for efficient processing
3. Rebuilds aggregate state by replaying events
4. Uses RocksDB to maintain efficient state snapshots
5. Handles event upcasting for schema evolution

```java
@DomainEventInfo(type = "WalletCreated", version = 1)
public record WalletCreatedEvent(@AggregateIdentifier String id) implements DomainEvent {
    @Override
    public String getAggregateId() {
        return id();
    }
}
```

### GDPR Compliance

Akces provides sophisticated GDPR compliance through:
1. `@PIIData` annotation to mark sensitive fields
2. Transparent encryption/decryption during serialization
3. Key management through dedicated Kafka topics
4. Context-based encryption to secure personal data
5. Separation of encryption keys from data for better security

```java
public record AccountState(
    @AggregateIdentifier String userId,
    String country,
    @PIIData String firstName,
    @PIIData String lastName,
    @PIIData String email
) implements AggregateState {
    @Override
    public String getAggregateId() {
        return userId();
    }
}
```

### Query Models

For efficient reads, Akces implements:
1. Query models updated via domain events
2. State hydration from event streams
3. Caching mechanisms for efficient access
4. Projection-based read models optimized for specific query patterns

```java
@QueryModelInfo(value = "WalletQuery", version = 1, indexName = "Wallets")
public class WalletQueryModel implements QueryModel<WalletQueryModelState> {
    @QueryModelEventHandler(create = true)
    public WalletQueryModelState create(WalletCreatedEvent event, WalletQueryModelState isNull) {
        return new WalletQueryModelState(event.id(), List.of());
    }
    
    @QueryModelEventHandler
    public WalletQueryModelState creditWallet(WalletCreditedEvent event, WalletQueryModelState state) {
        return new WalletQueryModelState(
            state.walletId(),
            state.balances().stream()
                .map(balance -> {
                    if (balance.currency().equals(event.currency())) {
                        return new WalletQueryModelState.Balance(
                            balance.currency(),
                            balance.amount().add(event.amount()),
                            balance.reservedAmount()
                        );
                    }
                    return balance;
                })
                .toList()
        );
    }
}
```

### Database Models

For integration with traditional databases:
1. Database models updated from domain events
2. Support for JDBC and JPA persistence
3. Transactional updates with exactly-once semantics
4. Partition-aware offset tracking for reliable processing

```java
@DatabaseModelInfo(value = "WalletDatabase", version = 1)
public class WalletDatabaseModel extends JdbcDatabaseModel {
    @DatabaseModelEventHandler
    public void handle(WalletCreatedEvent event) {
        jdbcTemplate.update("INSERT INTO wallets (wallet_id) VALUES (?)", event.id());
    }
    
    @DatabaseModelEventHandler
    public void handle(WalletCreditedEvent event) {
        jdbcTemplate.update(
            "UPDATE wallet_balances SET amount = ? WHERE wallet_id = ? AND currency = ?",
            event.newBalance(),
            event.id(),
            event.currency()
        );
    }
}
```

### Process Managers

For coordinating complex workflows:
1. Process managers to orchestrate multi-step processes
2. Process state tracking to maintain workflow state
3. Event-driven process advancement
4. Error handling and compensation logic

```java
@AggregateInfo(value = "OrderProcessManager", version = 1)
public class OrderProcessManager implements ProcessManager<OrderProcessManagerState, OrderProcess> {
    @CommandHandler
    public Stream<BuyOrderCreatedEvent> placeBuyOrder(PlaceBuyOrderCommand command, OrderProcessManagerState state) {
        String orderId = UUID.randomUUID().toString();
        
        // Reserve funds first - send command to Wallet aggregate
        getCommandBus().send(new ReserveAmountCommand(
            state.userId(),
            command.market().quoteCurrency(),
            command.quantity().multiply(command.limitPrice()),
            orderId
        ));
        
        return Stream.of(new BuyOrderCreatedEvent(
            state.userId(),
            orderId,
            command.market(),
            command.quantity(),
            command.limitPrice(),
            command.clientReference()
        ));
    }
    
    @EventHandler
    public Stream<DomainEvent> handle(AmountReservedEvent event, OrderProcessManagerState state) {
        if (state.hasAkcesProcess(event.referenceId())) {
            OrderProcess process = state.getAkcesProcess(event.referenceId());
            return Stream.of(new BuyOrderPlacedEvent(
                state.userId(),
                process.orderId(),
                process.market(),
                process.quantity(),
                process.limitPrice()
            ));
        }
        return Stream.empty();
    }
}
```

## Technical Implementation Details

### Partition-Based Processing

Akces utilizes Kafka's partitioning for scalability:
- Aggregates are distributed across partitions based on their ID
- Each partition is processed independently by a dedicated thread
- Partitions can be rebalanced across nodes dynamically
- State is maintained efficiently per partition using RocksDB

### Transactional Processing

Commands are processed transactionally:
- Kafka transactions ensure atomic updates
- State updates are coordinated with event publishing
- Exactly-once semantics are preserved
- Failures result in transaction rollbacks
- Consistent offset management for reliable processing

### Schema Management

Schema evolution is handled through:
- Schema registry integration (Confluent Schema Registry)
- JSON Schema validation for commands and events
- Automatic schema compatibility checks
- Version management for backward compatibility
- Support for upcasting to handle schema changes

### State Management

Aggregate state is managed efficiently:
- RocksDB for persistent state storage with high performance
- Transactional state updates with rollback capability
- Optimistic concurrency control
- In-memory caching for performance
- State snapshots to avoid full event replay

## Key Innovations

1. **Integrated GDPR Compliance**: Built-in support for handling personal data with transparent encryption, making compliance easier.

2. **Event Indexing**: Automatic indexing of events for efficient temporal queries and state reconstruction across aggregates.

3. **Flexible Deployment Models**: Support for different deployment topologies from monolithic to fully distributed microservices.

4. **RocksDB Integration**: Efficient state storage using RocksDB for high performance with durability.

5. **Process Manager Support**: First-class support for process managers to handle complex workflows across aggregate boundaries.

6. **Schema Evolution**: Sophisticated handling of schema changes with backward compatibility checks and upcasting.

7. **Annotation-Based Programming Model**: Intuitive, declarative programming model that reduces boilerplate code.

## Advantages Over Similar Frameworks

Compared to other event sourcing frameworks like Axon or EventStore:

1. **Kafka Foundation**: Built on Kafka for enterprise-grade scalability, reliability, and throughput.

2. **Privacy by Design**: First-class GDPR compliance baked into the core rather than as an afterthought.

3. **Schema Evolution**: Sophisticated schema management with backward compatibility checks and automatic validation.

4. **Programming Model**: Clean, annotation-based programming model that minimizes boilerplate and follows domain-driven design principles.

5. **Complete CQRS Stack**: Full support for both command and query sides with multiple implementation options.

6. **Partition-Based Scalability**: Leverages Kafka's partitioning for horizontal scaling without complex configuration.

## Usage Scenarios

Akces is well-suited for:

1. **Financial Systems**: Where audit trails, transaction integrity, and high throughput are critical requirements.

2. **Customer Data Platforms**: Where GDPR compliance is essential and personal data needs protection.

3. **Distributed Commerce Systems**: With complex workflows across services and high scalability needs.

4. **High-Scale Event-Driven Systems**: Requiring reliable, high-throughput event processing.

5. **Systems with Complex Temporal Requirements**: Needing historical state reconstruction and time-based queries.

6. **Microservice Architectures**: Where clear boundaries and eventual consistency are appropriate design choices.

## Limitations and Considerations

1. **Kafka Dependency**: Requires a well-configured Kafka cluster, which adds operational complexity.

2. **Learning Curve**: Event sourcing and CQRS patterns require a mindset shift for teams used to traditional CRUD.

3. **Eventual Consistency**: Query models may lag behind command processing, requiring careful design for user experience.

4. **Infrastructure Complexity**: Requires Schema Registry and additional components for full functionality.

5. **Performance Considerations**: Event replaying can be resource-intensive for aggregates with many events.

## Production Readiness

The framework includes several features that make it production-ready:

1. **Resilience**: Automatic recovery from failures through Kafka's reliability mechanisms.

2. **Observability**: Comprehensive logging and metrics for monitoring system behavior.

3. **Configuration Flexibility**: Extensive configuration options for tuning performance.

4. **Testing Support**: Built-in utilities for testing aggregates and command handlers.

5. **Deployment Options**: Support for containerized deployment in modern cloud environments.

## Conclusion

The Akces Framework provides a comprehensive solution for building event-sourced, CQRS-based applications with a focus on scalability, privacy, and developer experience. Its clean programming model, combined with sophisticated runtime components, addresses many common challenges in distributed systems development.

The framework's integration with Kafka provides a reliable foundation for high-throughput event processing, while its schema management and GDPR compliance features address important enterprise concerns. The partition-based processing model enables horizontal scaling, making it suitable for applications with demanding performance requirements.

By providing a complete implementation of event sourcing and CQRS patterns, Akces enables developers to focus on domain logic rather than infrastructure concerns, ultimately leading to more maintainable, scalable, and secure distributed applications.

================
File: README.md
================
# Akces Framework

## Overview

Akces is a powerful CQRS (Command Query Responsibility Segregation) and Event Sourcing framework built on Apache Kafka. It provides a comprehensive infrastructure for building distributed, event-driven applications with a clear separation between write operations (commands) and read operations (queries).

The framework implements the full event sourcing pattern, capturing all changes to application state as a sequence of events. These events serve as the system of record and can be replayed to reconstruct the state at any point in time, providing a complete audit trail and enabling temporal queries.

Akces leverages Kafka's distributed architecture for reliable event storage and processing, making it highly scalable and resilient. It also provides built-in support for privacy protection (GDPR compliance), schema evolution, and efficient state management.

## Core Concepts

- **Aggregates**: Domain entities that encapsulate business logic and maintain consistency boundaries
- **Commands**: Requests to perform actions that change the state of an aggregate
- **Domain Events**: Immutable records of facts that have occurred, representing state changes
- **Command Handlers**: Process commands and produce events 
- **Event Sourcing Handlers**: Apply events to update aggregate state
- **Query Models**: Read-optimized projections of aggregate state
- **Database Models**: Persistent storage of aggregate data optimized for queries
- **Process Managers**: Coordinate workflows across multiple aggregates

## Key Features

### Command Processing

- **Command Bus**: Distribute commands to appropriate aggregates
- **Command Validation**: Automatic schema-based validation using JSON Schema
- **Command Routing**: Intelligent routing based on aggregate IDs
- **Transactional Processing**: Atomic processing with Kafka transactions

### Event Sourcing

- **Event Store**: Kafka-based storage for all domain events
- **State Reconstruction**: Rebuild aggregate state by replaying events
- **Event Handlers**: React to events to trigger additional processes
- **Event Bridging**: Connect events from one aggregate to commands on another

### Aggregate Management

- **Partition-Based Processing**: Scale horizontally through Kafka partitioning
- **State Snapshots**: Efficient state storage using RocksDB
- **Aggregate Lifecycle**: Manage aggregate creation and updates
- **Event Indexing**: Index events for efficient retrieval

### Query Support

- **Query Models**: Build specialized read models from events
- **State Hydration**: Efficiently load and cache query model state
- **Database Integration**: Support for both JDBC and JPA database models
- **Event-Driven Updates**: Keep read models in sync with write models

### Privacy & GDPR

- **PII Data Protection**: Automatic encryption of personal data
- **Transparent Handling**: Annotation-based marking of sensitive fields
- **Key Management**: Secure handling of encryption keys
- **Context-Aware Processing**: Apply encryption based on context

### Schema Management

- **Schema Registry Integration**: Work with Confluent Schema Registry
- **Schema Evolution**: Support versioning and evolution of schemas
- **Compatibility Checking**: Ensure backward compatibility
- **Automatic Generation**: Generate JSON schemas from command and event classes

### Process Managers

- **Orchestration**: Manage complex workflows across multiple aggregates
- **Stateful Processing**: Maintain process state through events
- **Event-Driven Flow**: React to events to advance processes
- **Error Handling**: Built-in compensation logic for failures

## Architecture

Akces is organized into several Maven modules:

- **api**: Core interfaces and annotations defining the programming model
- **runtime**: Implementation of event sourcing and command handling
- **shared**: Common utilities, serialization, and GDPR functionality
- **client**: Client library for sending commands and processing responses
- **query-support**: Support for query models and database models

## Getting Started

### Prerequisites

- Java 21 or higher
- Apache Kafka 3.x with KRaft mode enabled
- Confluent Schema Registry
- Maven 3.6 or higher

### Maven Dependencies

Add the following to your `pom.xml`:

```xml
<dependency>
    <groupId>org.elasticsoftwarefoundation.akces</groupId>
    <artifactId>akces-api</artifactId>
    <version>0.9.0</version>
</dependency>

<!-- For command senders -->
<dependency>
    <groupId>org.elasticsoftwarefoundation.akces</groupId>
    <artifactId>akces-client</artifactId>
    <version>0.9.0</version>
</dependency>

<!-- For aggregate services -->
<dependency>
    <groupId>org.elasticsoftwarefoundation.akces</groupId>
    <artifactId>akces-runtime</artifactId>
    <version>0.9.0</version>
</dependency>

<!-- For query models and database models -->
<dependency>
    <groupId>org.elasticsoftwarefoundation.akces</groupId>
    <artifactId>akces-query-support</artifactId>
    <version>0.9.0</version>
</dependency>
```

### Configuration

Configure the framework in your `application.yaml`:

```yaml
spring:
  kafka:
    bootstrap-servers: localhost:9092
    consumer:
      enable-auto-commit: false
      isolation-level: read_committed
      max-poll-records: 500
      heartbeat-interval: 2000
      auto-offset-reset: latest
      properties:
        max.poll.interval.ms: 10000
        session.timeout.ms: 30000
        partition.assignment.strategy: org.apache.kafka.clients.consumer.CooperativeStickyAssignor
    producer:
      acks: all
      retries: 2147483647
      properties:
        linger.ms: 0
        retry.backoff.ms: 0
        enable.idempotence: true
        max.in.flight.requests.per.connection: 1

akces:
  schemaregistry:
    url: http://localhost:8081
  rocksdb:
    baseDir: /tmp/akces
```

## Usage Examples

### Defining an Aggregate

```java
@AggregateInfo(value = "Wallet", version = 1, indexed = true, indexName = "Wallets")
public final class Wallet implements Aggregate<WalletState> {
    @Override
    public Class<WalletState> getStateClass() {
        return WalletState.class;
    }

    @CommandHandler(create = true, produces = {WalletCreatedEvent.class, BalanceCreatedEvent.class})
    public Stream<DomainEvent> create(CreateWalletCommand cmd, WalletState isNull) {
        return Stream.of(new WalletCreatedEvent(cmd.id()), 
                         new BalanceCreatedEvent(cmd.id(), cmd.currency()));
    }

    @EventSourcingHandler(create = true)
    public WalletState create(WalletCreatedEvent event, WalletState isNull) {
        return new WalletState(event.id(), new ArrayList<>());
    }
    
    @EventSourcingHandler
    public WalletState createBalance(BalanceCreatedEvent event, WalletState state) {
        List<WalletState.Balance> balances = new ArrayList<>(state.balances());
        balances.add(new WalletState.Balance(event.currency(), BigDecimal.ZERO));
        return new WalletState(state.id(), balances);
    }
    
    @CommandHandler(produces = {WalletCreditedEvent.class})
    public Stream<DomainEvent> credit(CreditWalletCommand cmd, WalletState currentState) {
        WalletState.Balance balance = currentState.balances().stream()
                .filter(b -> b.currency().equals(cmd.currency()))
                .findFirst()
                .orElse(null);
                
        if (balance == null) {
            return Stream.of(new InvalidCurrencyErrorEvent(cmd.id(), cmd.currency()));
        }
        
        if (cmd.amount().compareTo(BigDecimal.ZERO) < 0) {
            return Stream.of(new InvalidAmountErrorEvent(cmd.id(), cmd.currency()));
        }
        
        return Stream.of(new WalletCreditedEvent(currentState.id(), 
                                               cmd.currency(), 
                                               cmd.amount(), 
                                               balance.amount().add(cmd.amount())));
    }
}
```

### Defining the Aggregate State

```java
public record WalletState(String id, List<Balance> balances) implements AggregateState {
    @Override
    public String getAggregateId() {
        return id();
    }

    public record Balance(String currency, BigDecimal amount, BigDecimal reservedAmount) {
        public Balance(String currency, BigDecimal amount) {
            this(currency, amount, BigDecimal.ZERO);
        }

        public BigDecimal getAvailableAmount() {
            return amount.subtract(reservedAmount);
        }
    }
}
```

### Creating Commands

```java
@CommandInfo(type = "CreateWallet", version = 1)
public record CreateWalletCommand(
    @AggregateIdentifier 
    @NotNull String id, 
    
    @NotNull String currency
) implements Command {
    @Override
    public String getAggregateId() {
        return id();
    }
}

@CommandInfo(type = "CreditWallet", version = 1)
public record CreditWalletCommand(
    @AggregateIdentifier 
    @NotNull String id,
    
    @NotNull String currency,
    
    @NotNull BigDecimal amount
) implements Command {
    @Override
    public String getAggregateId() {
        return id();
    }
}
```

### Creating Events

```java
@DomainEventInfo(type = "WalletCreated", version = 1)
public record WalletCreatedEvent(
    @AggregateIdentifier 
    @NotNull String id
) implements DomainEvent {
    @Override
    public String getAggregateId() {
        return id();
    }
}

@DomainEventInfo(type = "BalanceCreated", version = 1)
public record BalanceCreatedEvent(
    @AggregateIdentifier 
    @NotNull String id, 
    
    @NotNull String currency
) implements DomainEvent {
    @Override
    public String getAggregateId() {
        return id();
    }
}

@DomainEventInfo(type = "WalletCredited", version = 1)
public record WalletCreditedEvent(
    @AggregateIdentifier 
    @NotNull String id,
    
    @NotNull String currency,
    
    @NotNull BigDecimal amount,
    
    @NotNull BigDecimal newBalance
) implements DomainEvent {
    @Override
    public String getAggregateId() {
        return id();
    }
}
```

### Error Events

```java
@DomainEventInfo(type = "InvalidCurrencyError", version = 1)
public record InvalidCurrencyErrorEvent(
    @AggregateIdentifier 
    @NotNull String walletId,
    
    @NotNull String currency
) implements ErrorEvent {
    @Override
    public String getAggregateId() {
        return walletId();
    }
}

@DomainEventInfo(type = "InvalidAmountError", version = 1)
public record InvalidAmountErrorEvent(
    @AggregateIdentifier 
    @NotNull String walletId,
    
    @NotNull String currency
) implements ErrorEvent {
    @Override
    public String getAggregateId() {
        return walletId();
    }
}
```

### Sending Commands

```java
@Service
public class WalletService {
    private final AkcesClient akcesClient;
    
    @Autowired
    public WalletService(AkcesClient akcesClient) {
        this.akcesClient = akcesClient;
    }
    
    public String createWallet(String currency) {
        String walletId = UUID.randomUUID().toString();
        CreateWalletCommand command = new CreateWalletCommand(walletId, currency);
        
        // Send command and wait for response
        List<DomainEvent> events = akcesClient.send("DEFAULT_TENANT", command)
            .toCompletableFuture()
            .join();
            
        // Check for success
        if (events.stream().anyMatch(e -> e instanceof ErrorEvent)) {
            throw new RuntimeException("Failed to create wallet");
        }
        
        return walletId;
    }
    
    public void creditWallet(String walletId, String currency, BigDecimal amount) {
        CreditWalletCommand command = new CreditWalletCommand(walletId, currency, amount);
        
        try {
            // Send command without waiting for response
            akcesClient.sendAndForget("DEFAULT_TENANT", command);
        } catch (CommandRefusedException e) {
            // Handle specific command exceptions
            throw new RuntimeException("Command refused: " + e.getMessage());
        } catch (CommandValidationException e) {
            throw new RuntimeException("Invalid command: " + e.getMessage());
        }
    }
}
```

### Creating a Query Model

```java
@QueryModelInfo(value = "WalletQuery", version = 1, indexName = "Wallets")
public class WalletQueryModel implements QueryModel<WalletQueryModelState> {
    @Override
    public Class<WalletQueryModelState> getStateClass() {
        return WalletQueryModelState.class;
    }
    
    @Override
    public String getIndexName() {
        return "Wallets";
    }

    @QueryModelEventHandler(create = true)
    public WalletQueryModelState create(WalletCreatedEvent event, WalletQueryModelState isNull) {
        return new WalletQueryModelState(event.id(), List.of());
    }
    
    @QueryModelEventHandler
    public WalletQueryModelState createBalance(BalanceCreatedEvent event, WalletQueryModelState state) {
        List<WalletQueryModelState.Balance> balances = new ArrayList<>(state.balances());
        balances.add(new WalletQueryModelState.Balance(event.currency(), BigDecimal.ZERO));
        return new WalletQueryModelState(state.walletId(), balances);
    }
    
    @QueryModelEventHandler
    public WalletQueryModelState creditWallet(WalletCreditedEvent event, WalletQueryModelState state) {
        return new WalletQueryModelState(
            state.walletId(),
            state.balances().stream()
                .map(balance -> {
                    if (balance.currency().equals(event.currency())) {
                        return new WalletQueryModelState.Balance(
                            balance.currency(),
                            balance.amount().add(event.amount()),
                            balance.reservedAmount()
                        );
                    }
                    return balance;
                })
                .toList()
        );
    }
}

public record WalletQueryModelState(String walletId, List<Balance> balances) implements QueryModelState {
    @Override
    public String getIndexKey() {
        return walletId();
    }
    
    public record Balance(String currency, BigDecimal amount, BigDecimal reservedAmount) {
        public Balance(String currency, BigDecimal amount) {
            this(currency, amount, BigDecimal.ZERO);
        }
        
        public BigDecimal getAvailableAmount() {
            return amount.subtract(reservedAmount);
        }
    }
}
```

### Querying a Model

```java
@RestController
@RequestMapping("/wallets")
public class WalletController {
    private final QueryModels queryModels;
    
    @Autowired
    public WalletController(QueryModels queryModels) {
        this.queryModels = queryModels;
    }
    
    @GetMapping("/{walletId}")
    public ResponseEntity<WalletQueryModelState> getWallet(@PathVariable String walletId) {
        try {
            WalletQueryModelState wallet = queryModels.getHydratedState(WalletQueryModel.class, walletId)
                .toCompletableFuture()
                .get(5, TimeUnit.SECONDS);
                
            return ResponseEntity.ok(wallet);
        } catch (QueryModelIdNotFoundException e) {
            return ResponseEntity.notFound().build();
        } catch (Exception e) {
            return ResponseEntity.status(500).build();
        }
    }
}
```

### Creating a Database Model

```java
@DatabaseModelInfo(value = "WalletDB", version = 1)
public class WalletDatabaseModel extends JdbcDatabaseModel {

    @Autowired
    public WalletDatabaseModel(JdbcTemplate jdbcTemplate, PlatformTransactionManager transactionManager) {
        super(jdbcTemplate, transactionManager);
    }
    
    @DatabaseModelEventHandler
    public void handle(WalletCreatedEvent event) {
        jdbcTemplate.update(
            "INSERT INTO wallets (wallet_id, created_at) VALUES (?, NOW())",
            event.id()
        );
    }
    
    @DatabaseModelEventHandler
    public void handle(BalanceCreatedEvent event) {
        jdbcTemplate.update(
            "INSERT INTO wallet_balances (wallet_id, currency, amount, reserved_amount) VALUES (?, ?, 0, 0)",
            event.id(),
            event.currency()
        );
    }
    
    @DatabaseModelEventHandler
    public void handle(WalletCreditedEvent event) {
        jdbcTemplate.update(
            "UPDATE wallet_balances SET amount = ? WHERE wallet_id = ? AND currency = ?",
            event.newBalance(),
            event.id(),
            event.currency()
        );
    }
}
```

### GDPR and PII Data

Akces provides built-in support for handling personal identifiable information (PII):

```java
@AggregateStateInfo(value = "UserState", version = 1)
public record UserState(
    @AggregateIdentifier 
    String userId,
    
    String country,
    
    @PIIData 
    String firstName,
    
    @PIIData 
    String lastName,
    
    @PIIData 
    String email
) implements AggregateState {
    @Override
    public String getAggregateId() {
        return userId();
    }
}
```

With this annotation, the framework automatically:
- Encrypts PII data before storing it
- Decrypts PII data when loading it
- Manages encryption keys securely
- Ensures only authorized access to decrypted data

### Process Managers

For coordinating complex workflows across multiple aggregates:

```java
@AggregateInfo(value = "OrderProcessManager", version = 1)
public class OrderProcessManager implements ProcessManager<OrderProcessManagerState, OrderProcess> {
    
    @Override
    public Class<OrderProcessManagerState> getStateClass() {
        return OrderProcessManagerState.class;
    }
    
    @EventHandler(create = true)
    public Stream<UserOrderProcessesCreatedEvent> create(AccountCreatedEvent event, OrderProcessManagerState isNull) {
        return Stream.of(new UserOrderProcessesCreatedEvent(event.userId()));
    }
    
    @EventSourcingHandler(create = true)
    public OrderProcessManagerState create(UserOrderProcessesCreatedEvent event, OrderProcessManagerState isNull) {
        return new OrderProcessManagerState(event.userId());
    }
    
    @CommandHandler
    public Stream<BuyOrderCreatedEvent> placeBuyOrder(PlaceBuyOrderCommand command, OrderProcessManagerState state) {
        String orderId = UUID.randomUUID().toString();
        
        // Reserve funds first - send command to Wallet aggregate
        getCommandBus().send(new ReserveAmountCommand(
            state.userId(),
            command.market().quoteCurrency(),
            command.quantity().multiply(command.limitPrice()),
            orderId
        ));
        
        // Create order record
        return Stream.of(new BuyOrderCreatedEvent(
            state.userId(),
            orderId,
            command.market(),
            command.quantity(),
            command.limitPrice(),
            command.clientReference()
        ));
    }
    
    @EventHandler
    public Stream<DomainEvent> handle(AmountReservedEvent event, OrderProcessManagerState state) {
        if (state.hasAkcesProcess(event.referenceId())) {
            OrderProcess process = state.getAkcesProcess(event.referenceId());
            return Stream.of(new BuyOrderPlacedEvent(
                state.userId(),
                process.orderId(),
                process.market(),
                process.quantity(),
                process.limitPrice()
            ));
        }
        return Stream.empty();
    }
    
    @EventHandler
    public Stream<DomainEvent> handle(InsufficientFundsErrorEvent errorEvent, OrderProcessManagerState state) {
        if (state.hasAkcesProcess(errorEvent.referenceId())) {
            return Stream.of(state.getAkcesProcess(errorEvent.referenceId()).handle(errorEvent));
        }
        return Stream.empty();
    }
}
```

## Schema Evolution

Akces supports evolving your domain model over time:

```java
// Original version
@DomainEventInfo(type = "AccountCreated", version = 1)
public record AccountCreatedEvent(
    @AggregateIdentifier String userId,
    String country,
    String firstName,
    String lastName,
    String email
) implements DomainEvent { 
    @Override
    public String getAggregateId() {
        return userId();
    }
}

// New version with additional field
@DomainEventInfo(type = "AccountCreated", version = 2)
public record AccountCreatedEventV2(
    @AggregateIdentifier String userId,
    String country,
    String firstName,
    String lastName,
    String email,
    Boolean twoFactorEnabled
) implements DomainEvent {
    @Override
    public String getAggregateId() {
        return userId();
    }
}

// The upcasting handler
@UpcastingHandler
public AccountCreatedEventV2 cast(AccountCreatedEvent event) {
    return new AccountCreatedEventV2(
        event.userId(), 
        event.country(), 
        event.firstName(), 
        event.lastName(), 
        event.email(), 
        false // Default value for new field
    );
}
```

## Running the Framework

### Aggregate Service

```java
@SpringBootApplication
public class AggregateServiceApplication {
    public static void main(String[] args) {
        SpringApplication.run(AggregateServiceApplication.class, args);
    }
}
```

### Query Service

```java
@SpringBootApplication
public class QueryServiceApplication {
    public static void main(String[] args) {
        SpringApplication.run(QueryServiceApplication.class, args);
    }
}
```

### Client Application

```java
@SpringBootApplication
public class ClientApplication {
    public static void main(String[] args) {
        SpringApplication.run(ClientApplication.class, args);
    }
}
```

## Benefits of Using Akces

- **Scalability**: Built on Kafka for horizontal scaling across multiple nodes
- **Reliability**: Event sourcing ensures data integrity and complete audit trails
- **Flexibility**: Clean separation of commands and queries with CQRS
- **Performance**: Efficient state management with RocksDB and optimized query models
- **Security**: Built-in GDPR compliance with transparent PII handling
- **Evolution**: Schema evolution with backward compatibility checks
- **Developer Experience**: Intuitive annotation-based programming model
- **Observability**: Complete visibility into all commands and events

## License

Apache License 2.0

## Release Process

This project uses the Maven Release Plugin and GitHub Actions to create releases.
Run `mvn release:prepare release:perform && git push` to select the version to be released and create a VCS tag.

GitHub Actions will start [the build process](https://github.com/elasticsoftwarefoundation/akces-framework/actions/workflows/maven-publish.yml).

If successful, the build will be automatically published to [Github Packages](https://maven.pkg.github.com/elasticsoftwarefoundation/akces-framework/).

================
File: services/operator/pom.xml
================
<?xml version="1.0" encoding="UTF-8"?>

















<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>
    <parent>
        <groupId>org.elasticsoftwarefoundation.akces</groupId>
        <artifactId>akces-framework-services</artifactId>
        <version>0.9.1-SNAPSHOT</version>
    </parent>
    <artifactId>akces-operator</artifactId>
    <name>Elastic Software Foundation :: Akces :: Services :: Akces Operator</name>
    <description>Kubernetes Operator for the Akces Framework</description>
    <properties>
    </properties>
    <dependencies>
        <dependency>
            <groupId>io.javaoperatorsdk</groupId>
            <artifactId>operator-framework-spring-boot-starter</artifactId>
        </dependency>

        <dependency>
            <groupId>io.javaoperatorsdk</groupId>
            <artifactId>operator-framework-spring-boot-starter-test</artifactId>
            <scope>test</scope>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-actuator</artifactId>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-logging</artifactId>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-autoconfigure</artifactId>
        </dependency>

        <dependency>
            <groupId>org.springframework.kafka</groupId>
            <artifactId>spring-kafka</artifactId>
        </dependency>
        <dependency>
            <groupId>org.bouncycastle</groupId>
            <artifactId>bcprov-jdk18on</artifactId>
        </dependency>
        <dependency>
            <groupId>org.bouncycastle</groupId>
            <artifactId>bcpkix-jdk18on</artifactId>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-test</artifactId>
            <scope>test</scope>
        </dependency>

        <dependency>
            <groupId>org.testcontainers</groupId>
            <artifactId>junit-jupiter</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.mockito</groupId>
            <artifactId>mockito-core</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.testcontainers</groupId>
            <artifactId>kafka</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>io.javaoperatorsdk</groupId>
            <artifactId>operator-framework-junit-5</artifactId>
            <scope>test</scope>
        </dependency>
    </dependencies>

    <build>
        <plugins>
            <plugin>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-maven-plugin</artifactId>
            </plugin>
            <plugin>
                <groupId>io.fabric8</groupId>
                <artifactId>crd-generator-maven-plugin</artifactId>
                <executions>
                    <execution>
                        <id>generate-resources</id>
                        <configuration>
                            <outputDirectory>${project.basedir}/src/main/resources/META-INF/fabric8/</outputDirectory>
                        </configuration>
                        <goals>
                            <goal>generate</goal>
                        </goals>
                    </execution>
                    <execution>
                        <goals>
                            <goal>generate</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>
        </plugins>
    </build>

</project>

================
File: services/pom.xml
================
<?xml version="1.0" encoding="UTF-8"?>

















<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <parent>
        <groupId>org.elasticsoftwarefoundation.akces</groupId>
        <artifactId>akces-framework-parent</artifactId>
        <version>0.9.1-SNAPSHOT</version>
    </parent>
    <modelVersion>4.0.0</modelVersion>

    <artifactId>akces-framework-services</artifactId>
    <packaging>pom</packaging>

    <name>Elastic Software Foundation :: Akces :: Services</name>
    <url>https://github.com/elasticsoftwarefoundation/akces-framework</url>

    <properties>
        <operator-sdk.version>5.0.4</operator-sdk.version>
        <bouncycastle.version>1.80</bouncycastle.version>
        <fabric8.version>7.1.0</fabric8.version>
    </properties>

    <dependencyManagement>
        <dependencies>
            <dependency>
                <groupId>io.javaoperatorsdk</groupId>
                <artifactId>operator-framework-spring-boot-starter</artifactId>
                <version>6.0.1</version>
                <exclusions>
                    <exclusion>
                        <groupId>io.fabric8</groupId>
                        <artifactId>kubernetes-httpclient-vertx</artifactId>
                    </exclusion>
                </exclusions>
            </dependency>
            <dependency>
                <groupId>io.javaoperatorsdk</groupId>
                <artifactId>operator-framework-spring-boot-starter-test</artifactId>
                <version>6.0.1</version>
            </dependency>
            <dependency>
                <groupId>io.javaoperatorsdk</groupId>
                <artifactId>operator-framework-junit-5</artifactId>
                <version>${operator-sdk.version}</version>
            </dependency>
            <dependency>
                <groupId>io.javaoperatorsdk</groupId>
                <artifactId>operator-framework</artifactId>
                <version>${operator-sdk.version}</version>
            </dependency>
            <dependency>
                <groupId>io.fabric8</groupId>
                <artifactId>crd-generator-apt-v2</artifactId>
                <version>${fabric8.version}</version>
            </dependency>
            <dependency>
                <groupId>org.bouncycastle</groupId>
                <artifactId>bcprov-jdk18on</artifactId>
                <version>${bouncycastle.version}</version>
            </dependency>
            <dependency>
                <groupId>org.bouncycastle</groupId>
                <artifactId>bcpkix-jdk18on</artifactId>
                <version>${bouncycastle.version}</version>
            </dependency>
            <dependency>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-dependencies</artifactId>
                <version>${spring-boot.version}</version>
                <type>pom</type>
                <scope>import</scope>
            </dependency>
        </dependencies>
    </dependencyManagement>
    <modules>
        <module>operator</module>
    </modules>
    <build>
        <plugins>
            <plugin>

                <artifactId>maven-deploy-plugin</artifactId>
                <configuration>
                    <skip>true</skip>
                </configuration>
            </plugin>
        </plugins>
    </build>
    <profiles>
        <profile>
            <id>maven-release</id>
            <build>
                <plugins>
                    <plugin>
                        <groupId>org.springframework.boot</groupId>
                        <artifactId>spring-boot-maven-plugin</artifactId>
                        <configuration>
                            <docker>
                                <publishRegistry>
                                    <username>${env.GITHUB_ACTOR}</username>
                                    <password>${env.GITHUB_TOKEN}</password>
                                    <url>docker://ghcr.io</url>
                                </publishRegistry>
                            </docker>
                            <image>
                                <builder>docker.io/paketobuildpacks/builder-noble-java-tiny:latest</builder>
                                <runImage>docker.io/paketobuildpacks/run-noble-tiny:latest</runImage>
                                <name>ghcr.io/elasticsoftwarefoundation/${project.artifactId}:${project.version}</name>
                                <publish>true</publish>
                                <env>
                                    <BP_JVM_VERSION>${java.version}</BP_JVM_VERSION>
                                    <BP_JVM_JLINK_ENABLED>false</BP_JVM_JLINK_ENABLED>
                                </env>
                                <buildpacks>
                                    <buildpack>paketo-buildpacks/ca-certificates</buildpack>
                                    <buildpack>gcr.io/paketo-buildpacks/adoptium:latest</buildpack>
                                    <buildpack>paketo-buildpacks/syft</buildpack>
                                    <buildpack>paketo-buildpacks/executable-jar</buildpack>
                                    <buildpack>paketo-buildpacks/spring-boot</buildpack>
                                </buildpacks>
                            </image>
                        </configuration>
                    </plugin>
                </plugins>
            </build>
        </profile>
        <profile>
            <id>native</id>
            <build>
                <pluginManagement>
                    <plugins>
                        <plugin>
                            <groupId>org.apache.maven.plugins</groupId>
                            <artifactId>maven-jar-plugin</artifactId>
                            <configuration>
                                <archive>
                                    <manifestEntries>
                                        <Spring-Boot-Native-Processed>true</Spring-Boot-Native-Processed>
                                    </manifestEntries>
                                </archive>
                            </configuration>
                        </plugin>
                        <plugin>
                            <groupId>org.springframework.boot</groupId>
                            <artifactId>spring-boot-maven-plugin</artifactId>
                            <executions>
                                <execution>
                                    <id>process-aot</id>
                                    <goals>
                                        <goal>process-aot</goal>
                                    </goals>
                                </execution>
                            </executions>
                            <configuration>
                                <docker>
                                    <publishRegistry>
                                        <username>${env.GITHUB_ACTOR}</username>
                                        <password>${env.GITHUB_TOKEN}</password>
                                        <url>docker://ghcr.io</url>
                                    </publishRegistry>
                                </docker>
                                <image>
                                    <builder>docker.io/paketobuildpacks/builder-noble-java-tiny:latest</builder>
                                    <runImage>docker.io/paketobuildpacks/run-noble-tiny:latest</runImage>
                                    <name>ghcr.io/elasticsoftwarefoundation/${project.artifactId}:${project.version}
                                    </name>
                                    <publish>true</publish>
                                    <env>
                                        <BP_JVM_VERSION>${java.version}</BP_JVM_VERSION>
                                        <BP_JVM_JLINK_ENABLED>false</BP_JVM_JLINK_ENABLED>
                                    </env>
                                </image>
                            </configuration>
                        </plugin>
                        <plugin>
                            <groupId>org.graalvm.buildtools</groupId>
                            <artifactId>native-maven-plugin</artifactId>
                            <configuration>
                                <classesDirectory>${project.build.outputDirectory}</classesDirectory>
                                <requiredVersion>22.3</requiredVersion>
                            </configuration>
                            <executions>
                                <execution>
                                    <id>add-reachability-metadata</id>
                                    <goals>
                                        <goal>add-reachability-metadata</goal>
                                    </goals>
                                </execution>
                                <execution>
                                    <id>build-native</id>
                                    <goals>
                                        <goal>compile-no-fork</goal>
                                    </goals>
                                    <phase>package</phase>
                                </execution>
                            </executions>
                        </plugin>
                    </plugins>
                </pluginManagement>
            </build>
        </profile>
        <profile>
            <id>nativeTest</id>
            <dependencies>
                <dependency>
                    <groupId>org.junit.platform</groupId>
                    <artifactId>junit-platform-launcher</artifactId>
                    <scope>test</scope>
                </dependency>
            </dependencies>
            <build>
                <plugins>
                    <plugin>
                        <groupId>org.springframework.boot</groupId>
                        <artifactId>spring-boot-maven-plugin</artifactId>
                        <executions>
                            <execution>
                                <id>process-test-aot</id>
                                <goals>
                                    <goal>process-test-aot</goal>
                                </goals>
                            </execution>
                        </executions>
                    </plugin>
                    <plugin>
                        <groupId>org.graalvm.buildtools</groupId>
                        <artifactId>native-maven-plugin</artifactId>
                        <configuration>
                            <classesDirectory>${project.build.outputDirectory}</classesDirectory>
                            <requiredVersion>22.3</requiredVersion>
                        </configuration>
                        <executions>
                            <execution>
                                <id>native-test</id>
                                <goals>
                                    <goal>test</goal>
                                </goals>
                            </execution>
                        </executions>
                    </plugin>
                </plugins>
            </build>
        </profile>
    </profiles>
</project>



================================================================
End of Codebase
================================================================

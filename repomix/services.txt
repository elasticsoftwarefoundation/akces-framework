This file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.
The content has been processed where comments have been removed, content has been compressed (code blocks are separated by ⋮---- delimiter).

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: *.md, services/**/*.java, services/**/*.xml, services/**/*.properties, services/**/*.proto, services/**/*.imports, services/**/*.yaml
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Code comments have been removed from supported file types
- Content has been compressed - code blocks are separated by ⋮---- delimiter
- Files are sorted by Git change count (files with more changes are at the bottom)

Additional Info:
----------------

================================================================
Directory Structure
================================================================
services/
  operator/
    src/
      main/
        java/
          org/
            elasticsoftware/
              akces/
                operator/
                  aggregate/
                    Aggregate.java
                    AggregateReconciler.java
                    AggregateSpec.java
                    AggregateStatus.java
                    ConfigMapDependentResource.java
                    ServiceDependentResource.java
                    StatefulSetDependentResource.java
                  command/
                    CommandService.java
                    CommandServiceReconciler.java
                    CommandServiceSpec.java
                    CommandServiceStatus.java
                    ConfigMapDependentResource.java
                    ServiceDependentResource.java
                    StatefulSetDependentResource.java
                  query/
                    ConfigMapDependentResource.java
                    QueryService.java
                    QueryServiceReconciler.java
                    QueryServiceSpec.java
                    QueryServiceStatus.java
                    ServiceDependentResource.java
                    StatefulSetDependentResource.java
                  utils/
                    KafkaTopicUtils.java
                  AkcesOperatorApplication.java
                  AkcesOperatorConfig.java
        resources/
          META-INF/
            native-image/
              native-image.properties
          org/
            elasticsoftware/
              akces/
                operator/
                  aggregate/
                    configmap.yaml
                    service.yaml
                    statefulset.yaml
                  command/
                    configmap.yaml
                    service.yaml
                    statefulset.yaml
                  query/
                    configmap.yaml
                    service.yaml
                    statefulset.yaml
          application.properties
          logback.xml
      test/
        java/
          org/
            elasticsoftware/
              akces/
                operator/
                  AkcesOperatorApplicationTests.java
    pom.xml
  pom.xml
FRAMEWORK_OVERVIEW.md
README.md
RELEASE.md

================================================================
Files
================================================================

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/aggregate/Aggregate.java
================
public class Aggregate extends CustomResource<AggregateSpec, AggregateStatus> implements Namespaced {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/aggregate/AggregateReconciler.java
================
public class AggregateReconciler implements Reconciler<Aggregate> {
private final Logger log = LoggerFactory.getLogger(getClass());
⋮----
public void init() {
partitions = kafkaAdmin.describeTopics("Akces-Control").get("Akces-Control").partitions().size();
log.info("Found Akces-Control Topic with {} partitions", partitions);
⋮----
public UpdateControl<Aggregate> reconcile(Aggregate resource, Context<Aggregate> context) throws Exception {
reconcileTopics(resource.getSpec().getAggregateNames());
return context.getSecondaryResource(StatefulSet.class).map(statefulSet -> {
Aggregate updatedAggregate = createAggregateForStatusUpdate(resource, statefulSet);
log.info(
⋮----
resource.getMetadata().getName(),
resource.getMetadata().getNamespace(),
resource.getStatus() == null ? 0 : resource.getStatus().getReadyReplicas());
return UpdateControl.patchStatus(updatedAggregate);
}).orElseGet(UpdateControl::noUpdate);
⋮----
private Aggregate createAggregateForStatusUpdate(Aggregate tomcat, StatefulSet statefulSet) {
Aggregate res = new Aggregate();
res.setMetadata(new ObjectMetaBuilder()
.withName(tomcat.getMetadata().getName())
.withNamespace(tomcat.getMetadata().getNamespace())
.build());
⋮----
Objects.requireNonNullElse(statefulSet.getStatus(), new StatefulSetStatus());
int readyReplicas = Objects.requireNonNullElse(statefulSetStatus.getReadyReplicas(), 0);
AggregateStatus status = new AggregateStatus();
status.setReadyReplicas(readyReplicas);
res.setStatus(status);
⋮----
private void reconcileTopics(List<String> aggregateNames) {
log.info("Reconciling topics for Aggregates: {}", aggregateNames);
List<NewTopic> topics = aggregateNames.stream()
.map(name -> KafkaTopicUtils.createTopics(name, partitions))
.flatMap(List::stream).toList();
kafkaAdmin.createOrModifyTopics(topics.toArray(new NewTopic[0]));

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/aggregate/AggregateSpec.java
================
public class AggregateSpec {
⋮----
public List<String> getAggregateNames() {
⋮----
public void setAggregateNames(List<String> aggregateNames) {
⋮----
public Integer getReplicas() {
⋮----
public void setReplicas(Integer replicas) {
⋮----
public String getImage() {
⋮----
public void setImage(String image) {
⋮----
public List<String> getArgs() {
⋮----
public void setArgs(List<String> args) {
⋮----
public ResourceRequirements getResources() {
⋮----
public void setResources(ResourceRequirements resources) {
⋮----
public Boolean getEnableSchemaOverwrites() {
⋮----
public void setEnableSchemaOverwrites(Boolean enableSchemaOverwrites) {
⋮----
public String getApplicationName() {
⋮----
public void setApplicationName(String applicationName) {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/aggregate/AggregateStatus.java
================
public class AggregateStatus {
⋮----
public Integer getReadyReplicas() {
⋮----
public void setReadyReplicas(Integer readyReplicas) {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/aggregate/ConfigMapDependentResource.java
================
public class ConfigMapDependentResource extends CRUDKubernetesDependentResource<ConfigMap, Aggregate> {
⋮----
protected ConfigMap desired(Aggregate aggregate, Context<Aggregate> context) {
final ObjectMeta aggregateMetadata = aggregate.getMetadata();
final String aggregateName = aggregateMetadata.getName();
return new ConfigMapBuilder(ReconcilerUtils.loadYaml(ConfigMap.class, getClass(), "configmap.yaml"))
.editMetadata()
.withName(aggregateName + "-config")
.withNamespace(aggregateMetadata.getNamespace())
.addToLabels("app.kubernetes.io/part-of", aggregateName)
.addToLabels("app.kubernetes.io/managed-by", "akces-operator")
.endMetadata()
.build();

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/aggregate/ServiceDependentResource.java
================
public class ServiceDependentResource extends CRUDKubernetesDependentResource<Service, Aggregate> {
⋮----
protected Service desired(Aggregate aggregate, Context<Aggregate> context) {
final ObjectMeta aggregateMetadata = aggregate.getMetadata();
final String aggregateName = aggregateMetadata.getName();
return new ServiceBuilder(ReconcilerUtils.loadYaml(Service.class, getClass(), "service.yaml"))
.editMetadata()
.withName(aggregateName + "-service")
.withNamespace(aggregateMetadata.getNamespace())
.addToLabels("app.kubernetes.io/part-of", aggregateName)
.addToLabels("app.kubernetes.io/managed-by", "akces-operator")
.endMetadata()
.editSpec()
.addToSelector("app", aggregateMetadata.getName())
.endSpec()
.build();

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/aggregate/StatefulSetDependentResource.java
================
public class StatefulSetDependentResource extends CRUDKubernetesDependentResource<StatefulSet, Aggregate> {
⋮----
protected StatefulSet desired(Aggregate aggregate, Context<Aggregate> context) {
StatefulSet statefulSet = ReconcilerUtils.loadYaml(StatefulSet.class, getClass(), "statefulset.yaml");
final ObjectMeta aggregateMetadata = aggregate.getMetadata();
final String aggregateName = aggregateMetadata.getName();
⋮----
statefulSet = new StatefulSetBuilder(statefulSet)
.editMetadata()
.withName(aggregateName)
.withNamespace(aggregateMetadata.getNamespace())
.addToLabels("app", aggregateName)
.addToLabels("app.kubernetes.io/part-of", aggregateName)
.addToLabels("app.kubernetes.io/managed-by", "akces-operator")
.endMetadata()
.editSpec()
.withServiceName(aggregateName + "-service")
.editSelector().addToMatchLabels("app", aggregateName).endSelector()
.withReplicas(aggregate.getSpec().getReplicas())
.editTemplate()
.editMetadata().addToLabels("app", aggregateName).endMetadata()
⋮----
.addToImagePullSecrets(new LocalObjectReference("github-packages-cfg"))
.editFirstContainer()
.withImage(aggregate.getSpec().getImage())
.withName("akces-aggregate-service")
.withArgs(aggregate.getSpec().getArgs())
.editFirstEnv()
.withValue(aggregate.getSpec().getApplicationName())
.endEnv()
.editLastEnv()
.withValue(aggregate.getSpec().getEnableSchemaOverwrites().toString())
⋮----
.withResources(aggregate.getSpec().getResources())
.endContainer()
.editFirstVolume()
.editConfigMap()
.withName(aggregateName + "-config")
.endConfigMap()
.endVolume()
.endSpec()
.endTemplate()
.editFirstVolumeClaimTemplate()
⋮----
.withStorageClassName("akces-data-hyperdisk-balanced")
.editResources()
.withRequests(Map.of("storage", new Quantity("4Gi")))
.endResources()
⋮----
.endVolumeClaimTemplate()
⋮----
.build();

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/command/CommandService.java
================
public class CommandService extends CustomResource<CommandServiceSpec, CommandServiceStatus> implements Namespaced {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/command/CommandServiceReconciler.java
================
public class CommandServiceReconciler implements Reconciler<CommandService> {
private final Logger log = LoggerFactory.getLogger(getClass());
⋮----
public UpdateControl<CommandService> reconcile(CommandService commandService, Context<CommandService> context) throws Exception {
return context.getSecondaryResource(StatefulSet.class).map(statefulSet -> {
CommandService updatedCommandService = createCommandServiceForStatusUpdate(commandService, statefulSet);
return UpdateControl.patchStatus(updatedCommandService);
}).orElseGet(UpdateControl::noUpdate);
⋮----
private CommandService createCommandServiceForStatusUpdate(CommandService commandService, StatefulSet statefulSet) {
CommandService res = new CommandService();
res.setMetadata(new ObjectMetaBuilder()
.withName(commandService.getMetadata().getName())
.withNamespace(commandService.getMetadata().getNamespace())
.build());
⋮----
Objects.requireNonNullElse(statefulSet.getStatus(), new StatefulSetStatus());
int readyReplicas = Objects.requireNonNullElse(statefulSetStatus.getReadyReplicas(), 0);
CommandServiceStatus status = new CommandServiceStatus();
status.setReadyReplicas(readyReplicas);
res.setStatus(status);

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/command/CommandServiceSpec.java
================
public class CommandServiceSpec {
⋮----
public Integer getReplicas() {
⋮----
public void setReplicas(Integer replicas) {
⋮----
public String getImage() {
⋮----
public void setImage(String image) {
⋮----
public List<String> getArgs() {
⋮----
public void setArgs(List<String> args) {
⋮----
public ResourceRequirements getResources() {
⋮----
public void setResources(ResourceRequirements resources) {
⋮----
public String getApplicationName() {
⋮----
public void setApplicationName(String applicationName) {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/command/CommandServiceStatus.java
================
public class CommandServiceStatus {
⋮----
public Integer getReadyReplicas() {
⋮----
public void setReadyReplicas(Integer readyReplicas) {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/command/ConfigMapDependentResource.java
================
public class ConfigMapDependentResource extends CRUDKubernetesDependentResource<ConfigMap, CommandService> {
⋮----
protected ConfigMap desired(CommandService commandService, Context<CommandService> context) {
final ObjectMeta metadata = commandService.getMetadata();
final String commandServiceName = metadata.getName();
return new ConfigMapBuilder(ReconcilerUtils.loadYaml(ConfigMap.class, getClass(), "configmap.yaml"))
.editMetadata()
.withName(commandServiceName + "-config")
.withNamespace(metadata.getNamespace())
.addToLabels("app.kubernetes.io/part-of", commandServiceName)
.addToLabels("app.kubernetes.io/managed-by", "akces-operator")
.endMetadata()
.build();

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/command/ServiceDependentResource.java
================
public class ServiceDependentResource extends CRUDKubernetesDependentResource<Service, CommandService> {
⋮----
protected Service desired(CommandService commandService, Context<CommandService> context) {
final ObjectMeta metadata = commandService.getMetadata();
final String commandServiceName = metadata.getName();
return new ServiceBuilder(ReconcilerUtils.loadYaml(Service.class, getClass(), "service.yaml"))
.editMetadata()
.withName(commandServiceName + "-service")
.withNamespace(metadata.getNamespace())
.addToLabels("app.kubernetes.io/part-of", commandServiceName)
.addToLabels("app.kubernetes.io/managed-by", "akces-operator")
.endMetadata()
.editSpec()
.addToSelector("app", metadata.getName())
.endSpec()
.build();

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/command/StatefulSetDependentResource.java
================
public class StatefulSetDependentResource extends CRUDKubernetesDependentResource<StatefulSet, CommandService> {
⋮----
protected StatefulSet desired(CommandService aggregate, Context<CommandService> context) {
StatefulSet statefulSet = ReconcilerUtils.loadYaml(StatefulSet.class, getClass(), "statefulset.yaml");
final ObjectMeta metadata = aggregate.getMetadata();
final String commandServiceName = metadata.getName();
⋮----
statefulSet = new StatefulSetBuilder(statefulSet)
.editMetadata()
.withName(commandServiceName)
.withNamespace(metadata.getNamespace())
.addToLabels("app", commandServiceName)
.addToLabels("app.kubernetes.io/part-of", commandServiceName)
.addToLabels("app.kubernetes.io/managed-by", "akces-operator")
.endMetadata()
.editSpec()
.withServiceName(commandServiceName + "-service")
.editSelector().addToMatchLabels("app", commandServiceName).endSelector()
.withReplicas(aggregate.getSpec().getReplicas())
.editTemplate()
.editMetadata().addToLabels("app", commandServiceName).endMetadata()
⋮----
.addToImagePullSecrets(new LocalObjectReference("github-packages-cfg"))
.editFirstContainer()
.withImage(aggregate.getSpec().getImage())
.withName("akces-command-service")
.withArgs(aggregate.getSpec().getArgs())
.editFirstEnv()
.withValue(aggregate.getSpec().getApplicationName())
.endEnv()
.withResources(aggregate.getSpec().getResources())
.endContainer()
.editFirstVolume()
.editConfigMap()
.withName(commandServiceName + "-config")
.endConfigMap()
.endVolume()
.endSpec()
.endTemplate()
⋮----
.build();

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/query/QueryService.java
================
public class QueryService extends CustomResource<QueryServiceSpec, QueryServiceStatus> implements Namespaced {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/query/QueryServiceReconciler.java
================
public class QueryServiceReconciler implements Reconciler<QueryService> {
private final Logger log = LoggerFactory.getLogger(getClass());
⋮----
public UpdateControl<QueryService> reconcile(QueryService queryService, Context<QueryService> context) throws Exception {
return context.getSecondaryResource(StatefulSet.class).map(statefulSet -> {
QueryService updatedQueryService = createQueryServiceForStatusUpdate(queryService, statefulSet);
return UpdateControl.patchStatus(updatedQueryService);
}).orElseGet(UpdateControl::noUpdate);
⋮----
private QueryService createQueryServiceForStatusUpdate(QueryService queryService, StatefulSet statefulSet) {
QueryService res = new QueryService();
res.setMetadata(new ObjectMetaBuilder()
.withName(queryService.getMetadata().getName())
.withNamespace(queryService.getMetadata().getNamespace())
.build());
⋮----
Objects.requireNonNullElse(statefulSet.getStatus(), new StatefulSetStatus());
int readyReplicas = Objects.requireNonNullElse(statefulSetStatus.getReadyReplicas(), 0);
QueryServiceStatus status = new QueryServiceStatus();
status.setReadyReplicas(readyReplicas);
res.setStatus(status);

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/query/QueryServiceStatus.java
================
public class QueryServiceStatus {
⋮----
public Integer getReadyReplicas() {
⋮----
public void setReadyReplicas(Integer readyReplicas) {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/query/ServiceDependentResource.java
================
public class ServiceDependentResource extends CRUDKubernetesDependentResource<Service, QueryService> {
⋮----
protected Service desired(QueryService queryService, Context<QueryService> context) {
final ObjectMeta queryServiceMetadata = queryService.getMetadata();
final String queryServiceName = queryServiceMetadata.getName();
return new ServiceBuilder(ReconcilerUtils.loadYaml(Service.class, getClass(), "service.yaml"))
.editMetadata()
.withName(queryServiceName + "-service")
.withNamespace(queryServiceMetadata.getNamespace())
.addToLabels("app.kubernetes.io/part-of", queryServiceName)
.addToLabels("app.kubernetes.io/managed-by", "akces-operator")
.endMetadata()
.editSpec()
.addToSelector("app", queryServiceMetadata.getName())
.endSpec()
.build();

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/utils/KafkaTopicUtils.java
================
public class KafkaTopicUtils {
⋮----
public static List<NewTopic> createTopics(String topicName, int numPartitions) {
return List.of(
createTopic(topicName + COMMANDS_SUFFIX, numPartitions),
createTopic(topicName + DOMAINEVENTS_SUFFIX, numPartitions),
createCompactedTopic(topicName + AGGREGRATESTATE_SUFFIX, numPartitions)
⋮----
public static NewTopic createTopic(String name, int numPartitions) {
return createTopic(name, numPartitions, -1L);
⋮----
public static NewTopic createTopic(String name, int numPartitions, long retentionMs) {
NewTopic topic = new NewTopic(name, numPartitions, Short.parseShort("1"));
return topic.configs(Map.of(
⋮----
"retention.ms", Long.toString(retentionMs),
⋮----
public static NewTopic createCompactedTopic(String name, int numPartitions) {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/AkcesOperatorApplication.java
================
public class AkcesOperatorApplication {
⋮----
public static void main(String[] args) {
Security.setProperty("crypto.policy", "unlimited");
Security.insertProviderAt(new BouncyCastleProvider(), 1);
SpringApplication.run(AkcesOperatorApplication.class, args);

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/AkcesOperatorConfig.java
================
public class AkcesOperatorConfig {
⋮----
public KafkaAdmin kafkaAdmin(@Value(value = "${spring.kafka.bootstrap-servers}") String bootstrapServers) {
return new KafkaAdmin(Map.of(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers));
⋮----
public AggregateReconciler aggregateReconciler(KafkaAdmin kafkaAdmin) {
return new AggregateReconciler(kafkaAdmin);
⋮----
public CommandServiceReconciler commandServiceReconciler() {
return new CommandServiceReconciler();
⋮----
public QueryServiceReconciler queryServiceReconciler() {
return new QueryServiceReconciler();

================
File: services/operator/src/main/resources/META-INF/native-image/native-image.properties
================
#
# Copyright 2022 - 2025 The Original Authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
#     you may not use this file except in compliance with the License.
#     You may obtain a copy of the License at
#
#           http://www.apache.org/licenses/LICENSE-2.0
#
#     Unless required by applicable law or agreed to in writing, software
#     distributed under the License is distributed on an "AS IS" BASIS,
#     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#     See the License for the specific language governing permissions and
#     limitations under the License.
#
#
Args=--strict-image-heap

================
File: services/operator/src/main/resources/org/elasticsoftware/akces/operator/aggregate/service.yaml
================
apiVersion: v1
kind: Service
metadata:
  name: ""
spec:
  selector:
    app: ""
  ports:
    - protocol: TCP
      name: http
      port: 80
      targetPort: 8080
  type: ClusterIP

================
File: services/operator/src/main/resources/org/elasticsoftware/akces/operator/command/configmap.yaml
================
apiVersion: v1
kind: ConfigMap
metadata:
  name: ""
data:
  application.properties: |
    # Spring application properties
    spring.application.name=${SPRING_APPLICATION_NAME}
    spring.kafka.enabled=true
    spring.kafka.bootstrap-servers=akces-kafka-bootstrap.kafka:9092
    spring.kafka.consumer.properties.session.timeout.ms=45000
    management.endpoint.health.probes.enabled=true
    management.health.livenessState.enabled=true
    management.health.readinessState.enabled=true
    server.shutdown=graceful
    spring.mvc.problemdetails.enabled=true
    akces.schemaregistry.url=http://akces-schema-registry.kafka:8081
    akces.rocksdb.baseDir=/var/lib/akces-data
  logback.xml: |
    <configuration>
        <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
            <layout class="ch.qos.logback.classic.PatternLayout">
                <Pattern>
                    %d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n
                </Pattern>
            </layout>
        </appender>

        <logger name="org.apache.kafka" level="warn" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <logger name="org.apache.kafka.clients.producer" level="warn" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <logger name="org.apache.kafka.clients.consumer" level="warn" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <root level="info">
            <appender-ref ref="CONSOLE"/>
        </root>
    </configuration>

================
File: services/operator/src/main/resources/org/elasticsoftware/akces/operator/command/service.yaml
================
apiVersion: v1
kind: Service
metadata:
  name: ""
spec:
  selector:
    app: ""
  ports:
    - protocol: TCP
      name: http
      port: 80
      targetPort: 8080
  type: ClusterIP

================
File: services/operator/src/main/resources/org/elasticsoftware/akces/operator/command/statefulset.yaml
================
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: ""
  labels:
    app.kubernetes.io/part-of: ""
    app.kubernetes.io/managed-by: ""
spec:
  serviceName: ""
  replicas: 3
  podManagementPolicy: Parallel
  selector:
    matchLabels:
      app: ""
  template:
    metadata:
      labels:
        app: ""
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      containers:
        - name: akces-command-service
          image: ""
          env:
            - name: SPRING_APPLICATION_NAME
              value: "Akces Command Service"
            - name: SPRING_CONFIG_LOCATION
              value: "file:/config/application.properties"
            - name: LOGGING_CONFIG
              value: "file:/config/logback.xml"
            - name: BPL_JVM_THREAD_COUNT
              value: "100"
            - name: JAVA_TOOL_OPTIONS
              value: "-XX:+UseZGC -XX:+ZGenerational"
          lifecycle:
            preStop:
              exec:
                command: [ "/bin/sh", "-c", "sleep 10" ]
          ports:
            - containerPort: 8080
              name: http
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /actuator/health/readiness
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 1
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: actuator/health/liveness
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          volumeMounts:
            - name: config-volume
              mountPath: /config
      volumes:
        - name: config-volume
          configMap:
            name: ""

================
File: services/operator/src/main/resources/org/elasticsoftware/akces/operator/query/service.yaml
================
apiVersion: v1
kind: Service
metadata:
  name: ""
spec:
  selector:
    app: ""
  ports:
    - protocol: TCP
      name: http
      port: 80
      targetPort: 8080
  type: ClusterIP

================
File: services/operator/src/main/resources/application.properties
================
#
# Copyright 2022 - 2025 The Original Authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
#     you may not use this file except in compliance with the License.
#     You may obtain a copy of the License at
#
#           http://www.apache.org/licenses/LICENSE-2.0
#
#     Unless required by applicable law or agreed to in writing, software
#     distributed under the License is distributed on an "AS IS" BASIS,
#     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#     See the License for the specific language governing permissions and
#     limitations under the License.
#
#
spring.application.name=Akces Operator
spring.kafka.bootstrap-servers=akces-kafka-bootstrap.kafka:9092
management.endpoint.health.probes.enabled=true
management.health.livenessState.enabled=true
management.health.readinessState.enabled=true
server.shutdown=graceful
javaoperatorsdk.crd.apply-on-startup=true

================
File: services/operator/src/main/resources/logback.xml
================
<?xml version="1.0" encoding="UTF-8"?>

















<configuration>

    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <layout class="ch.qos.logback.classic.PatternLayout">
            <Pattern>
                %d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n
            </Pattern>
        </layout>
    </appender>

    <logger name="org.apache.kafka" level="warn" additivity="false">
        <appender-ref ref="CONSOLE"/>
    </logger>

    <logger name="org.apache.kafka.clients.producer" level="warn" additivity="false">
        <appender-ref ref="CONSOLE"/>
    </logger>

    <logger name="org.apache.kafka.clients.consumer" level="warn" additivity="false">
        <appender-ref ref="CONSOLE"/>
    </logger>

    <root level="info">
        <appender-ref ref="CONSOLE"/>
    </root>

</configuration>

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/query/ConfigMapDependentResource.java
================
public class ConfigMapDependentResource extends CRUDKubernetesDependentResource<ConfigMap, QueryService> {
⋮----
protected ConfigMap desired(QueryService queryService, Context<QueryService> context) {
final ObjectMeta queryServiceMetadata = queryService.getMetadata();
final String queryServiceName = queryServiceMetadata.getName();
final QueryServiceSpec spec = queryService.getSpec();
return new ConfigMapBuilder(ReconcilerUtils.loadYaml(ConfigMap.class, getClass(), "configmap.yaml"))
.editMetadata()
.withName(queryServiceName + "-config")
.withNamespace(queryServiceMetadata.getNamespace())
.addToLabels("app.kubernetes.io/part-of", queryServiceName)
.addToLabels("app.kubernetes.io/managed-by", "akces-operator")
.endMetadata()
.addToData(spec.getApplicationProperties() != null ?
Map.of("application.properties", spec.getApplicationProperties()) :
Collections.emptyMap())
.build();

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/query/QueryServiceSpec.java
================
public class QueryServiceSpec {
⋮----
public Integer getReplicas() {
⋮----
public void setReplicas(Integer replicas) {
⋮----
public String getImage() {
⋮----
public void setImage(String image) {
⋮----
public List<String> getArgs() {
return args != null ? args : Collections.emptyList();
⋮----
public void setArgs(List<String> args) {
⋮----
public ResourceRequirements getResources() {
⋮----
public void setResources(ResourceRequirements resources) {
⋮----
public String getApplicationName() {
⋮----
public void setApplicationName(String applicationName) {
⋮----
public List<EnvVar> getEnv() {
return env != null ? env : Collections.emptyList();
⋮----
public void setEnv(List<EnvVar> env) {
⋮----
public String getApplicationProperties() {
⋮----
public void setApplicationProperties(String applicationProperties) {

================
File: services/operator/src/main/java/org/elasticsoftware/akces/operator/query/StatefulSetDependentResource.java
================
public class StatefulSetDependentResource extends CRUDKubernetesDependentResource<StatefulSet, QueryService> {
⋮----
protected StatefulSet desired(QueryService queryService, Context<QueryService> context) {
StatefulSet statefulSet = ReconcilerUtils.loadYaml(StatefulSet.class, getClass(), "statefulset.yaml");
final ObjectMeta queryServiceMetadata = queryService.getMetadata();
final String queryServiceName = queryServiceMetadata.getName();
⋮----
statefulSet = new StatefulSetBuilder(statefulSet)
.editMetadata()
.withName(queryServiceName)
.withNamespace(queryServiceMetadata.getNamespace())
.addToLabels("app", queryServiceName)
.addToLabels("app.kubernetes.io/part-of", queryServiceName)
.addToLabels("app.kubernetes.io/managed-by", "akces-operator")
.endMetadata()
.editSpec()
.withServiceName(queryServiceName + "-service")
.editSelector().addToMatchLabels("app", queryServiceName).endSelector()
.withReplicas(queryService.getSpec().getReplicas())
.editTemplate()
.editMetadata().addToLabels("app", queryServiceName).endMetadata()
⋮----
.addToImagePullSecrets(new LocalObjectReference("github-packages-cfg"))
.editFirstContainer()
.withImage(queryService.getSpec().getImage())
.withName("akces-query-service")
.withArgs(queryService.getSpec().getArgs())
.editFirstEnv()
.withValue(queryService.getSpec().getApplicationName())
.endEnv()
.addToEnv(queryService.getSpec().getEnv().toArray(new EnvVar[0]))
.withResources(queryService.getSpec().getResources())
.endContainer()
.editFirstVolume()
.editConfigMap()
.withName(queryServiceName + "-config")
.endConfigMap()
.endVolume()
.endSpec()
.endTemplate()
.editFirstVolumeClaimTemplate()
⋮----
.withStorageClassName("akces-data-hyperdisk-balanced")
.editResources()
.withRequests(Map.of("storage", new Quantity("4Gi")))
.endResources()
⋮----
.endVolumeClaimTemplate()
⋮----
.build();

================
File: services/operator/src/main/resources/org/elasticsoftware/akces/operator/aggregate/configmap.yaml
================
apiVersion: v1
kind: ConfigMap
metadata:
  name: ""
data:
  application.properties: |
    # Spring application properties
    spring.application.name=${SPRING_APPLICATION_NAME}
    spring.kafka.enabled=true
    spring.kafka.bootstrap-servers=akces-kafka-bootstrap.kafka:9092
    spring.kafka.consumer.properties.session.timeout.ms=45000
    management.endpoint.health.probes.enabled=true
    management.health.livenessState.enabled=true
    management.health.readinessState.enabled=true
    server.shutdown=graceful
    spring.mvc.problemdetails.enabled=true
    akces.schemaregistry.url=http://akces-schema-registry.kafka:8081
    akces.rocksdb.baseDir=/var/lib/akces-data
    akces.aggregate.schemas.forceRegister=${ENABLE_SCHEMA_OVERWRITES}
  logback.xml: |
    <configuration>
        <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
            <layout class="ch.qos.logback.classic.PatternLayout">
                <Pattern>
                    %d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n
                </Pattern>
            </layout>
        </appender>

        <logger name="org.apache.kafka" level="warn" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <logger name="org.apache.kafka.clients.producer" level="warn" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <logger name="org.apache.kafka.clients.consumer" level="warn" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <logger name="org.apache.kafka.clients.NetworkClient" level="error" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <logger name="org.apache.kafka.clients.producer.internals.Sender" level="error" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <root level="info">
            <appender-ref ref="CONSOLE"/>
        </root>
    </configuration>

================
File: services/operator/src/main/resources/org/elasticsoftware/akces/operator/aggregate/statefulset.yaml
================
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: ""
  labels:
    app.kubernetes.io/part-of: ""
    app.kubernetes.io/managed-by: ""
spec:
  serviceName: ""
  replicas: 3
  podManagementPolicy: Parallel
  selector:
    matchLabels:
      app: ""
  template:
    metadata:
      labels:
        app: ""
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      containers:
        - name: akces-aggregate-service
          image: ""
          env:
            - name: SPRING_APPLICATION_NAME
              value: "Akces Aggregate Service"
            - name: SPRING_CONFIG_LOCATION
              value: "file:/config/application.properties"
            - name: LOGGING_CONFIG
              value: "file:/config/logback.xml"
            - name: BPL_JVM_THREAD_COUNT
              value: "100"
            - name: JAVA_TOOL_OPTIONS
              value: "-XX:+UseZGC -XX:+ZGenerational"
            - name: ENABLE_SCHEMA_OVERWRITES
              value: "false"
          lifecycle:
            preStop:
              exec:
                command: [ "/bin/sh", "-c", "sleep 15" ]
          ports:
            - containerPort: 8080
              name: http
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /actuator/health/readiness
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 1
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: actuator/health/liveness
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          volumeMounts:
            - name: config-volume
              mountPath: /config
            - name: akces-data
              mountPath: /var/lib/akces-data
              readOnly: false
      volumes:
        - name: config-volume
          configMap:
            name: ""
  volumeClaimTemplates:
    - metadata:
        name: akces-data
      spec:
        accessModes: [ "ReadWriteOnce" ]
        storageClassName: "akces-data-hyperdisk-balanced"
        resources:
          requests:
            storage: 4Gi

================
File: services/operator/src/main/resources/org/elasticsoftware/akces/operator/query/configmap.yaml
================
apiVersion: v1
kind: ConfigMap
metadata:
  name: ""
data:
  application-default.properties: |
    # Spring application properties
    spring.application.name=${SPRING_APPLICATION_NAME}
    spring.kafka.enabled=true
    spring.kafka.bootstrap-servers=akces-kafka-bootstrap.kafka:9092
    spring.kafka.consumer.properties.session.timeout.ms=45000
    management.endpoint.health.probes.enabled=true
    management.health.livenessState.enabled=true
    management.health.readinessState.enabled=true
    server.shutdown=graceful
    spring.mvc.problemdetails.enabled=true
    akces.schemaregistry.url=http://akces-schema-registry.kafka:8081
    akces.rocksdb.baseDir=/var/lib/akces-data
  logback.xml: |
    <configuration>
        <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
            <layout class="ch.qos.logback.classic.PatternLayout">
                <Pattern>
                    %d{HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n
                </Pattern>
            </layout>
        </appender>

        <logger name="org.apache.kafka" level="warn" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <logger name="org.apache.kafka.clients.producer" level="warn" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <logger name="org.apache.kafka.clients.consumer" level="warn" additivity="false">
            <appender-ref ref="CONSOLE"/>
        </logger>

        <root level="info">
            <appender-ref ref="CONSOLE"/>
        </root>
    </configuration>

================
File: services/operator/src/test/java/org/elasticsoftware/akces/operator/AkcesOperatorApplicationTests.java
================
class AkcesOperatorApplicationTests {
⋮----
private static final Network network = Network.newNetwork();
⋮----
new KafkaContainer(DockerImageName.parse("confluentinc/cp-kafka:" + CONFLUENT_PLATFORM_VERSION))
.withKraft()
.withEnv("KAFKA_AUTO_CREATE_TOPICS_ENABLE", "false")
.withNetwork(network)
.withNetworkAliases("kafka");
⋮----
void contextLoads() {
assertThat(restTemplate).isNotNull();
assertThat(aggregateReconciler).isNotNull();
⋮----
void healthReadinessEndpointShouldBeEnabled() throws Exception {
assertThat(this.restTemplate.getForObject("http://localhost:" + port + "/actuator/health/readiness",
String.class)).contains("{\"status\":\"UP\"}");
⋮----
void healthLivenessEndpointShouldBeEnabled() throws Exception {
assertThat(this.restTemplate.getForObject("http://localhost:" + port + "/actuator/health/liveness",
⋮----
void testAggregateReconciliation() throws Exception {
Aggregate aggregate = new Aggregate();
aggregate.setMetadata(new ObjectMetaBuilder()
.withName("test-aggregate")
.withNamespace("akces")
.build());
aggregate.setSpec(new AggregateSpec());
aggregate.getSpec().setReplicas(3);
aggregate.getSpec().setImage("test-image");
aggregate.getSpec().setAggregateNames(List.of("Account", "OrderProcessManager", "Wallet"));
⋮----
Context<Aggregate> mockContext = mock(Context.class);
when(mockContext.getSecondaryResource(StatefulSet.class)).thenReturn(Optional.empty());
UpdateControl<Aggregate> updateControl = aggregateReconciler.reconcile(aggregate, mockContext);
⋮----
Map<String, TopicDescription> reconciledTopics = kafkaAdmin.describeTopics("Account-DomainEvents", "Account-Commands", "Account-AggregateState",
⋮----
assertThat(reconciledTopics).hasSize(9);
assertThat(reconciledTopics.get("Account-DomainEvents").partitions().size()).isEqualTo(3);
assertThat(reconciledTopics.get("Account-Commands").partitions().size()).isEqualTo(3);
assertThat(reconciledTopics.get("Account-AggregateState").partitions().size()).isEqualTo(3);
assertThat(reconciledTopics.get("OrderProcessManager-DomainEvents").partitions().size()).isEqualTo(3);
assertThat(reconciledTopics.get("OrderProcessManager-Commands").partitions().size()).isEqualTo(3);
assertThat(reconciledTopics.get("OrderProcessManager-AggregateState").partitions().size()).isEqualTo(3);
assertThat(reconciledTopics.get("Wallet-DomainEvents").partitions().size()).isEqualTo(3);
assertThat(reconciledTopics.get("Wallet-Commands").partitions().size()).isEqualTo(3);
assertThat(reconciledTopics.get("Wallet-AggregateState").partitions().size()).isEqualTo(3);
⋮----
void testCommandServiceReconciliation() throws Exception {
CommandService commandService = new CommandService();
commandService.setMetadata(new ObjectMetaBuilder()
.withName("test-command-service")
⋮----
commandService.setSpec(new CommandServiceSpec());
commandService.getSpec().setReplicas(3);
commandService.getSpec().setImage("test-image");
⋮----
Context<CommandService> mockContext = mock(Context.class);
⋮----
UpdateControl<CommandService> updateControl = commandServiceReconciler.reconcile(commandService, mockContext);
⋮----
assertThat(updateControl.isNoUpdate()).isTrue();
assertThat(updateControl.getResource().isPresent()).isFalse();
⋮----
void testQueryServiceReconciliation() throws Exception {
QueryService queryService = new QueryService();
queryService.setMetadata(new ObjectMetaBuilder()
.withName("test-query-service")
⋮----
queryService.setSpec(new QueryServiceSpec());
queryService.getSpec().setReplicas(3);
queryService.getSpec().setImage("test-image");
⋮----
Context<QueryService> mockContext = mock(Context.class);
⋮----
UpdateControl<QueryService> updateControl = queryServiceReconciler.reconcile(queryService, mockContext);
⋮----
public static class KafkaInitializer
⋮----
public void initialize(ConfigurableApplicationContext applicationContext) {
⋮----
KafkaAdmin kafkaAdmin = new KafkaAdmin(Map.of(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, kafka.getBootstrapServers()));
kafkaAdmin.createOrModifyTopics(
createCompactedTopic("Akces-Control", 3),
createTopic("Akces-CommandResponses", 3, 604800000L),
createCompactedTopic("Akces-GDPRKeys", 3)
⋮----
TestPropertySourceUtils.addInlinedPropertiesToEnvironment(
⋮----
"spring.kafka.bootstrap-servers=" + kafka.getBootstrapServers()

================
File: RELEASE.md
================
## Release process

This project uses the Maven Release Plugin and GitHub Actions to create releases.\
Just run `mvn release:prepare release:perform && git push` in the root to select the version to be released and create a
VCS tag.

GitHub Actions will
start [the build process](https://github.com/elasticsoftwarefoundation/akces-framework/actions/workflows/maven-publish.yml).

If successful, the build will be automatically published
to [Github Packages](https://maven.pkg.github.com/elasticsoftwarefoundation/akces-framework/).

================
File: services/operator/src/main/resources/org/elasticsoftware/akces/operator/query/statefulset.yaml
================
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: ""
  labels:
    app.kubernetes.io/part-of: ""
    app.kubernetes.io/managed-by: ""
spec:
  serviceName: ""
  replicas: 3
  podManagementPolicy: Parallel
  selector:
    matchLabels:
      app: ""
  template:
    metadata:
      labels:
        app: ""
    spec:
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      containers:
        - name: akces-query-service
          image: ""
          env:
            - name: SPRING_APPLICATION_NAME
              value: "Akces Query Service"
            - name: SPRING_CONFIG_LOCATION
              value: "file:/config/application-default.properties,optional:file:/config/application.properties"
            - name: LOGGING_CONFIG
              value: "file:/config/logback.xml"
            - name: BPL_JVM_THREAD_COUNT
              value: "100"
            - name: JAVA_TOOL_OPTIONS
              value: "-XX:+UseZGC -XX:+ZGenerational"
          lifecycle:
            preStop:
              exec:
                command: [ "/bin/sh", "-c", "sleep 10" ]
          ports:
            - containerPort: 8080
              name: http
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /actuator/health/readiness
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 1
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: actuator/health/liveness
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          volumeMounts:
            - name: config-volume
              mountPath: /config
            - name: akces-data
              mountPath: /var/lib/akces-data
              readOnly: false
      volumes:
        - name: config-volume
          configMap:
            name: ""
  volumeClaimTemplates:
    - metadata:
        name: akces-data
      spec:
        accessModes: [ "ReadWriteOnce" ]
        storageClassName: "akces-data-hyperdisk-balanced"
        resources:
          requests:
            storage: 4Gi

================
File: FRAMEWORK_OVERVIEW.md
================
# Comprehensive Analysis of the Akces Framework

## Introduction

The Akces Framework is a sophisticated event sourcing and CQRS (Command Query Responsibility Segregation) implementation built on Apache Kafka. It provides a complete infrastructure for building distributed, event-driven applications with a clear separation between write and read concerns.

## Core Purpose and Values

Akces addresses several key challenges in distributed systems:

1. **Event Sourcing Implementation**: Provides a comprehensive event sourcing implementation where all changes to application state are captured as a sequence of events.

2. **CQRS Architecture**: Enforces clean separation between command (write) and query (read) responsibilities.

3. **Scalability**: Leverages Kafka's partitioning for horizontal scaling of aggregates.

4. **Privacy By Design**: Built-in GDPR compliance through transparent encryption of personally identifiable information (PII).

5. **Schema Evolution**: Sophisticated schema management with backward compatibility checks.

## Architecture Overview

Akces is organized into five main modules, each with distinct responsibilities:

### 1. API Module (`akces-api`)
Defines the core interfaces and annotations that make up the programming model.
- `Aggregate` and `AggregateState` interfaces
- Command and event interfaces
- Handler annotations for commands and events
- Query model interfaces

### 2. Shared Module (`akces-shared`)
Contains common utilities and shared functionality:
- Protocol record definitions for Kafka communication
- GDPR compliance utilities (encryption/decryption)
- Schema registry integration
- Serialization/deserialization support

### 3. Runtime Module (`akces-runtime`)
Implements the core event sourcing infrastructure:
- Aggregate runtime for handling commands and events
- State repositories (RocksDB-based and in-memory)
- Command handling pipeline
- Event sourcing mechanics

### 4. Client Module (`akces-client`)
Provides client-side functionality for sending commands and receiving responses:
- Command sending with synchronous and asynchronous APIs
- Service discovery for routing commands
- Schema validation

### 5. Query Support Module (`akces-query-support`)
Implements the query side of CQRS:
- Query model runtime
- Database model support (JDBC, JPA)
- Event handling for query models
- State hydration

## Key Components and Patterns

### Aggregate Pattern

At the core of Akces is the concept of aggregates, which are domain entities that:
- Encapsulate business logic
- Respond to commands
- Emit domain events
- Maintain state through event sourcing

```java
@AggregateInfo(value = "Wallet", version = 1)
public final class Wallet implements Aggregate<WalletState> {
    @CommandHandler(create = true)
    public Stream<DomainEvent> create(CreateWalletCommand cmd, WalletState isNull) {
        return Stream.of(new WalletCreatedEvent(cmd.id()));
    }
    
    @EventSourcingHandler(create = true)
    public WalletState create(WalletCreatedEvent event, WalletState isNull) {
        return new WalletState(event.id(), new ArrayList<>());
    }
}
```

### Command Handling

Commands are processed through a pipeline that:
1. Validates the command structure (using JSON Schema)
2. Routes the command to the appropriate aggregate
3. Processes the command to produce events
4. Applies those events to update the aggregate state
5. Persists the events and updated state

```java
@CommandInfo(type = "CreateWallet", version = 1)
public record CreateWalletCommand(@AggregateIdentifier String id, String currency) implements Command {
    @Override
    public String getAggregateId() {
        return id();
    }
}
```

### Event Sourcing

The event sourcing mechanism:
1. Captures all state changes as immutable events
2. Stores events in Kafka topics, partitioned by aggregate ID
3. Rebuilds aggregate state by replaying events
4. Uses RocksDB to maintain efficient state snapshots

```java
@DomainEventInfo(type = "WalletCreated", version = 1)
public record WalletCreatedEvent(@AggregateIdentifier String id) implements DomainEvent {
    @Override
    public String getAggregateId() {
        return id();
    }
}
```

### GDPR Compliance

Akces provides sophisticated GDPR compliance through:
1. `@PIIData` annotation to mark sensitive fields
2. Transparent encryption/decryption during serialization
3. Key management through Kafka topics
4. Context-based encryption to secure personal data

```java
public record AccountState(
    @AggregateIdentifier String userId,
    String country,
    @PIIData String firstName,
    @PIIData String lastName,
    @PIIData String email
) implements AggregateState {
    @Override
    public String getAggregateId() {
        return userId();
    }
}
```

### Query Models

For efficient reads, Akces implements:
1. Query models updated via domain events
2. State hydration from event streams
3. Caching mechanisms for efficient access
4. Support for custom query model implementations

```java
@QueryModelInfo(value = "WalletQuery", version = 1, indexName = "Wallets")
public class WalletQueryModel implements QueryModel<WalletQueryModelState> {
    @QueryModelEventHandler(create = true)
    public WalletQueryModelState create(WalletCreatedEvent event, WalletQueryModelState isNull) {
        return new WalletQueryModelState(event.id(), List.of());
    }
}
```

### Database Models

For integration with databases:
1. Database models updated from domain events
2. Support for JDBC and JPA
3. Transactional updates with exactly-once semantics
4. Partition-aware offset tracking

```java
@DatabaseModelInfo(value = "WalletDatabase", version = 1)
public class WalletDatabaseModel extends JdbcDatabaseModel {
    @DatabaseModelEventHandler
    public void handle(WalletCreatedEvent event) {
        jdbcTemplate.update("INSERT INTO wallets (wallet_id) VALUES (?)", event.id());
    }
}
```

### Process Managers

For coordinating complex workflows:
1. Process managers to orchestrate multi-step processes
2. Process state tracking to maintain workflow state
3. Event-driven process advancement
4. Error handling and compensation logic

```java
@AggregateInfo(value = "OrderProcessManager", version = 1)
public class OrderProcessManager implements ProcessManager<OrderProcessManagerState, OrderProcess> {
    @CommandHandler
    public Stream<BuyOrderCreatedEvent> placeBuyOrder(PlaceBuyOrderCommand command, OrderProcessManagerState state) {
        // Initiate a multi-step process
    }
    
    @EventHandler
    public Stream<DomainEvent> handle(AmountReservedEvent event, OrderProcessManagerState state) {
        // Continue the process
    }
}
```

## Technical Implementation Details

### Partition-Based Processing

Akces utilizes Kafka's partitioning for scalability:
- Aggregates are distributed across partitions based on their ID
- Each partition is processed independently
- Partitions can be rebalanced across nodes as needed
- State is maintained efficiently per partition

### Transactional Processing

Commands are processed transactionally:
- Kafka transactions ensure atomicity
- State updates are coordinated with event publishing
- Exactly-once semantics are preserved
- Failures result in transaction rollbacks

### Schema Management

Schema evolution is handled through:
- Schema registry integration (Confluent Schema Registry)
- JSON Schema validation for commands and events
- Automatic schema compatibility checks
- Version management for backward compatibility

### State Management

Aggregate state is managed efficiently:
- RocksDB for persistent state storage
- Transactional state updates
- Optimistic concurrency control
- In-memory caching for performance

## Key Innovations

1. **Integrated GDPR Compliance**: Unlike many frameworks, Akces has built-in support for handling personal data with transparent encryption.

2. **Event Indexing**: Automatic indexing of events for efficient temporal queries and state reconstruction.

3. **Flexible Deployment Models**: Support for different deployment topologies from monolithic to fully distributed.

4. **RocksDB Integration**: Efficient state storage using RocksDB for high performance with durability.

5. **Process Manager Support**: First-class support for process managers to handle complex workflows.

## Advantages Over Similar Frameworks

Compared to other event sourcing frameworks like Axon or EventStore:

1. **Kafka Foundation**: Built on Kafka for enterprise-grade scalability and reliability.

2. **Privacy by Design**: First-class GDPR compliance baked into the core.

3. **Schema Evolution**: Sophisticated schema management with backward compatibility checks.

4. **Programming Model**: Clean, annotation-based programming model that minimizes boilerplate.

5. **Complete CQRS Stack**: Full support for both command and query sides with multiple implementation options.

## Usage Scenarios

Akces is well-suited for:

1. **Financial Systems**: Where audit trails and transaction integrity are critical
2. **Customer Data Platforms**: Where GDPR compliance is essential
3. **Distributed Commerce Systems**: With complex workflows across services
4. **High-Scale Event-Driven Systems**: Requiring reliable event processing
5. **Systems with Complex Temporal Requirements**: Needing historical state reconstruction

## Limitations and Considerations

1. **Kafka Dependency**: Requires a well-configured Kafka cluster
2. **Learning Curve**: Event sourcing and CQRS patterns require a mindset shift
3. **Eventual Consistency**: Query models may lag behind command processing
4. **Infrastructure Complexity**: Requires Schema Registry and additional components

## Conclusion

The Akces Framework provides a comprehensive solution for building event-sourced, CQRS-based applications with a focus on scalability, privacy, and developer experience. Its clean programming model, combined with sophisticated runtime components, addresses many common challenges in distributed systems development.

The framework's integration with Kafka provides a reliable foundation for processing, while its schema management and GDPR compliance features address important enterprise concerns. The separation between command handling and query models follows best practices for complex domain modeling while maintaining high performance for read operations.

By providing a complete implementation of event sourcing and CQRS patterns, Akces enables developers to focus on domain logic rather than infrastructure concerns, ultimately leading to more maintainable and scalable distributed applications.

================
File: README.md
================
# Akces Framework

## Overview

Akces is a powerful CQRS (Command Query Responsibility Segregation) and Event Sourcing framework built on Apache Kafka. It provides a comprehensive infrastructure for building distributed, event-driven applications with a clear separation between write operations (commands) and read operations (queries).

The framework implements the full event sourcing pattern, capturing all changes to application state as a sequence of events. These events serve as the system of record and can be replayed to reconstruct the state at any point in time, providing a complete audit trail and enabling temporal queries.

Akces leverages Kafka's distributed architecture for reliable event storage and processing, making it highly scalable and resilient. It also provides built-in support for privacy protection (GDPR compliance), schema evolution, and efficient state management.

## Core Concepts

- **Aggregates**: Domain entities that encapsulate business logic and maintain consistency boundaries
- **Commands**: Requests to perform actions that change the state of an aggregate
- **Domain Events**: Immutable records of facts that have occurred, representing state changes
- **Command Handlers**: Process commands and produce events 
- **Event Sourcing Handlers**: Apply events to update aggregate state
- **Query Models**: Read-optimized projections of aggregate state
- **Database Models**: Persistent storage of aggregate data optimized for queries
- **Process Managers**: Coordinate workflows across multiple aggregates

## Key Features

### Command Processing

- **Command Bus**: Distribute commands to appropriate aggregates
- **Command Validation**: Automatic schema-based validation using JSON Schema
- **Command Routing**: Intelligent routing based on aggregate IDs
- **Transactional Processing**: Atomic processing with Kafka transactions

### Event Sourcing

- **Event Store**: Kafka-based storage for all domain events
- **State Reconstruction**: Rebuild aggregate state by replaying events
- **Event Handlers**: React to events to trigger additional processes
- **Event Bridging**: Connect events from one aggregate to commands on another

### Aggregate Management

- **Partition-Based Processing**: Scale horizontally through Kafka partitioning
- **State Snapshots**: Efficient state storage using RocksDB
- **Aggregate Lifecycle**: Manage aggregate creation and updates
- **Event Indexing**: Index events for efficient retrieval

### Query Support

- **Query Models**: Build specialized read models from events
- **State Hydration**: Efficiently load and cache query model state
- **Database Integration**: Support for both JDBC and JPA database models
- **Event-Driven Updates**: Keep read models in sync with write models

### Privacy & GDPR

- **PII Data Protection**: Automatic encryption of personal data
- **Transparent Handling**: Annotation-based marking of sensitive fields
- **Key Management**: Secure handling of encryption keys
- **Context-Aware Processing**: Apply encryption based on context

### Schema Management

- **Schema Registry Integration**: Work with Confluent Schema Registry
- **Schema Evolution**: Support versioning and evolution of schemas
- **Compatibility Checking**: Ensure backward compatibility
- **Automatic Generation**: Generate JSON schemas from command and event classes

### Process Managers

- **Orchestration**: Manage complex workflows across multiple aggregates
- **Stateful Processing**: Maintain process state through events
- **Event-Driven Flow**: React to events to advance processes
- **Error Handling**: Built-in compensation logic for failures

## Architecture

Akces is organized into several Maven modules:

- **api**: Core interfaces and annotations defining the programming model
- **runtime**: Implementation of event sourcing and command handling
- **shared**: Common utilities, serialization, and GDPR functionality
- **client**: Client library for sending commands and processing responses
- **query-support**: Support for query models and database models

## Getting Started

### Prerequisites

- Java 21 or higher
- Apache Kafka 3.x with KRaft mode enabled
- Confluent Schema Registry
- Maven 3.6 or higher

### Maven Dependencies

Add the following to your `pom.xml`:

```xml
<dependency>
    <groupId>org.elasticsoftwarefoundation.akces</groupId>
    <artifactId>akces-api</artifactId>
    <version>0.9.0</version>
</dependency>

<!-- For command senders -->
<dependency>
    <groupId>org.elasticsoftwarefoundation.akces</groupId>
    <artifactId>akces-client</artifactId>
    <version>0.9.0</version>
</dependency>

<!-- For aggregate services -->
<dependency>
    <groupId>org.elasticsoftwarefoundation.akces</groupId>
    <artifactId>akces-runtime</artifactId>
    <version>0.9.0</version>
</dependency>

<!-- For query models and database models -->
<dependency>
    <groupId>org.elasticsoftwarefoundation.akces</groupId>
    <artifactId>akces-query-support</artifactId>
    <version>0.9.0</version>
</dependency>
```

### Configuration

Configure the framework in your `application.yaml`:

```yaml
spring:
  kafka:
    bootstrap-servers: localhost:9092
    consumer:
      enable-auto-commit: false
      isolation-level: read_committed
      max-poll-records: 500
      heartbeat-interval: 2000
      auto-offset-reset: latest
      properties:
        max.poll.interval.ms: 10000
        session.timeout.ms: 30000
        partition.assignment.strategy: org.apache.kafka.clients.consumer.CooperativeStickyAssignor
    producer:
      acks: all
      retries: 2147483647
      properties:
        linger.ms: 0
        retry.backoff.ms: 0
        enable.idempotence: true
        max.in.flight.requests.per.connection: 1

akces:
  schemaregistry:
    url: http://localhost:8081
  rocksdb:
    baseDir: /tmp/akces
```

## Usage Examples

### Defining an Aggregate

```java
@AggregateInfo(value = "Wallet", version = 1, indexed = true, indexName = "Wallets")
public final class Wallet implements Aggregate<WalletState> {
    @Override
    public Class<WalletState> getStateClass() {
        return WalletState.class;
    }

    @CommandHandler(create = true, produces = {WalletCreatedEvent.class, BalanceCreatedEvent.class})
    public Stream<DomainEvent> create(CreateWalletCommand cmd, WalletState isNull) {
        return Stream.of(new WalletCreatedEvent(cmd.id()), 
                         new BalanceCreatedEvent(cmd.id(), cmd.currency()));
    }

    @EventSourcingHandler(create = true)
    public WalletState create(WalletCreatedEvent event, WalletState isNull) {
        return new WalletState(event.id(), new ArrayList<>());
    }
    
    @EventSourcingHandler
    public WalletState createBalance(BalanceCreatedEvent event, WalletState state) {
        List<WalletState.Balance> balances = new ArrayList<>(state.balances());
        balances.add(new WalletState.Balance(event.currency(), BigDecimal.ZERO));
        return new WalletState(state.id(), balances);
    }
    
    @CommandHandler(produces = {WalletCreditedEvent.class})
    public Stream<DomainEvent> credit(CreditWalletCommand cmd, WalletState currentState) {
        WalletState.Balance balance = currentState.balances().stream()
                .filter(b -> b.currency().equals(cmd.currency()))
                .findFirst()
                .orElse(null);
                
        if (balance == null) {
            return Stream.of(new InvalidCurrencyErrorEvent(cmd.id(), cmd.currency()));
        }
        
        if (cmd.amount().compareTo(BigDecimal.ZERO) < 0) {
            return Stream.of(new InvalidAmountErrorEvent(cmd.id(), cmd.currency()));
        }
        
        return Stream.of(new WalletCreditedEvent(currentState.id(), 
                                               cmd.currency(), 
                                               cmd.amount(), 
                                               balance.amount().add(cmd.amount())));
    }
}
```

### Defining the Aggregate State

```java
public record WalletState(String id, List<Balance> balances) implements AggregateState {
    @Override
    public String getAggregateId() {
        return id();
    }

    public record Balance(String currency, BigDecimal amount, BigDecimal reservedAmount) {
        public Balance(String currency, BigDecimal amount) {
            this(currency, amount, BigDecimal.ZERO);
        }

        public BigDecimal getAvailableAmount() {
            return amount.subtract(reservedAmount);
        }
    }
}
```

### Creating Commands

```java
@CommandInfo(type = "CreateWallet", version = 1)
public record CreateWalletCommand(
    @AggregateIdentifier 
    @NotNull String id, 
    
    @NotNull String currency
) implements Command {
    @Override
    public String getAggregateId() {
        return id();
    }
}

@CommandInfo(type = "CreditWallet", version = 1)
public record CreditWalletCommand(
    @AggregateIdentifier 
    @NotNull String id,
    
    @NotNull String currency,
    
    @NotNull BigDecimal amount
) implements Command {
    @Override
    public String getAggregateId() {
        return id();
    }
}
```

### Creating Events

```java
@DomainEventInfo(type = "WalletCreated", version = 1)
public record WalletCreatedEvent(
    @AggregateIdentifier 
    @NotNull String id
) implements DomainEvent {
    @Override
    public String getAggregateId() {
        return id();
    }
}

@DomainEventInfo(type = "BalanceCreated", version = 1)
public record BalanceCreatedEvent(
    @AggregateIdentifier 
    @NotNull String id, 
    
    @NotNull String currency
) implements DomainEvent {
    @Override
    public String getAggregateId() {
        return id();
    }
}

@DomainEventInfo(type = "WalletCredited", version = 1)
public record WalletCreditedEvent(
    @AggregateIdentifier 
    @NotNull String id,
    
    @NotNull String currency,
    
    @NotNull BigDecimal amount,
    
    @NotNull BigDecimal newBalance
) implements DomainEvent {
    @Override
    public String getAggregateId() {
        return id();
    }
}
```

### Error Events

```java
@DomainEventInfo(type = "InvalidCurrencyError", version = 1)
public record InvalidCurrencyErrorEvent(
    @AggregateIdentifier 
    @NotNull String walletId,
    
    @NotNull String currency
) implements ErrorEvent {
    @Override
    public String getAggregateId() {
        return walletId();
    }
}

@DomainEventInfo(type = "InvalidAmountError", version = 1)
public record InvalidAmountErrorEvent(
    @AggregateIdentifier 
    @NotNull String walletId,
    
    @NotNull String currency
) implements ErrorEvent {
    @Override
    public String getAggregateId() {
        return walletId();
    }
}
```

### Sending Commands

```java
@Service
public class WalletService {
    private final AkcesClient akcesClient;
    
    @Autowired
    public WalletService(AkcesClient akcesClient) {
        this.akcesClient = akcesClient;
    }
    
    public String createWallet(String currency) {
        String walletId = UUID.randomUUID().toString();
        CreateWalletCommand command = new CreateWalletCommand(walletId, currency);
        
        // Send command and wait for response
        List<DomainEvent> events = akcesClient.send("DEFAULT_TENANT", command)
            .toCompletableFuture()
            .join();
            
        // Check for success
        if (events.stream().anyMatch(e -> e instanceof ErrorEvent)) {
            throw new RuntimeException("Failed to create wallet");
        }
        
        return walletId;
    }
    
    public void creditWallet(String walletId, String currency, BigDecimal amount) {
        CreditWalletCommand command = new CreditWalletCommand(walletId, currency, amount);
        
        try {
            // Send command without waiting for response
            akcesClient.sendAndForget("DEFAULT_TENANT", command);
        } catch (CommandRefusedException e) {
            // Handle specific command exceptions
            throw new RuntimeException("Command refused: " + e.getMessage());
        } catch (CommandValidationException e) {
            throw new RuntimeException("Invalid command: " + e.getMessage());
        }
    }
}
```

### Creating a Query Model

```java
@QueryModelInfo(value = "WalletQuery", version = 1, indexName = "Wallets")
public class WalletQueryModel implements QueryModel<WalletQueryModelState> {
    @Override
    public Class<WalletQueryModelState> getStateClass() {
        return WalletQueryModelState.class;
    }
    
    @Override
    public String getIndexName() {
        return "Wallets";
    }

    @QueryModelEventHandler(create = true)
    public WalletQueryModelState create(WalletCreatedEvent event, WalletQueryModelState isNull) {
        return new WalletQueryModelState(event.id(), List.of());
    }
    
    @QueryModelEventHandler
    public WalletQueryModelState createBalance(BalanceCreatedEvent event, WalletQueryModelState state) {
        List<WalletQueryModelState.Balance> balances = new ArrayList<>(state.balances());
        balances.add(new WalletQueryModelState.Balance(event.currency(), BigDecimal.ZERO));
        return new WalletQueryModelState(state.walletId(), balances);
    }
    
    @QueryModelEventHandler
    public WalletQueryModelState creditWallet(WalletCreditedEvent event, WalletQueryModelState state) {
        return new WalletQueryModelState(
            state.walletId(),
            state.balances().stream()
                .map(balance -> {
                    if (balance.currency().equals(event.currency())) {
                        return new WalletQueryModelState.Balance(
                            balance.currency(),
                            balance.amount().add(event.amount()),
                            balance.reservedAmount()
                        );
                    }
                    return balance;
                })
                .toList()
        );
    }
}

public record WalletQueryModelState(String walletId, List<Balance> balances) implements QueryModelState {
    @Override
    public String getIndexKey() {
        return walletId();
    }
    
    public record Balance(String currency, BigDecimal amount, BigDecimal reservedAmount) {
        public Balance(String currency, BigDecimal amount) {
            this(currency, amount, BigDecimal.ZERO);
        }
        
        public BigDecimal getAvailableAmount() {
            return amount.subtract(reservedAmount);
        }
    }
}
```

### Querying a Model

```java
@RestController
@RequestMapping("/wallets")
public class WalletController {
    private final QueryModels queryModels;
    
    @Autowired
    public WalletController(QueryModels queryModels) {
        this.queryModels = queryModels;
    }
    
    @GetMapping("/{walletId}")
    public ResponseEntity<WalletQueryModelState> getWallet(@PathVariable String walletId) {
        try {
            WalletQueryModelState wallet = queryModels.getHydratedState(WalletQueryModel.class, walletId)
                .toCompletableFuture()
                .get(5, TimeUnit.SECONDS);
                
            return ResponseEntity.ok(wallet);
        } catch (QueryModelIdNotFoundException e) {
            return ResponseEntity.notFound().build();
        } catch (Exception e) {
            return ResponseEntity.status(500).build();
        }
    }
}
```

### Creating a Database Model

```java
@DatabaseModelInfo(value = "WalletDB", version = 1)
public class WalletDatabaseModel extends JdbcDatabaseModel {

    @Autowired
    public WalletDatabaseModel(JdbcTemplate jdbcTemplate, PlatformTransactionManager transactionManager) {
        super(jdbcTemplate, transactionManager);
    }
    
    @DatabaseModelEventHandler
    public void handle(WalletCreatedEvent event) {
        jdbcTemplate.update(
            "INSERT INTO wallets (wallet_id, created_at) VALUES (?, NOW())",
            event.id()
        );
    }
    
    @DatabaseModelEventHandler
    public void handle(BalanceCreatedEvent event) {
        jdbcTemplate.update(
            "INSERT INTO wallet_balances (wallet_id, currency, amount, reserved_amount) VALUES (?, ?, 0, 0)",
            event.id(),
            event.currency()
        );
    }
    
    @DatabaseModelEventHandler
    public void handle(WalletCreditedEvent event) {
        jdbcTemplate.update(
            "UPDATE wallet_balances SET amount = ? WHERE wallet_id = ? AND currency = ?",
            event.newBalance(),
            event.id(),
            event.currency()
        );
    }
}
```

### GDPR and PII Data

Akces provides built-in support for handling personal identifiable information (PII):

```java
@AggregateStateInfo(value = "UserState", version = 1)
public record UserState(
    @AggregateIdentifier 
    String userId,
    
    String country,
    
    @PIIData 
    String firstName,
    
    @PIIData 
    String lastName,
    
    @PIIData 
    String email
) implements AggregateState {
    @Override
    public String getAggregateId() {
        return userId();
    }
}
```

With this annotation, the framework automatically:
- Encrypts PII data before storing it
- Decrypts PII data when loading it
- Manages encryption keys securely
- Ensures only authorized access to decrypted data

### Process Managers

For coordinating complex workflows across multiple aggregates:

```java
@AggregateInfo(value = "OrderProcessManager", version = 1)
public class OrderProcessManager implements ProcessManager<OrderProcessManagerState, OrderProcess> {
    
    @Override
    public Class<OrderProcessManagerState> getStateClass() {
        return OrderProcessManagerState.class;
    }
    
    @EventHandler(create = true)
    public Stream<UserOrderProcessesCreatedEvent> create(AccountCreatedEvent event, OrderProcessManagerState isNull) {
        return Stream.of(new UserOrderProcessesCreatedEvent(event.userId()));
    }
    
    @EventSourcingHandler(create = true)
    public OrderProcessManagerState create(UserOrderProcessesCreatedEvent event, OrderProcessManagerState isNull) {
        return new OrderProcessManagerState(event.userId());
    }
    
    @CommandHandler
    public Stream<BuyOrderCreatedEvent> placeBuyOrder(PlaceBuyOrderCommand command, OrderProcessManagerState state) {
        String orderId = UUID.randomUUID().toString();
        
        // Reserve funds first - send command to Wallet aggregate
        getCommandBus().send(new ReserveAmountCommand(
            state.userId(),
            command.market().quoteCurrency(),
            command.quantity().multiply(command.limitPrice()),
            orderId
        ));
        
        // Create order record
        return Stream.of(new BuyOrderCreatedEvent(
            state.userId(),
            orderId,
            command.market(),
            command.quantity(),
            command.limitPrice(),
            command.clientReference()
        ));
    }
    
    @EventHandler
    public Stream<DomainEvent> handle(AmountReservedEvent event, OrderProcessManagerState state) {
        if (state.hasAkcesProcess(event.referenceId())) {
            OrderProcess process = state.getAkcesProcess(event.referenceId());
            return Stream.of(new BuyOrderPlacedEvent(
                state.userId(),
                process.orderId(),
                process.market(),
                process.quantity(),
                process.limitPrice()
            ));
        }
        return Stream.empty();
    }
    
    @EventHandler
    public Stream<DomainEvent> handle(InsufficientFundsErrorEvent errorEvent, OrderProcessManagerState state) {
        if (state.hasAkcesProcess(errorEvent.referenceId())) {
            return Stream.of(state.getAkcesProcess(errorEvent.referenceId()).handle(errorEvent));
        }
        return Stream.empty();
    }
}
```

## Schema Evolution

Akces supports evolving your domain model over time:

```java
// Original version
@DomainEventInfo(type = "AccountCreated", version = 1)
public record AccountCreatedEvent(
    @AggregateIdentifier String userId,
    String country,
    String firstName,
    String lastName,
    String email
) implements DomainEvent { 
    @Override
    public String getAggregateId() {
        return userId();
    }
}

// New version with additional field
@DomainEventInfo(type = "AccountCreated", version = 2)
public record AccountCreatedEventV2(
    @AggregateIdentifier String userId,
    String country,
    String firstName,
    String lastName,
    String email,
    Boolean twoFactorEnabled
) implements DomainEvent {
    @Override
    public String getAggregateId() {
        return userId();
    }
}

// The upcasting handler
@UpcastingHandler
public AccountCreatedEventV2 cast(AccountCreatedEvent event) {
    return new AccountCreatedEventV2(
        event.userId(), 
        event.country(), 
        event.firstName(), 
        event.lastName(), 
        event.email(), 
        false // Default value for new field
    );
}
```

## Running the Framework

### Aggregate Service

```java
@SpringBootApplication
public class AggregateServiceApplication {
    public static void main(String[] args) {
        SpringApplication.run(AggregateServiceApplication.class, args);
    }
}
```

### Query Service

```java
@SpringBootApplication
public class QueryServiceApplication {
    public static void main(String[] args) {
        SpringApplication.run(QueryServiceApplication.class, args);
    }
}
```

### Client Application

```java
@SpringBootApplication
public class ClientApplication {
    public static void main(String[] args) {
        SpringApplication.run(ClientApplication.class, args);
    }
}
```

## Benefits of Using Akces

- **Scalability**: Built on Kafka for horizontal scaling across multiple nodes
- **Reliability**: Event sourcing ensures data integrity and complete audit trails
- **Flexibility**: Clean separation of commands and queries with CQRS
- **Performance**: Efficient state management with RocksDB and optimized query models
- **Security**: Built-in GDPR compliance with transparent PII handling
- **Evolution**: Schema evolution with backward compatibility checks
- **Developer Experience**: Intuitive annotation-based programming model
- **Observability**: Complete visibility into all commands and events

## License

Apache License 2.0

## Release Process

This project uses the Maven Release Plugin and GitHub Actions to create releases.
Run `mvn release:prepare release:perform && git push` to select the version to be released and create a VCS tag.

GitHub Actions will start [the build process](https://github.com/elasticsoftwarefoundation/akces-framework/actions/workflows/maven-publish.yml).

If successful, the build will be automatically published to [Github Packages](https://maven.pkg.github.com/elasticsoftwarefoundation/akces-framework/).

================
File: services/operator/pom.xml
================
<?xml version="1.0" encoding="UTF-8"?>

















<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>
    <parent>
        <groupId>org.elasticsoftwarefoundation.akces</groupId>
        <artifactId>akces-framework-services</artifactId>
        <version>0.9.0-SNAPSHOT</version>
    </parent>
    <artifactId>akces-operator</artifactId>
    <name>Elastic Software Foundation :: Akces :: Services :: Akces Operator</name>
    <description>Kubernetes Operator for the Akces Framework</description>
    <properties>
    </properties>
    <dependencies>
        <dependency>
            <groupId>io.javaoperatorsdk</groupId>
            <artifactId>operator-framework-spring-boot-starter</artifactId>
        </dependency>

        <dependency>
            <groupId>io.javaoperatorsdk</groupId>
            <artifactId>operator-framework-spring-boot-starter-test</artifactId>
            <scope>test</scope>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-web</artifactId>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-actuator</artifactId>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-logging</artifactId>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-autoconfigure</artifactId>
        </dependency>

        <dependency>
            <groupId>org.springframework.kafka</groupId>
            <artifactId>spring-kafka</artifactId>
        </dependency>
        <dependency>
            <groupId>org.bouncycastle</groupId>
            <artifactId>bcprov-jdk18on</artifactId>
        </dependency>
        <dependency>
            <groupId>org.bouncycastle</groupId>
            <artifactId>bcpkix-jdk18on</artifactId>
        </dependency>

        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-test</artifactId>
            <scope>test</scope>
        </dependency>

        <dependency>
            <groupId>org.testcontainers</groupId>
            <artifactId>junit-jupiter</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.mockito</groupId>
            <artifactId>mockito-core</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.testcontainers</groupId>
            <artifactId>kafka</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>io.javaoperatorsdk</groupId>
            <artifactId>operator-framework-junit-5</artifactId>
            <scope>test</scope>
        </dependency>
    </dependencies>

    <build>
        <plugins>
            <plugin>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-maven-plugin</artifactId>
            </plugin>
            <plugin>
                <groupId>io.fabric8</groupId>
                <artifactId>crd-generator-maven-plugin</artifactId>
                <executions>
                    <execution>
                        <id>generate-resources</id>
                        <configuration>
                            <outputDirectory>${project.basedir}/src/main/resources/META-INF/fabric8/</outputDirectory>
                        </configuration>
                        <goals>
                            <goal>generate</goal>
                        </goals>
                    </execution>
                    <execution>
                        <goals>
                            <goal>generate</goal>
                        </goals>
                    </execution>
                </executions>
            </plugin>
        </plugins>
    </build>

</project>

================
File: services/pom.xml
================
<?xml version="1.0" encoding="UTF-8"?>

















<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <parent>
        <groupId>org.elasticsoftwarefoundation.akces</groupId>
        <artifactId>akces-framework-parent</artifactId>
        <version>0.9.0-SNAPSHOT</version>
    </parent>
    <modelVersion>4.0.0</modelVersion>

    <artifactId>akces-framework-services</artifactId>
    <packaging>pom</packaging>

    <name>Elastic Software Foundation :: Akces :: Services</name>
    <url>https://github.com/elasticsoftwarefoundation/akces-framework</url>

    <properties>
        <operator-sdk.version>5.0.4</operator-sdk.version>
        <bouncycastle.version>1.80</bouncycastle.version>
        <fabric8.version>7.1.0</fabric8.version>
    </properties>

    <dependencyManagement>
        <dependencies>
            <dependency>
                <groupId>io.javaoperatorsdk</groupId>
                <artifactId>operator-framework-spring-boot-starter</artifactId>
                <version>6.0.1</version>
                <exclusions>
                    <exclusion>
                        <groupId>io.fabric8</groupId>
                        <artifactId>kubernetes-httpclient-vertx</artifactId>
                    </exclusion>
                </exclusions>
            </dependency>
            <dependency>
                <groupId>io.javaoperatorsdk</groupId>
                <artifactId>operator-framework-spring-boot-starter-test</artifactId>
                <version>6.0.1</version>
            </dependency>
            <dependency>
                <groupId>io.javaoperatorsdk</groupId>
                <artifactId>operator-framework-junit-5</artifactId>
                <version>${operator-sdk.version}</version>
            </dependency>
            <dependency>
                <groupId>io.javaoperatorsdk</groupId>
                <artifactId>operator-framework</artifactId>
                <version>${operator-sdk.version}</version>
            </dependency>
            <dependency>
                <groupId>io.fabric8</groupId>
                <artifactId>crd-generator-apt-v2</artifactId>
                <version>${fabric8.version}</version>
            </dependency>
            <dependency>
                <groupId>org.bouncycastle</groupId>
                <artifactId>bcprov-jdk18on</artifactId>
                <version>${bouncycastle.version}</version>
            </dependency>
            <dependency>
                <groupId>org.bouncycastle</groupId>
                <artifactId>bcpkix-jdk18on</artifactId>
                <version>${bouncycastle.version}</version>
            </dependency>
            <dependency>
                <groupId>org.springframework.boot</groupId>
                <artifactId>spring-boot-dependencies</artifactId>
                <version>${spring-boot.version}</version>
                <type>pom</type>
                <scope>import</scope>
            </dependency>
        </dependencies>
    </dependencyManagement>
    <modules>
        <module>operator</module>
    </modules>
    <build>
        <plugins>
            <plugin>

                <artifactId>maven-deploy-plugin</artifactId>
                <configuration>
                    <skip>true</skip>
                </configuration>
            </plugin>
        </plugins>
    </build>
    <profiles>
        <profile>
            <id>maven-release</id>
            <build>
                <plugins>
                    <plugin>
                        <groupId>org.springframework.boot</groupId>
                        <artifactId>spring-boot-maven-plugin</artifactId>
                        <configuration>
                            <docker>
                                <publishRegistry>
                                    <username>${env.GITHUB_ACTOR}</username>
                                    <password>${env.GITHUB_TOKEN}</password>
                                    <url>docker://ghcr.io</url>
                                </publishRegistry>
                            </docker>
                            <image>
                                <builder>docker.io/paketobuildpacks/builder-noble-java-tiny:latest</builder>
                                <runImage>docker.io/paketobuildpacks/run-noble-tiny:latest</runImage>
                                <name>ghcr.io/elasticsoftwarefoundation/${project.artifactId}:${project.version}</name>
                                <publish>true</publish>
                                <env>
                                    <BP_JVM_VERSION>${java.version}</BP_JVM_VERSION>
                                    <BP_JVM_JLINK_ENABLED>false</BP_JVM_JLINK_ENABLED>
                                </env>
                                <buildpacks>
                                    <buildpack>paketo-buildpacks/ca-certificates</buildpack>
                                    <buildpack>gcr.io/paketo-buildpacks/adoptium:latest</buildpack>
                                    <buildpack>paketo-buildpacks/syft</buildpack>
                                    <buildpack>paketo-buildpacks/executable-jar</buildpack>
                                    <buildpack>paketo-buildpacks/spring-boot</buildpack>
                                </buildpacks>
                            </image>
                        </configuration>
                    </plugin>
                </plugins>
            </build>
        </profile>
        <profile>
            <id>native</id>
            <build>
                <pluginManagement>
                    <plugins>
                        <plugin>
                            <groupId>org.apache.maven.plugins</groupId>
                            <artifactId>maven-jar-plugin</artifactId>
                            <configuration>
                                <archive>
                                    <manifestEntries>
                                        <Spring-Boot-Native-Processed>true</Spring-Boot-Native-Processed>
                                    </manifestEntries>
                                </archive>
                            </configuration>
                        </plugin>
                        <plugin>
                            <groupId>org.springframework.boot</groupId>
                            <artifactId>spring-boot-maven-plugin</artifactId>
                            <executions>
                                <execution>
                                    <id>process-aot</id>
                                    <goals>
                                        <goal>process-aot</goal>
                                    </goals>
                                </execution>
                            </executions>
                            <configuration>
                                <docker>
                                    <publishRegistry>
                                        <username>${env.GITHUB_ACTOR}</username>
                                        <password>${env.GITHUB_TOKEN}</password>
                                        <url>docker://ghcr.io</url>
                                    </publishRegistry>
                                </docker>
                                <image>
                                    <builder>docker.io/paketobuildpacks/builder-noble-java-tiny:latest</builder>
                                    <runImage>docker.io/paketobuildpacks/run-noble-tiny:latest</runImage>
                                    <name>ghcr.io/elasticsoftwarefoundation/${project.artifactId}:${project.version}
                                    </name>
                                    <publish>true</publish>
                                    <env>
                                        <BP_JVM_VERSION>${java.version}</BP_JVM_VERSION>
                                        <BP_JVM_JLINK_ENABLED>false</BP_JVM_JLINK_ENABLED>
                                    </env>
                                </image>
                            </configuration>
                        </plugin>
                        <plugin>
                            <groupId>org.graalvm.buildtools</groupId>
                            <artifactId>native-maven-plugin</artifactId>
                            <configuration>
                                <classesDirectory>${project.build.outputDirectory}</classesDirectory>
                                <requiredVersion>22.3</requiredVersion>
                            </configuration>
                            <executions>
                                <execution>
                                    <id>add-reachability-metadata</id>
                                    <goals>
                                        <goal>add-reachability-metadata</goal>
                                    </goals>
                                </execution>
                                <execution>
                                    <id>build-native</id>
                                    <goals>
                                        <goal>compile-no-fork</goal>
                                    </goals>
                                    <phase>package</phase>
                                </execution>
                            </executions>
                        </plugin>
                    </plugins>
                </pluginManagement>
            </build>
        </profile>
        <profile>
            <id>nativeTest</id>
            <dependencies>
                <dependency>
                    <groupId>org.junit.platform</groupId>
                    <artifactId>junit-platform-launcher</artifactId>
                    <scope>test</scope>
                </dependency>
            </dependencies>
            <build>
                <plugins>
                    <plugin>
                        <groupId>org.springframework.boot</groupId>
                        <artifactId>spring-boot-maven-plugin</artifactId>
                        <executions>
                            <execution>
                                <id>process-test-aot</id>
                                <goals>
                                    <goal>process-test-aot</goal>
                                </goals>
                            </execution>
                        </executions>
                    </plugin>
                    <plugin>
                        <groupId>org.graalvm.buildtools</groupId>
                        <artifactId>native-maven-plugin</artifactId>
                        <configuration>
                            <classesDirectory>${project.build.outputDirectory}</classesDirectory>
                            <requiredVersion>22.3</requiredVersion>
                        </configuration>
                        <executions>
                            <execution>
                                <id>native-test</id>
                                <goals>
                                    <goal>test</goal>
                                </goals>
                            </execution>
                        </executions>
                    </plugin>
                </plugins>
            </build>
        </profile>
    </profiles>
</project>



================================================================
End of Codebase
================================================================
